<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Kafka -- 内部原理 | ByteCoding</title><meta name="author" content="zhongmingmao"><meta name="copyright" content="zhongmingmao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="群组成员关系 Kakfa使用ZooKeeper来维护集群成员的信息 每个Broker都有一个唯一的ID，这个ID可以在配置文件里面指定，也可以自动生成 在Broker启动的时候，通过创建临时节点把自己的ID注册到ZooKeeper Kakfa组件订阅ZooKeeper的&#x2F;brokers&#x2F;ids路径，当有Broker加入集群或者退出集群时，Kafka组件能获得通知 如果要启动另一个具有相同ID的Br">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka -- 内部原理">
<meta property="og:url" content="https://blog.zhongmingmao.top/2019/03/26/kafka-internal-principle/index.html">
<meta property="og:site_name" content="ByteCoding">
<meta property="og:description" content="群组成员关系 Kakfa使用ZooKeeper来维护集群成员的信息 每个Broker都有一个唯一的ID，这个ID可以在配置文件里面指定，也可以自动生成 在Broker启动的时候，通过创建临时节点把自己的ID注册到ZooKeeper Kakfa组件订阅ZooKeeper的&#x2F;brokers&#x2F;ids路径，当有Broker加入集群或者退出集群时，Kafka组件能获得通知 如果要启动另一个具有相同ID的Br">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-9.png">
<meta property="article:published_time" content="2019-03-26T14:10:06.000Z">
<meta property="article:modified_time" content="2023-04-03T10:04:59.592Z">
<meta property="article:author" content="zhongmingmao">
<meta property="article:tag" content="Middleware">
<meta property="article:tag" content="MQ">
<meta property="article:tag" content="Kafka">
<meta property="article:tag" content="Stream">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-9.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Kafka -- 内部原理",
  "url": "https://blog.zhongmingmao.top/2019/03/26/kafka-internal-principle/",
  "image": "https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-9.png",
  "datePublished": "2019-03-26T14:10:06.000Z",
  "dateModified": "2023-04-03T10:04:59.592Z",
  "author": [
    {
      "@type": "Person",
      "name": "zhongmingmao",
      "url": "https://blog.zhongmingmao.top"
    }
  ]
}</script><link rel="shortcut icon" href="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png"><link rel="canonical" href="https://blog.zhongmingmao.top/2019/03/26/kafka-internal-principle/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":32,"languages":{"author":"Author: zhongmingmao","link":"Link: ","source":"Source: ByteCoding","info":"Copyright belongs to the author. For commercial use, please contact the author for authorization. For non-commercial use, please indicate the source."}},
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Kafka -- 内部原理',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="ByteCoding" type="application/atom+xml">
</head><body><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js/themes/blue/pace-theme-minimal.min.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg" style="background-image: url(/url(https:/cdn.pixabay.com/photo/2021/07/20/03/39/fisherman-6479663_1280.jpg));"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">639</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-9.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">ByteCoding</span></a><a class="nav-page-title" href="/"><span class="site-name">Kafka -- 内部原理</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Kafka -- 内部原理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">Created</span><time datetime="2019-03-26T14:10:06.000Z" title="Created 2019-03-26 22:10:06">2019-03-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/middleware/">Middleware</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/middleware/mq/">MQ</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/middleware/mq/kafka/">Kafka</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>22mins</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:512,&quot;messagePrev&quot;:&quot;It has been&quot;,&quot;messageNext&quot;:&quot;days since the last update, the content of the article may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2023-04-03 18:04:59&quot;}" hidden></div><h2 id="群组成员关系"><a href="#群组成员关系" class="headerlink" title="群组成员关系"></a>群组成员关系</h2><ol>
<li>Kakfa使用ZooKeeper来维护集群成员的信息</li>
<li>每个Broker都有一个<strong>唯一的ID</strong>，这个ID可以在<strong>配置文件</strong>里面指定，也可以<strong>自动生成</strong></li>
<li>在Broker启动的时候，通过创建<strong>临时节点</strong>把自己的ID注册到ZooKeeper</li>
<li>Kakfa组件订阅ZooKeeper的<code>/brokers/ids</code>路径，当有Broker加入集群或者退出集群时，Kafka组件能获得<strong>通知</strong></li>
<li>如果要启动另一个具有<strong>相同ID</strong>的Broker，会得到一个错误，这个Broker会尝试进行注册，但会失败</li>
<li>在Broker停机，出现网络分区或者长时间垃圾回收停顿时，Broker会从ZooKeeper上_<strong>断开连接</strong>_<ul>
<li>此时，Broker在启动时创建的<strong>临时节点</strong>会从ZooKeeper上自动移除（ZooKeeper特性）</li>
<li>订阅Broker列表的Kafka组件会被告知该Broker已经被移除</li>
</ul>
</li>
<li>在关闭Broker时，它对应的临时节点也会消失，不过它的ID会继续存在于其他数据结构中<ul>
<li>例如，主题的副本列表里可能会包含这些ID</li>
</ul>
</li>
<li>在完全关闭了一个Broker之后，如果使用<strong>相同的ID</strong>启动另一个全新的Broker<ul>
<li>该Broker会立即加入集群，并拥有与旧Broker<strong>相同</strong>的<strong>分区</strong>和<strong>主题</strong></li>
</ul>
</li>
</ol>
<span id="more"></span>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:12181(CONNECTED) 5] ls /brokers/ids</span><br><span class="line">[1, 2, 3]</span><br><span class="line">[zk: localhost:12181(CONNECTED) 6] get /brokers/ids/1</span><br><span class="line">&#123;&quot;listener_security_protocol_map&quot;:&#123;&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;&#125;,&quot;endpoints&quot;:[&quot;PLAINTEXT://kafka1:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;kafka1&quot;,&quot;timestamp&quot;:&quot;1553847899655&quot;,&quot;port&quot;:9092,&quot;version&quot;:4&#125;</span><br><span class="line">cZxid = 0x100000042</span><br><span class="line">ctime = Fri Mar 29 16:24:59 CST 2019</span><br><span class="line">mZxid = 0x100000042</span><br><span class="line">mtime = Fri Mar 29 16:24:59 CST 2019</span><br><span class="line">pZxid = 0x100000042</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x200025dc7770001</span><br><span class="line">dataLength = 182</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure>

<h2 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h2><ol>
<li>控制器其实就是一个Broker，除了具备普通Broker的一般功能之外，还负责_<strong>分区首领的选举</strong>_</li>
<li>集群里<strong>第一个启动</strong>的Broker通过在ZooKeeper里创建一个<strong>临时节点</strong><code>/controller</code>让自己成为控制器<ul>
<li>其他Broker在启动时也会尝试创建这个临时节点，但会收到<strong>节点已经存在</strong>的异常</li>
</ul>
</li>
<li>其他Broker在<code>/controller</code>节点上创建<code>watch</code>对象，可以收到这个节点的变更通知<ul>
<li>可以确保集群里在某一时刻只有一个控制器存在</li>
</ul>
</li>
<li>如果控制器被关闭或者与ZooKeeper断开连接，ZooKeeper上的<code>/controller</code>节点就会消失<ul>
<li>集群里的其他Broker通过<code>watch</code>对象会得到控制器节点消失的通知，并尝试让自己成为新的控制器</li>
<li>第一个在ZooKeeper里成功创建<code>/controller</code>节点的Broker就会成为新的控制器</li>
<li>其他Broker会收到<strong>节点已存在</strong>的异常，然后在新的<code>/controller</code>节点上创建<code>watch</code>对象</li>
<li>每个新选举出来的控制器通过ZooKeeper的<strong>条件递增操作</strong>获得一个<strong>全新的且数值更大</strong>的<code>controller epoch</code></li>
<li>其他Broker知道当前<code>controller epoch</code>后，如果收到包含<strong>较旧</strong><code>epoch</code>的消息，会直接忽略</li>
</ul>
</li>
<li>当控制器发现一个普通Broker已经离开集群（观察ZooKeeper路径：<code>/brokers/ids</code>）<ul>
<li>那些<strong>失去首领的分区</strong>需要一个<strong>新的分区首领</strong>（这些分区的首领恰好是这个Broker）</li>
<li>控制器遍历这些分区，并确定谁应该成为新首领（分区副本列表里的<strong>下一个</strong>副本）</li>
<li>然后向所有<strong>包含新分区首领的Broker</strong>或者<strong>现有跟随者的Broker</strong>发送请求<ul>
<li>请求的内容包括：<strong>谁是新的分区首领</strong>，<strong>谁是分区跟随者</strong></li>
<li>随后<strong>新的分区首领</strong>开始<strong>处理来自生产者和消费者的请求</strong></li>
<li>而<strong>跟随者</strong>开始从<strong>新的分区首领</strong>那里<strong>复制消息</strong></li>
</ul>
</li>
</ul>
</li>
<li>当控制器发现一个新的Broker加入集群时，它会使用<code>Broker ID</code>来检查新加入的Broker是否包含<strong>现有分区的副本</strong><ul>
<li>如果有，控制器就把变更通知发送给新加入的Broker和其他Broker</li>
<li>新Broker上的副本开始从分区首领那里复制消息</li>
</ul>
</li>
<li>简而言之，Kakfa使用ZooKeeper的<strong>临时节点</strong>来选举控制器，并在Broker加入集群或者退出集群时通知控制器<ul>
<li>控制器负责在Broker加入或离开集群时进行_<strong>分区首领选举</strong>_</li>
<li>控制器使用<code>epoch</code>来避免<strong>脑裂</strong>，脑裂指的是两个节点同时认为自己是当前的控制器</li>
</ul>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:12181(CONNECTED) 10] get /controller</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;brokerid&quot;:1,&quot;timestamp&quot;:&quot;1553847900310&quot;&#125;</span><br><span class="line">cZxid = 0x100000046</span><br><span class="line">ctime = Fri Mar 29 16:25:00 CST 2019</span><br><span class="line">mZxid = 0x100000046</span><br><span class="line">mtime = Fri Mar 29 16:25:00 CST 2019</span><br><span class="line">pZxid = 0x100000046</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x200025dc7770001</span><br><span class="line">dataLength = 54</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure>

<h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h2><ol>
<li>复制功能是Kafka架构的<strong>核心</strong>，在<strong>个别节点</strong>失效时仍能保证Kafka的<strong>可用性</strong>和<strong>持久性</strong></li>
<li>Kafka使用<strong>主题</strong>来组织数据，每个主题被分为若干个<strong>分区</strong>，每个分区有多个<strong>副本</strong>（主题 -&gt; 分区 -&gt; 副本）</li>
<li>每个Broker可以保存多个属于不同主题和不同分区的副本</li>
</ol>
<h3 id="副本类型"><a href="#副本类型" class="headerlink" title="副本类型"></a>副本类型</h3><h4 id="首领副本"><a href="#首领副本" class="headerlink" title="首领副本"></a>首领副本</h4><ol>
<li>每个分区都有一个<strong>首领副本</strong></li>
<li>为了保证<strong>一致性</strong>，所有<strong>生产者请求</strong>和<strong>消费者请求</strong>都会经过<strong>首领副本</strong></li>
<li>首领的另一个任务：弄清楚哪个<strong>跟随者的状态</strong>与自己的状态是一致的</li>
<li>跟随者为了保持与首领的状态一致，在有新消息到达时尝试从首领那里<strong>复制</strong>消息，但也有可能同步失败<ul>
<li>例如网络拥塞导致变慢，Broker发生崩溃导致复制滞后，直到重启Broker后复制才会继续</li>
</ul>
</li>
</ol>
<h4 id="跟随者副本"><a href="#跟随者副本" class="headerlink" title="跟随者副本"></a>跟随者副本</h4><ol>
<li>跟随者副本：<strong>首领副本以外的副本</strong></li>
<li>跟随者副本<strong>不处理</strong>来自客户端的请求<ul>
<li>唯一的任务：从<strong>首领副本</strong>那里<strong>复制</strong>消息，保持与首领副本<strong>状态一致</strong></li>
</ul>
</li>
<li>如果首领副本发生崩溃，其中的一个跟随者副本就会被<strong>晋升</strong>为新的首领副本</li>
<li>跟随者为了与首领保持同步，跟随者向首领发送<strong>获取数据</strong>的请求<ul>
<li>这种请求与<strong>消费者为了读取消息而发送的请求</strong>是一样的</li>
<li>请求消息里面包含了跟随者想要获取消息的<strong>偏移量</strong>（偏移量总是<strong>有序</strong>的）</li>
<li>首领将响应消息发送给跟随者</li>
</ul>
</li>
<li>一个跟随者依次请求消息1、消息2和消息3，在收到这3个请求的响应之前，跟随者是不会发送第4个请求<ul>
<li>如果跟随者请求了消息4，那么首领就会知道它已经收到了前面3个请求的响应</li>
</ul>
</li>
<li><em><strong>通过查看每个跟随者请求的最新偏移量，首领就会知道每个跟随者复制的进度</strong></em></li>
<li>跟随者会被首领认为<strong>不同步</strong>的情况<ul>
<li>跟随者在10S内<strong>没有请求任何消息</strong>（_<strong>可能死亡</strong>_）</li>
<li>虽然跟随者在请求消息，但在10S内<strong>没有请求到首领最新的数据</strong>（_<strong>滞后</strong>_）</li>
</ul>
</li>
<li>同步的跟随者：_<strong>持续请求得到的最新消息</strong>_<ul>
<li>在首领发生失效时，只有同步的跟随者才有可能被选为<strong>新首领</strong></li>
</ul>
</li>
<li><code>replica.lag.time.max.ms</code>：正常的跟随者允许的不活跃时间，默认10S</li>
</ol>
<h3 id="首选首领"><a href="#首选首领" class="headerlink" title="首选首领"></a>首选首领</h3><ol>
<li>除了<strong>当前首领</strong>之外，每个分区都有一个_<strong>首选首领</strong>_<ul>
<li>首选首领：<em>创建主题时指定的首领</em></li>
</ul>
</li>
<li>默认情况下，<code>auto.leader.rebalance.enable=true</code><ul>
<li>Kafka会检查首选首领是不是当前首领，如果不是并且该首选首领是<strong>同步</strong>的</li>
<li>那么就会触发<strong>首领选举</strong>，让首选首领成为当前首领</li>
</ul>
</li>
<li>找到首选首领<ul>
<li>从分区的副本清单里可以很容易找到首选首领，清单里的<strong>第一个</strong>副本一般就是首选首领<ul>
<li>不管当前首领是哪一个副本，都不会改变这一事实</li>
</ul>
</li>
<li>如果是手动进行副本分配，第一个指定的副本就是首选首领，_<strong>要确保首选首领被传播到其他Broker</strong>_<ul>
<li>避免让包含了首选首领的Broker负载过重，而其他Broker却无法为它们分担负载</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="处理请求"><a href="#处理请求" class="headerlink" title="处理请求"></a>处理请求</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-handle-request-procedure.png" width=500/>

<ol>
<li>Broker的大部分工作就是处理<strong>客户端、分区副本和控制器</strong>发送给<strong>分区首领</strong>的请求</li>
<li>Kafka提供了一个<strong>基于TCP的二进制协议</strong>，指定了<strong>请求消息的格式</strong>以及Broker如何对请求做出响应<ul>
<li>客户端发起连接并发送请求，Broker处理请求并做出响应</li>
</ul>
</li>
<li>Broker按照<strong>请求到达的顺序</strong>来处理它们<ul>
<li>这种顺序保证让Kafka具有了消息队列的特性，同时保证保存的消息也是有序的</li>
</ul>
</li>
<li>所有请求消息都包含一个<strong>标准消息头</strong><ul>
<li><code>Request type</code>（即 API Key）</li>
<li><code>Request version</code>（Broker可以处理不同版本的客户端请求，并依据客户端版本做出不同的响应）</li>
<li><code>Correlation ID</code>一个具有<strong>唯一性</strong>的数字，用于<strong>标识请求消息</strong>，同时也会出现在响应消息和错误日志里</li>
</ul>
</li>
<li>Broker会在它所监听的每一个端口上运行一个<code>Acceptor</code>线程<ul>
<li>这个线程会创建一个<strong>连接</strong>，并把它交给<code>Processor</code>线程去处理</li>
<li><code>Processor</code>线程（网络线程）的数量是可配置的</li>
<li>网络线程负责从客户端获取请求消息，把它们放进<strong>请求队列</strong>，然后从<strong>响应队列</strong>获取响应消息，把它们发送给客户端</li>
</ul>
</li>
<li>请求消息被放到请求队列后，IO线程会负责处理他们，主要的请求类型如下<ul>
<li><strong>生产请求</strong>：生产者发送的请求，它包含客户端要写入Broker的消息</li>
<li><strong>获取请求</strong>：在<strong>消费者</strong>和<strong>跟随者副本</strong>需要从Broker读取消息时发送的请求</li>
</ul>
</li>
<li>生产请求和获取请求都必须发送给分区的<strong>首领副本</strong><ul>
<li>如果Broker收到一个针对特定分区的请求，而该分区的首领副本在另一个Broker上<ul>
<li>那么发送请求的客户端会收到一个<strong>非分区首领</strong>的错误响应</li>
</ul>
</li>
<li>客户端要自己负责把<strong>生产请求</strong>和<strong>获取请求</strong>发送到正确的Broker上<ul>
<li>客户端通过发送<strong>元数据请求</strong>来确定分区的首领副本在哪个Broker上</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="生产请求"><a href="#生产请求" class="headerlink" title="生产请求"></a>生产请求</h3><ol>
<li>生产者配置参数<code>acks</code>：指定了需要多少个Broker确认才可以认为一个消息的写入是成功的<ul>
<li><code>acks=1</code>：只要<strong>分区首领</strong>收到消息就认为写入成功</li>
<li><code>acks=all</code>：需要<strong>所有同步的副本</strong>收到消息才算写入成功</li>
<li><code>acks=0</code>：生产者把消息发出去之后，完全不需要等待Broker的响应</li>
</ul>
</li>
<li>包含首领副本的Broker在收到生产请求时，会做一些验证动作<ul>
<li>发送数据的用户是否有对主题的<strong>写入权限</strong></li>
<li>请求里包含的acks值是否有效（0、1或all）</li>
<li>如果<code>acks=all</code>，判断是否有足够多的同步副本保证消息已经被安全写入</li>
</ul>
</li>
<li>随后，消息会被写入<strong>本地磁盘</strong><ul>
<li>在<code>Linux</code>系统上，消息会被写到<strong>文件系统缓存</strong>里，并不保证它们何时会被刷新到磁盘上</li>
<li>Kafka不会一直等待数据被写到磁盘上（Kafka依赖<strong>复制功能</strong>来保证消息的<strong>持久性</strong>）</li>
</ul>
</li>
<li>在消息被<strong>写入分区首领之后</strong>，Broker开始检查<code>acks</code>的配置参数<ul>
<li>如果<code>acks</code>被设为0或者1，Broker立即返回响应</li>
<li>如果<code>acks</code>被设为all，那么请求会被保存在一个叫做<strong>炼狱</strong>的<strong>缓冲区</strong>里<ul>
<li>直到分区首领发现<strong>所有跟随者副本</strong>都复制了消息，响应才会被返回给客户端</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="获取请求"><a href="#获取请求" class="headerlink" title="获取请求"></a>获取请求</h3><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-consume-min-size.png" width=600/>

<ol>
<li>客户端发送获取请求，向Broker请求主题分区里具有<strong>特定偏移量</strong>的消息</li>
<li>获取请求需要先到达指定的<strong>分区首领</strong>上，然后客户端通过<strong>查询元数据</strong>来确保请求的路由是正确的</li>
<li>分区首领在收到获取请求时，分区首领首先会检查获取请求是否有效（例如指定的偏移量在分区上是否存在）</li>
<li>如果请求的偏移量存在，Broker将按照<strong>客户端指定的数量上限</strong>从分区里读取消息，再把消息返回给客户端</li>
<li>客户端除了可以设置Broker返回数据的上限外，还可以设置<strong>下限</strong><ul>
<li>如果把下限设置为10KB，相当于告诉Broker：等到有10KB数据的时候再把他们发送给我</li>
<li>在主题消息的流量不是很大的情况下，可以减少<strong>CPU开销</strong>和<strong>网络开销</strong></li>
<li>Kafka也不会让客户端一直等待Broker积累数据<ul>
<li>客户端定义一个<strong>超时时间</strong>，告诉Broker：如果无法在X毫秒内积累满足要求的数据量，就把当前数据返回给我</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="零复制"><a href="#零复制" class="headerlink" title="零复制"></a>零复制</h4><ol>
<li>Kafka使用<strong>零复制</strong>技术向客户端发送消息</li>
<li>Kafka直接把消息从<strong>Linux文件系统缓存</strong>里发送到<strong>网络通道</strong>，而不需要经过任何中间缓冲区<ul>
<li>这是Kafka与其他大部分数据库系统不一样的地方</li>
<li>其他数据库在将数据发送给客户端之前会先把它们保存在本地缓存里</li>
</ul>
</li>
<li>这项技术<strong>避免了字节复制</strong>，<strong>不需要管理内存缓冲区</strong>，从而获得<strong>更好的性能</strong></li>
</ol>
<h4 id="高水位"><a href="#高水位" class="headerlink" title="高水位"></a>高水位</h4><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-consume-isr.png" width=600/>

<ol>
<li>并不是所有保存在<strong>分区首领</strong>上的数据都可以被客户端读取</li>
<li>分区首领知道每个消息会被复制到哪个副本上，_<strong>在消息还没有被写入所有同步副本之前，是不会发送给消费者的</strong>_<ul>
<li>尝试获取这些消息的请求会得到<strong>空响应</strong>而不是错误</li>
</ul>
</li>
<li>还没有被足够多的副本复制的消息被认为是<strong>不安全</strong>的<ul>
<li>如果分区首领发生崩溃，另一个跟随者副本成为新首领，那么有些消息就可能会_<strong>丢失</strong>_</li>
<li>如果允许消费者读取这些消息，可能会_<strong>破坏一致性</strong>_</li>
<li>一个消费者读取并处理了这样的一个消息，但另外一个消费者发现这个消息其实并不存在</li>
<li>所以会等到<strong>所有同步副本</strong>复制了这些消息，才允许消费者读取它们</li>
<li>这就意味着，如果Broker间的<strong>消息复制</strong>因为某些原因变慢了<ul>
<li>那么消息到达消费者的时间就会随之变长（因为需要先等待消息复制完毕）</li>
</ul>
</li>
<li>参数<code>replica.lag.time.max.ms</code>，默认值为10S<ul>
<li>指定了副本在复制消息时可被允许的最大延时时间</li>
<li>如果超过了该时间，跟随者会被分区首领认为是<strong>不同步</strong>的，会被移出<code>ISR</code></li>
</ul>
</li>
</ul>
</li>
<li>消费者只能看到已经复制到<code>ISR</code>(in-sync replica)的消息</li>
</ol>
<h3 id="元数据请求"><a href="#元数据请求" class="headerlink" title="元数据请求"></a>元数据请求</h3><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-client-route.png" width=500/>

<ol>
<li>元数据请求包含了客户端感兴趣的<strong>主题列表</strong></li>
<li>服务端的响应消息包含：这些主题所包含的分区，每个分区都有哪些副本，以及哪个分区副本是首领</li>
<li>元数据请求可以发送给任意一个Broker，因为所有的Broker都缓存了这些信息</li>
<li>一般情况下，客户端会把这些信息缓存起来，并直接往目标Broker发送生产请求和获取请求</li>
<li>客户端需要不定时通过元数据请求刷新这些信息，刷新间隔由参数<code>metadata.max.age.ms</code>（默认为5分钟）控制</li>
<li>如果客户端收到<strong>非分区首领</strong>的错误，客户端会在尝试重新发送请求之前先刷新元数据</li>
</ol>
<h3 id="其他请求"><a href="#其他请求" class="headerlink" title="其他请求"></a>其他请求</h3><ol>
<li>客户端在网络上使用的是<strong>通用二进制协议</strong><ul>
<li>Kakfa内置了Java客户端，但也有其他语言实现的客户端，如C，Python和Go</li>
<li>这些客户端就是使用这个二进制协议与Broker通信的</li>
</ul>
</li>
<li>Broker之间也使用同样的通信协议，它们之间的请求发生在Kafka内部，客户端不应该使用这些请求<ul>
<li>例如当一个新分区首领被选举出来，控制器会发送<code>LeaderAndIsr</code>请求给新分区首领和跟随者</li>
<li>新分区首领：可以开始接收和处理来自客户端的请求</li>
<li>跟随者：开始跟随新分区首领</li>
</ul>
</li>
<li>协议在持续演化<ul>
<li>随着客户端功能的不断增加，需要改进协议来满足需求</li>
<li>修改已有请求类型来增加新功能</li>
</ul>
</li>
</ol>
<h2 id="物理存储"><a href="#物理存储" class="headerlink" title="物理存储"></a>物理存储</h2><ol>
<li>Kafka的<strong>基本存储单元</strong>是<strong>分区</strong><ul>
<li><em><strong>一个分区只能属于一个Broker</strong></em></li>
<li><em><strong>一个分区只能属于一个磁盘</strong></em></li>
</ul>
</li>
<li>因此，分区的大小受到<strong>单个挂载点可用空间</strong>的限制，一个挂载点由单个磁盘或多个磁盘组成</li>
<li>在配置Kafka时，<code>log.dirs</code>指定了一个用于存储分区的目录列表</li>
</ol>
<h3 id="分区分配"><a href="#分区分配" class="headerlink" title="分区分配"></a>分区分配</h3><h4 id="Broker间分配分区"><a href="#Broker间分配分区" class="headerlink" title="Broker间分配分区"></a>Broker间分配分区</h4><ol>
<li>假设有6个Broker，打算创建一个包含10个分区的主题，并且复制系数为3，那么Kafka就会有30个分区副本</li>
<li>在进行分区分配的时候，要达到如下目标<ul>
<li>在Broker间<strong>平均分布</strong>分区副本，保证每个Broker可以分到5个副本</li>
<li><strong>每个分区的每个副本分布到不同的Broker上</strong><ul>
<li>假设分区0的首领副本在Broker 2上</li>
<li>那么可以把跟随者副本放在Broker 3和Broker 4上</li>
<li>但不能放在Broker 2上，也不能两个都放在Broker 3上</li>
</ul>
</li>
<li>如果Broker指定了机架信息，那么尽可能把每个分区的副本分配到不同机架的Broker上<ul>
<li>保证在一个机架不可用时不会导致整体的分区不可用</li>
</ul>
</li>
</ul>
</li>
<li>分配策略<ul>
<li>先<strong>随机选择</strong>一个Broker（假设是4），然后使用<strong>轮询</strong>的方式给每个Broker分配分区来确定<strong>分区首领</strong>的位置<ul>
<li>分区0的首领副本会在Broker 4，分区1的首领副本会在Broker 5，分区2的首领副本会在Broker 0，以此类推</li>
</ul>
</li>
<li>然后从分区首领开始，依次分配<strong>跟随者副本</strong><ul>
<li>如果分区0的首领在Broker 4，那么它的第一个跟随者会在Broker 5，第二个跟随者会在Broker 0</li>
<li>如果分区1的首领在Broker 5，那么它的第一个跟随者会在Broker 0，第二个跟随者会在Broker 1</li>
</ul>
</li>
<li>如果设置了机架信息，那就不是按照数字顺序来选择Broker，而是按照<strong>交替机架</strong>的方式来选择Broker<ul>
<li>假设Broker 0~2放置在同一个机架上，Broker 3~5放置在另一个机架上</li>
<li>不是按照0~5的顺序来选择Broker，而是按照0、3、1、4、2、5的顺序选择</li>
<li>这样每个相邻的Broker都在不同的机架上</li>
<li>在机架下线时依然能保证<strong>可用性</strong></li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="Broker内分配分区"><a href="#Broker内分配分区" class="headerlink" title="Broker内分配分区"></a>Broker内分配分区</h4><ol>
<li>为分区首领和跟随者副本选好的Broker后，接下来需要决定这些分区使用哪个目录（<code>log.dirs</code>）</li>
<li><em><strong>一个分区只能属于某一个目录</strong></em></li>
<li>规则：计算每个目录里的<strong>分区数量</strong>，新的分区总是被添加到<strong>数量最少</strong>的那个目录里</li>
</ol>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ol>
<li>在Broker间分配分区时并没有考虑<strong>可用空间</strong>和<strong>工作负载</strong>的问题</li>
<li>在为分区分配到磁盘上时会考虑<strong>分区数量</strong>，但也不会考虑<strong>分区大小</strong></li>
</ol>
<h3 id="文件管理"><a href="#文件管理" class="headerlink" title="文件管理"></a>文件管理</h3><ol>
<li>Kafka的一个基本特性：<strong>保留数据</strong></li>
<li>Kafka不会一直保留数据，也不会等到所有消费者都读取消息之后才删除消息</li>
<li>Kafka为每个主题配置了数据保留期限<ul>
<li>数据被删除之前可以保留多长<strong>时间</strong></li>
<li>清理数据之前可以保留数据量的<strong>大小</strong></li>
</ul>
</li>
<li>由于在一个大文件里查找和删除消息是很费时间的，也很容易出错，因此把分区分成若干个<strong>片段</strong><ul>
<li>默认情况下，每个片段包含<strong>1GB</strong>或<strong>一周</strong>的数据，以<strong>较小</strong>的那个为准</li>
<li>在Broker往分区写入数据时，如果达到片段上限，就关闭当前文件，并打开一个新文件</li>
<li>当前<strong>正在写入数据的片段</strong>叫作<strong>活跃片段</strong>，_<strong>活跃片段永远不会被删除</strong>_<ul>
<li>如果你要保留1天数据，但活跃片段里包含5天的数据，那么这些数据会被保留5天</li>
<li>因为在片段被关闭之前这些数据是无法被删除的</li>
</ul>
</li>
</ul>
</li>
<li>Broker会为分区里的<strong>每个片段</strong>打开一个<strong>文件句柄</strong>，哪怕片段时不活跃的<ul>
<li>这样会导致打开过多的文件句柄，操作系统必须根据实际情况做一些调优</li>
</ul>
</li>
</ol>
<h3 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h3><ol>
<li>Kafka的<strong>消息</strong>和<strong>偏移量</strong>保存在文件中</li>
<li><em><strong>磁盘上的数据格式 &#x3D;&#x3D; 生产者发送过来的消息格式 &#x3D;&#x3D; 发送给消费者的消息格式</strong></em><ul>
<li>Kafka可以使用<strong>零复制</strong>技术给消费者发送消息</li>
<li>避免了对生产者已经压缩过的消息进行<strong>解压</strong>和<strong>再压缩</strong></li>
</ul>
</li>
<li>消息里还包含了<strong>消息大小</strong>、<strong>校验和</strong>、<strong>消息格式版本号</strong>、<strong>压缩算法</strong>（<code>Snappy</code>、<code>GZip</code>和<code>LZ4</code>）和<strong>时间戳</strong><ul>
<li>时间戳可以是生产者发送消息的时间，也可以是消息到达Broker的时间，可配置的</li>
</ul>
</li>
<li>可以用<code>DumpLogSegments</code>工具来查看日志片段的内容</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kafka-run-class kafka.tools.DumpLogSegments --files 00000000000000000000.log</span><br><span class="line">Dumping 00000000000000000000.log</span><br><span class="line">Starting offset: 0</span><br><span class="line">baseOffset: 0 lastOffset: 0 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1553172809994 isvalid: true size: 98 magic: 2 compresscodec: NONE crc: 898077232</span><br><span class="line">baseOffset: 1 lastOffset: 2 count: 2 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 98 CreateTime: 1553172813953 isvalid: true size: 76 magic: 2 compresscodec: NONE crc: 4107488416</span><br><span class="line">baseOffset: 3 lastOffset: 3 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 174 CreateTime: 1553172817170 isvalid: true size: 79 magic: 2 compresscodec: NONE crc: 1335719899</span><br><span class="line">baseOffset: 4 lastOffset: 4 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 253 CreateTime: 1553172846668 isvalid: true size: 69 magic: 2 compresscodec: NONE crc: 4157562046</span><br><span class="line">baseOffset: 5 lastOffset: 5 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 322 CreateTime: 1553172857356 isvalid: true size: 79 magic: 2 compresscodec: NONE crc: 3694331330</span><br><span class="line">baseOffset: 6 lastOffset: 6 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 401 CreateTime: 1553219688039 isvalid: true size: 73 magic: 2 compresscodec: NONE crc: 3459522042</span><br><span class="line">baseOffset: 7 lastOffset: 7 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 474 CreateTime: 1553219691963 isvalid: true size: 80 magic: 2 compresscodec: NONE crc: 2634324074</span><br><span class="line">baseOffset: 8 lastOffset: 8 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 554 CreateTime: 1553219762539 isvalid: true size: 71 magic: 2 compresscodec: NONE crc: 950257936</span><br><span class="line">baseOffset: 9 lastOffset: 9 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 625 CreateTime: 1553429752873 isvalid: true size: 92 magic: 2 compresscodec: NONE crc: 1719404601</span><br><span class="line">baseOffset: 10 lastOffset: 10 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 717 CreateTime: 1553435686204 isvalid: true size: 92 magic: 2 compresscodec: NONE crc: 1667790229</span><br><span class="line">baseOffset: 11 lastOffset: 11 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 809 CreateTime: 1553435686355 isvalid: true size: 92 magic: 2 compresscodec: NONE crc: 1615137336</span><br></pre></td></tr></table></figure>

<h4 id="消息压缩"><a href="#消息压缩" class="headerlink" title="消息压缩"></a>消息压缩</h4><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-compressed-message.png" width=800/>

<ol>
<li>如果生产者发送的是<strong>压缩过</strong>的消息，那么<strong>同一批次</strong>的消息会被压缩在一起，然后被当做<strong>包装消息</strong>进行发送<ul>
<li>Broker收到这样的消息后，会直接把它发送给消费者</li>
</ul>
</li>
<li>消费者在解压这个消息后，会看到<strong>整个批次</strong>的消息，它们都有自己的时间戳和偏移量</li>
<li>如果<strong>生产者</strong>使用了<strong>压缩功能</strong>（<strong>极力推荐</strong>）<ul>
<li><em><strong>如果发送的批次越大，那么在网络传输和磁盘存储方面会获得越好的压缩性能</strong></em></li>
<li>同时意味着如果修改了消费者使用的消息格式，那么网络传输和磁盘存储的格式也要随之修改<ul>
<li>而且Broker要知道如何处理包含这两种消息格式的文件</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><ol>
<li>消费者可以从Kafka的<strong>任意可用偏移量位置</strong>开始读取消息</li>
<li>假设消费者要读取从偏移量100开始的1MB消息<ul>
<li>那么Broker必须<strong>立即定位</strong>到偏移量100（可以是分区的任意一个片段），然后从这个位置读取消息</li>
</ul>
</li>
<li>为了帮助Broker<strong>快速地定位</strong>到指定的偏移量，_<strong>Kafka为每个分区维护了一个索引</strong>_<ul>
<li><em><strong>索引结构：偏移量 -&gt; 日志片段名（file） + 偏移量在日志片段中的位置（pos）</strong></em></li>
</ul>
</li>
<li>索引也被分成<strong>片段</strong>，在<strong>删除消息</strong>时，也可以<strong>删除相应的索引</strong></li>
<li><strong>Kafka不维护索引的校验和</strong><ul>
<li>如果索引出现损坏，Kafka会通过<strong>重新读取消息并生成索引</strong>，因此<strong>删除索引</strong>是<strong>绝对安全</strong>的</li>
</ul>
</li>
</ol>
<h3 id="清理"><a href="#清理" class="headerlink" title="清理"></a>清理</h3><ol>
<li>一般情况下，Kafka会根据设置的时间保留数据，把超过时效的旧数据删除</li>
<li>早于保留时间的旧事件会被删除，<strong>为每个键保留最新的值</strong>，从而达到清理的效果</li>
</ol>
<h4 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h4><ol>
<li>每个日志片段都可以分为以下两部分<ul>
<li><strong>干净的部分</strong>：这些消息之前被清理过，<strong>每个键只有一个对应的值</strong>，这个值是上一次清理时保留下来的</li>
<li><strong>污浊的部分</strong>：这些消息是在上一次清理<strong>之后</strong>写入的</li>
</ul>
</li>
<li>如果Kafka在启动时启用了清理功能（<code>log.cleaner.enable=true</code>）<ul>
<li>每个Broker会启动<strong>一个清理管理线程</strong>和<strong>多个清理线程</strong>，它们负责执行清理任务</li>
<li>这些线程会优先选择<strong>污浊率较高</strong>（污浊消息占分区总大小的比例）的分区进行清理</li>
</ul>
</li>
<li>为了清理分区，清理线程会读取分区的<strong>污浊部分</strong>，并在内存里创建一个<strong>map</strong><ul>
<li>map里的每个元素包含了<strong>消息键的散列值</strong>和<strong>消息的偏移量</strong>，即<code>&lt;hash(key),offset&gt;</code></li>
<li>消息键的散列值为<strong>16 Bytes</strong>，消息的偏移量为<strong>8 Bytes</strong></li>
<li>如果要清理一个1GB的日志片段，并假设每个消息为1KB，那么这个日志片段包含100W个消息<ul>
<li>但最多只需要24MB就可以清理这个片段（在键的散列值不重复的情况）</li>
</ul>
</li>
</ul>
</li>
<li>在配置Kafka时可以对map使用的内存大小进行配置<ul>
<li>每个清理线程都有自己的map，而上面的这个参数指定的是<strong>所有清理线程</strong>可使用的内存总大小</li>
<li>如果为map分配了1GB的内存，并使用5个清理线程，每个线程可以使用200MB内存来创建自己的map</li>
</ul>
</li>
<li>Kafka不要求分区的整个污浊部分来适应这个map的大小，但要求<strong>至少一个完整的日志片段</strong>必须符合<ul>
<li>如果不符合，那么Kafka就会报错，要么分配更多的内存，要么减少清理线程的数量</li>
</ul>
</li>
<li>如果只有少部分片段完全符合，Kafka将从<strong>最旧</strong>的片段开始清理，等待下一次再清理剩余的部分</li>
</ol>
<img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-clean-log-before-after.png" width=400/>


<h4 id="删除事件"><a href="#删除事件" class="headerlink" title="删除事件"></a>删除事件</h4><ol>
<li>为了<strong>彻底</strong>把一个键从系统里删除，客户端必须发送一个包含该键且<strong>值为null</strong>的消息</li>
<li>清理线程发现该消息时，会先进行常规的清理，只保留值为null的消息</li>
<li>该消息（<strong>墓碑消息</strong>）会被保留一段时间（可配置）<ul>
<li>在这期间，消费者可以看到这个墓碑消息，并且发现它的值已经被删除了</li>
<li>这段时间过后，清理线程会移除这个墓碑信息，这个键也将从Kafka分区里消失</li>
<li>重要的是要留给消费者足够多的时间，让它们能够看到墓碑消息</li>
</ul>
</li>
</ol>
<!-- indicate-the-source -->
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top">zhongmingmao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top/2019/03/26/kafka-internal-principle/">https://blog.zhongmingmao.top/2019/03/26/kafka-internal-principle/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/middleware/">Middleware</a><a class="post-meta__tags" href="/tags/mq/">MQ</a><a class="post-meta__tags" href="/tags/kafka/">Kafka</a><a class="post-meta__tags" href="/tags/stream/">Stream</a></div><div class="post-share"><div class="social-share" data-image="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-9.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2019/03/31/kafka-reliability/" title="Kafka -- 可靠性"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-23.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Kafka -- 可靠性</div></div><div class="info-2"><div class="info-item-1">可靠性保证 可靠性保证：确保系统在各种不同的环境下能够发生一致的行为 Kafka的保证 保证_分区消息的顺序_ 如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入 那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B   只有当消息被写入分区的所有同步副本时（文件系统缓存），它才被认为是已提交 生产者可以选择接收不同类型的确认，控制参数acks   只要还有一个副本是活跃的，那么已提交的消息就不会丢失 消费者只能读取已经提交的消息      复制 Kafka可靠性保证的核心：_复制机制_ + 分区的多副本架构 把消息写入多个副本，可以使Kafka在发生崩溃时仍能保证消息的持久性 Kafka的主题被分成多个分区，分区是基本的数据块，分区存储在单个磁盘上 Kafka可以保证分区里的事件总是有序的，分区可以在线（可用），也可以离线（不可用） 每个分区可以有多个副本，其中一个副本是首领副本 所有的事件都直接发送给首领副本，或者直接从首领副本读取事件 其他副本只需要与首领副本保持同步，并及时复制最新的事件即可 当首领副本不可用时，其中一个同步副本将成为新的...</div></div></div></a><a class="pagination-related" href="/2019/03/26/kafka-docker-schema-registry/" title="Kafka -- Docker + Schema Registry"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-1.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Kafka -- Docker + Schema Registry</div></div><div class="info-2"><div class="info-item-1">Avro Avro的数据文件里包含了整个Schema 如果每条Kafka记录都嵌入了Schema，会让记录的大小成倍地增加 在读取记录时，仍然需要读到整个Schema，所以需要先找到Schema 可以采用通用的结构模式并使用Schema注册表的方案 开源的Schema注册表实现：Confluent Schema Registry      Confluent Schema Registry   把所有写入数据需要用到的Schema保存在注册表里，然后在_记录里引用Schema ID_ 负责读数据的应用程序使用Schema ID从注册表拉取Schema来反序列化记录 序列化器和反序列化器分别负责处理Schema的注册和拉取  Confluent Schema Registry1234567891011121314151617181920# Start Zookeeper and expose port 2181 for use by the host machine$ docker run -d --name zookeeper -p 2181:2181 confluent/zookeeper# Star...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2019/09/30/kafka-tuning/" title="Kafka -- 调优"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-16.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-30</div><div class="info-item-2">Kafka -- 调优</div></div><div class="info-2"><div class="info-item-1">调优目标 主要目标：高吞吐量、低延时 吞吐量 即TPS，指的是Broker端进程或Client端应用程序每秒能处理的字节数或消息数   延时，可以有两种理解 从Producer发送消息到Broker持久化完成之间的时间间隔 端到端的延时，即从Producer发送消息到Consumer成功消费该消息的总时长      优化漏斗优化漏斗是调优过程中的分层漏斗，层级越靠上，调优的效果越明显 操作系统层 mount -o noatime 在挂载文件系统时禁用atime（Access Time）更新，记录的是文件最后被访问的时间 记录atime需要操作系统访问inode资源，禁用atime可以避免inode访问时间的写入操作   文件系统选择ext4、XFS、ZFS 将swappiness设置成一个很小的值（1~10，默认是60），防止Linux的OOM Killer开启随机杀掉进程 swappiness&#x3D;0，并不会禁止对swap的使用，只是最大限度地降低使用swap的可能性 因为一旦设置为0，当物理内存耗尽时，操作系统会触发OOM Killer OOM Killer会随机挑选一个进程然后kill掉，不...</div></div></div></a><a class="pagination-related" href="/2019/09/29/kafka-monitor/" title="Kafka -- 监控"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-14.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-29</div><div class="info-item-2">Kafka -- 监控</div></div><div class="info-2"><div class="info-item-1">主机监控 主机监控：监控Kafka集群Broker所在的节点机器的性能 常见的主机监控指标 机器负载 CPU使用率 内存使用率，包括空闲内存和已使用内存 磁盘IO使用率，包括读使用率和写使用率 网络IO使用率 TCP连接数 打开文件数 inode使用情况      JVM监控 重点指标 Full GC发生频率和时长 活跃对象大小 应用线程总数   设置堆大小 经历一次Full GC后，堆上存活的活跃对象大小为S，可以安全地将老年代堆大小设置为1.5S或者2S   从0.9.0.0版本开始，社区将默认的GC收集器设置为G1，而G1的Full GC是由单线程执行的，速度非常慢 一旦发现Broker进程频繁Full GC，可以开启G1的**-XX:+PrintAdaptiveSizePolicy，获知引发Full GC的原因**    集群监控 查看Broker进程是否启动，端口是否建立 在容器化的Kafka环境，容器虽然启动成功，但由于网络配置有误，会出现进程已经启动但端口未成功监听的情形   查看Broker端关键日志 Broker端服务器日志server.log – 最重要 控制器日志controlle...</div></div></div></a><a class="pagination-related" href="/2019/09/28/kafka-admin-client/" title="Kafka -- KafkaAdminClient"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-12.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-28</div><div class="info-item-2">Kafka -- KafkaAdminClient</div></div><div class="info-2"><div class="info-item-1">背景 命令行脚本只能运行在控制台上，在应用程序、运维框架或者监控平台中集成它们，会非常困难 很多命令行脚本都是通过连接ZK来提供服务的，这会存在潜在的问题，即绕过Kafka的安全设置 运行这些命令行脚本需要使用Kafka内部的类实现，也就是Kafka服务端的代码 社区是希望用户使用Kafka客户端代码，通过现有的请求机制来运维管理集群   基于上述原因，社区于0.11版本正式推出Java客户端版的KafkaAdminClient    功能 主题管理 主题的创建、删除、查询   权限管理 具体权限的配置和删除   配置参数管理 Kafka各种资源（Broker、主题、用户、Client-Id等）的参数设置、查询   副本日志管理 副本底层日志路径的变更和详情查询   分区管理 创建额外的主题分区   消息删除 删除指定位移之前的分区消息   Delegation Token管理 Delegation Token的创建、更新、过期、查询   消费者组管理 消费者组的查询、位移查询和删除   Preferred领导者选举 推选指定主题分区的Preferred Broker为领导者    工作原理   Kaf...</div></div></div></a><a class="pagination-related" href="/2019/09/27/kafka-shell/" title="Kafka -- 常用脚本"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-6.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-27</div><div class="info-item-2">Kafka -- 常用脚本</div></div><div class="info-2"><div class="info-item-1">脚本列表12345678connect-distributed              kafka-consumer-perf-test         kafka-reassign-partitions        kafka-verifiable-producerconnect-standalone               kafka-delegation-tokens          kafka-replica-verification       trogdorkafka-acls                       kafka-delete-records             kafka-run-class                  zookeeper-security-migrationkafka-broker-api-versions        kafka-dump-log                   kafka-server-start               zookeeper-server-startkafka-configs      ...</div></div></div></a><a class="pagination-related" href="/2019/09/26/kafka-reset-consumer-group-offset/" title="Kafka -- 重设消费者组位移"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-18.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-26</div><div class="info-item-2">Kafka -- 重设消费者组位移</div></div><div class="info-2"><div class="info-item-1">背景 Kafka和传统的消息引擎在设计上有很大的区别，Kafka消费者读取消息是可以重演的 像RabbitMQ和ActiveMQ等传统消息中间件，处理和响应消息的方式是破坏性 一旦消息被成功处理，就会从Broker上被删除   Kafka是基于日志结构（Log-based）的消息引擎 消费者在消费消息时，仅仅是从磁盘文件中读取数据而已，是只读操作，因为消费者不会删除消息数据 同时，由于位移数据是由消费者控制的，因此能够很容易地修改位移值，实现重复消费历史数据的功能   Kafka Or 传统消息中间件 传统消息中间件：消息处理逻辑非常复杂，处理代价高、又不关心消息之间的顺序 Kafka：需要较高的吞吐量、但每条消息的处理时间很短，又关心消息的顺序      重设位移策略 位移维度 直接把消费者的位移值重设成给定的位移值   时间维度 给定一个时间，让消费者把位移调整成大于该时间的最小位移       维度 策略 含义    位移维度 Earliest 把位移调整到当前最早位移处    Latest 把位移调整到当前最新位移处    Current 把位移调整到当前最新提交位移处    Specified...</div></div></div></a><a class="pagination-related" href="/2019/09/25/kafka-dynamic-config/" title="Kafka -- 动态配置"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-19.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-25</div><div class="info-item-2">Kafka -- 动态配置</div></div><div class="info-2"><div class="info-item-1">背景 Kafka安装目录的config路径下，有server.properties文件 通常情况下，会指定server.properties来启动Broker 如果要设置Broker端的任何参数，必须要显式修改server.properties，然后重启Broker，让参数生效 但在生产环境，不能随意重启Broker，因此需要能够动态修改Broker端参数   社区于1.1.0正式引入了动态Broker参数 动态指的是修改参数后，无需重启Broker就能立即生效，而之前server.properties中配置的参数称为静态参数   并非所有Broker端参数都可以动态调整的，官方文档中有Dynamic Update Mode一列 read-only 与原来的参数行为一样，只有重启Broker，才能令修改生效   per-broker 动态参数，修改之后，只会在对应的Broker上生效   cluster-wide 动态参数，修改之后，会在整个集群范围内生效        使用场景 动态调整Broker端各种线程池大小，实时应对突发流量 – 比较常用 动态调整Broker端连接信息或安全配置信息 动态更新...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">zhongmingmao</div><div class="author-info-description">Focus on Infrastructure.</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">639</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="mailto:zhongmingmao0625@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Things are always unexpected!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BE%A4%E7%BB%84%E6%88%90%E5%91%98%E5%85%B3%E7%B3%BB"><span class="toc-number">1.</span> <span class="toc-text">群组成员关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E5%99%A8"><span class="toc-number">2.</span> <span class="toc-text">控制器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6"><span class="toc-number">3.</span> <span class="toc-text">复制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%AF%E6%9C%AC%E7%B1%BB%E5%9E%8B"><span class="toc-number">3.1.</span> <span class="toc-text">副本类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A6%96%E9%A2%86%E5%89%AF%E6%9C%AC"><span class="toc-number">3.1.1.</span> <span class="toc-text">首领副本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B7%9F%E9%9A%8F%E8%80%85%E5%89%AF%E6%9C%AC"><span class="toc-number">3.1.2.</span> <span class="toc-text">跟随者副本</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A6%96%E9%80%89%E9%A6%96%E9%A2%86"><span class="toc-number">3.2.</span> <span class="toc-text">首选首领</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E8%AF%B7%E6%B1%82"><span class="toc-number">4.</span> <span class="toc-text">处理请求</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">4.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%AF%B7%E6%B1%82"><span class="toc-number">4.2.</span> <span class="toc-text">生产请求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E8%AF%B7%E6%B1%82"><span class="toc-number">4.3.</span> <span class="toc-text">获取请求</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%B6%E5%A4%8D%E5%88%B6"><span class="toc-number">4.3.1.</span> <span class="toc-text">零复制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E6%B0%B4%E4%BD%8D"><span class="toc-number">4.3.2.</span> <span class="toc-text">高水位</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%83%E6%95%B0%E6%8D%AE%E8%AF%B7%E6%B1%82"><span class="toc-number">4.4.</span> <span class="toc-text">元数据请求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E8%AF%B7%E6%B1%82"><span class="toc-number">4.5.</span> <span class="toc-text">其他请求</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%A9%E7%90%86%E5%AD%98%E5%82%A8"><span class="toc-number">5.</span> <span class="toc-text">物理存储</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D"><span class="toc-number">5.1.</span> <span class="toc-text">分区分配</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Broker%E9%97%B4%E5%88%86%E9%85%8D%E5%88%86%E5%8C%BA"><span class="toc-number">5.1.1.</span> <span class="toc-text">Broker间分配分区</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Broker%E5%86%85%E5%88%86%E9%85%8D%E5%88%86%E5%8C%BA"><span class="toc-number">5.1.2.</span> <span class="toc-text">Broker内分配分区</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">5.1.3.</span> <span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86"><span class="toc-number">5.2.</span> <span class="toc-text">文件管理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F"><span class="toc-number">5.3.</span> <span class="toc-text">文件格式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E5%8E%8B%E7%BC%A9"><span class="toc-number">5.3.1.</span> <span class="toc-text">消息压缩</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95"><span class="toc-number">5.4.</span> <span class="toc-text">索引</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B8%85%E7%90%86"><span class="toc-number">5.5.</span> <span class="toc-text">清理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">5.5.1.</span> <span class="toc-text">工作原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E4%BA%8B%E4%BB%B6"><span class="toc-number">5.5.2.</span> <span class="toc-text">删除事件</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java-agent.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java Zero Code"/></a><div class="content"><a class="title" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code">Observability - OpenTelemetry Java Zero Code</a><time datetime="2025-01-20T16:06:25.000Z" title="Created 2025-01-21 00:06:25">2025-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java"/></a><div class="content"><a class="title" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java">Observability - OpenTelemetry Java</a><time datetime="2025-01-19T16:06:25.000Z" title="Created 2025-01-20 00:06:25">2025-01-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/19/ai-agent-overview-mcp/" title="AI Agent - MCP Overview"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/mcp.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AI Agent - MCP Overview"/></a><div class="content"><a class="title" href="/2025/01/19/ai-agent-overview-mcp/" title="AI Agent - MCP Overview">AI Agent - MCP Overview</a><time datetime="2025-01-18T16:06:25.000Z" title="Created 2025-01-19 00:06:25">2025-01-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/18/ai-agent-overview/" title="AI Agent - Overview"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/ai-agent.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AI Agent - Overview"/></a><div class="content"><a class="title" href="/2025/01/18/ai-agent-overview/" title="AI Agent - Overview">AI Agent - Overview</a><time datetime="2025-01-17T16:06:25.000Z" title="Created 2025-01-18 00:06:25">2025-01-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/17/new-java-feature-foreign-function-api/" title="New Java Feature - Foreign Function API"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://java-feature-1253868755.cos.ap-guangzhou.myqcloud.com/Java-Foreign-Function-API.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="New Java Feature - Foreign Function API"/></a><div class="content"><a class="title" href="/2025/01/17/new-java-feature-foreign-function-api/" title="New Java Feature - Foreign Function API">New Java Feature - Foreign Function API</a><time datetime="2025-01-16T16:06:25.000Z" title="Created 2025-01-17 00:06:25">2025-01-17</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2015 - 2025 By zhongmingmao</span></div><div class="footer_custom_text">Life is like a box of chocolates. You can't know what you'll eat until you open it.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional and Simplified Chinese">繁</button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script></div></body></html>