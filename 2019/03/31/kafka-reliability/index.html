<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Kafka -- 可靠性 | ByteCoding</title><meta name="author" content="zhongmingmao"><meta name="copyright" content="zhongmingmao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="可靠性保证 可靠性保证：确保系统在各种不同的环境下能够发生一致的行为 Kafka的保证 保证_分区消息的顺序_ 如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入 那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B   只有当消息被写入分区的所有同步副本时（文件系统缓存），它才被认为是已提交 生产者可以选择接收不同类型的确认，控制参数ac">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka -- 可靠性">
<meta property="og:url" content="https://blog.zhongmingmao.top/2019/03/31/kafka-reliability/index.html">
<meta property="og:site_name" content="ByteCoding">
<meta property="og:description" content="可靠性保证 可靠性保证：确保系统在各种不同的环境下能够发生一致的行为 Kafka的保证 保证_分区消息的顺序_ 如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入 那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B   只有当消息被写入分区的所有同步副本时（文件系统缓存），它才被认为是已提交 生产者可以选择接收不同类型的确认，控制参数ac">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-20.png">
<meta property="article:published_time" content="2019-03-31T07:17:47.000Z">
<meta property="article:modified_time" content="2023-04-03T10:04:59.593Z">
<meta property="article:author" content="zhongmingmao">
<meta property="article:tag" content="Middleware">
<meta property="article:tag" content="MQ">
<meta property="article:tag" content="Kafka">
<meta property="article:tag" content="Stream">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-20.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Kafka -- 可靠性",
  "url": "https://blog.zhongmingmao.top/2019/03/31/kafka-reliability/",
  "image": "https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-20.png",
  "datePublished": "2019-03-31T07:17:47.000Z",
  "dateModified": "2023-04-03T10:04:59.593Z",
  "author": [
    {
      "@type": "Person",
      "name": "zhongmingmao",
      "url": "https://blog.zhongmingmao.top"
    }
  ]
}</script><link rel="shortcut icon" href="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png"><link rel="canonical" href="https://blog.zhongmingmao.top/2019/03/31/kafka-reliability/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":32,"languages":{"author":"Author: zhongmingmao","link":"Link: ","source":"Source: ByteCoding","info":"Copyright belongs to the author. For commercial use, please contact the author for authorization. For non-commercial use, please indicate the source."}},
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Kafka -- 可靠性',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="ByteCoding" type="application/atom+xml">
</head><body><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js/themes/blue/pace-theme-minimal.min.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg" style="background-image: url(/url(https:/cdn.pixabay.com/photo/2021/07/20/03/39/fisherman-6479663_1280.jpg));"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">642</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-20.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">ByteCoding</span></a><a class="nav-page-title" href="/"><span class="site-name">Kafka -- 可靠性</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Kafka -- 可靠性</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">Created</span><time datetime="2019-03-31T07:17:47.000Z" title="Created 2019-03-31 15:17:47">2019-03-31</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/middleware/">Middleware</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/middleware/mq/">MQ</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/middleware/mq/kafka/">Kafka</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">5.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>15mins</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:512,&quot;messagePrev&quot;:&quot;It has been&quot;,&quot;messageNext&quot;:&quot;days since the last update, the content of the article may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2023-04-03 18:04:59&quot;}" hidden></div><h2 id="可靠性保证"><a href="#可靠性保证" class="headerlink" title="可靠性保证"></a>可靠性保证</h2><ol>
<li>可靠性保证：确保系统在<strong>各种不同的环境</strong>下能够发生<strong>一致</strong>的行为</li>
<li>Kafka的保证<ul>
<li>保证_<strong>分区消息的顺序</strong>_<ul>
<li>如果使用<strong>同一个生产者</strong>往<strong>同一个分区</strong>写入消息，而且消息B在消息A之后写入</li>
<li>那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B</li>
</ul>
</li>
<li>只有当消息被写入分区的<strong>所有同步副本</strong>时（文件系统缓存），它才被认为是<strong>已提交</strong><ul>
<li>生产者可以选择接收不同类型的确认，控制参数<code>acks</code></li>
</ul>
</li>
<li>只要还有一个副本是活跃的，那么<strong>已提交的消息就不会丢失</strong></li>
<li><em><strong>消费者只能读取已经提交的消息</strong></em></li>
</ul>
</li>
</ol>
<span id="more"></span>

<h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h2><ol>
<li>Kafka可靠性保证的核心：_<strong>复制机制</strong>_ + <em><strong>分区的多副本架构</strong></em></li>
<li>把消息写入<strong>多个副本</strong>，可以使Kafka在发生<strong>崩溃</strong>时仍能<strong>保证消息的持久性</strong></li>
<li>Kafka的主题被分成多个分区，分区是基本的数据块，分区存储在<strong>单个磁盘</strong>上</li>
<li>Kafka可以保证分区里的事件总是<strong>有序</strong>的，分区可以<strong>在线</strong>（可用），也可以<strong>离线</strong>（不可用）</li>
<li>每个分区可以有多个副本，其中一个副本是首领副本<ul>
<li>所有的事件都直接发送给首领副本，或者直接从首领副本读取事件</li>
<li>其他副本只需要与首领副本<strong>保持同步</strong>，并<strong>及时复制最新的事件</strong>即可</li>
<li>当首领副本不可用时，其中一个<strong>同步副本</strong>将成为新的首领</li>
</ul>
</li>
<li>_<strong>分区首领是同步副本</strong>_，对于跟随者副本来说，需要满足下列的<strong>全部条件</strong>才被认为是<strong>同步</strong>的<ul>
<li>与<strong>ZooKeeper</strong>之间有一个<strong>活跃的会话</strong>（6S内的心跳）</li>
<li>在过去的10S内从首领副本那里获取过<strong>最新的消息</strong>（几乎<strong>零延迟</strong>）</li>
</ul>
</li>
<li>一个不同步的副本通过与ZooKeeper重新建立连接，并从首领副本那里获取最新的消息，可以重新变成同步的<ul>
<li>这个过程在网络出现临时问题时很快就能得到修复，但如果Broker发生崩溃就需要较长的时间</li>
</ul>
</li>
<li>如果一个或多个副本在<strong>同步</strong>和<strong>非同步</strong>状态之间_<strong>快速切换</strong>_<ul>
<li>说明集群内部出现了问题，通常是由于Java不恰当的<strong>垃圾回收配置</strong>导致的</li>
<li>不恰当的垃圾回收配置会造成几秒钟的停顿，从而导致Broker和ZooKeeper之间断开连接</li>
<li>最后变成不同步，进而发生状态切换</li>
</ul>
</li>
<li>一个<strong>滞后的同步副本</strong>会导致生产者和消费者<strong>变慢</strong><ul>
<li>因为消息在被认为<strong>已提交</strong>之前，客户端会等待<strong>所有同步副本</strong>接收消息</li>
<li>如果一个副本不再同步了，那么我们将不再关心它是否已经接收到消息<ul>
<li>因此，_<strong>非同步副本不会对性能造成任何影响</strong>_</li>
<li>但更少的同步副本意味着<strong>更低的有效复制系数</strong>，在发生宕机时<strong>丢失数据</strong>的风险就会变大</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Broker配置"><a href="#Broker配置" class="headerlink" title="Broker配置"></a>Broker配置</h2><p>Broker有3个配置参数会影响到Kafka消息存储的<strong>可靠性</strong>，可以应用于<strong>Broker级别</strong>（所有主题），也可以应用于<strong>主题级别</strong></p>
<h3 id="复制系数"><a href="#复制系数" class="headerlink" title="复制系数"></a>复制系数</h3><ol>
<li>主题级别的配置参数为<code>replication.factor</code>，Broker级别的配置参数为<code>default.replication.factor</code></li>
<li>Kafka的默认复制系数为3，即使在主题创建后，仍然可以通过<strong>新增</strong>或<strong>移除</strong>副本来改变复制系数</li>
<li>如果复制系数为<code>N</code>，那么在<code>N-1</code>个Broker<strong>失效</strong>的情况下，仍然能够从主题<strong>读取</strong>数据或向主题<strong>写入</strong>数据<ul>
<li>更高的复制系数可以带来_<strong>更高的可用性、可靠性和更少的故障</strong>_</li>
<li>但会占用_<strong>更多的磁盘空间</strong>_</li>
</ul>
</li>
<li>主题的<strong>复制系数</strong>与主题的<strong>重要程度</strong>成<strong>正相关</strong><ul>
<li>在要求<strong>可用性</strong>的场景下，把复制系数设置为<strong>3</strong>，已经<strong>足够安全</strong>了，银行可能会使用5个副本</li>
</ul>
</li>
<li>副本的<strong>分布</strong>也很重要<ul>
<li>Kafka会确保分区的每个副本被放在<strong>不同</strong>的Broker上</li>
<li>同时，为了避免<strong>机架级别</strong>的故障，建议把Broker分布在不同的机架上，控制参数为<code>broker.rack</code></li>
</ul>
</li>
</ol>
<h3 id="不完全的首领选举"><a href="#不完全的首领选举" class="headerlink" title="不完全的首领选举"></a>不完全的首领选举</h3><ol>
<li><code>unclean.leader.election.enable</code>只能在<strong>Broker级别</strong>进行设置，默认值为false</li>
<li>当分区首领不可用时，一个<strong>同步副本</strong>会被选为新的分区首领<ul>
<li>如果<strong>选举过程中没有丢失数据</strong>，即提交到旧首领的数据同时存在于所有的同步副本上，那么这个选举过程是<strong>完全</strong>的</li>
</ul>
</li>
<li>在首领不可用时，其他副本<strong>都不同步</strong>的场景<ul>
<li>分区有3个副本，其中两个跟随者<strong>不可用</strong>，这时如果生产者继续往首领写入数据，所有消息都会得到确认并被提交<ul>
<li>因为首领是<strong>唯一同步</strong>的副本</li>
<li>如果首领也不可用了，恰巧之前的一个跟随者重新启动，该跟随者就成为分区的唯一不同步副本</li>
</ul>
</li>
<li>分区有3个副本，因为网络问题导致两个跟随者<strong>复制消息滞后</strong>，尽管它们还在复制消息，但已经<strong>不同步</strong>了<ul>
<li>首领作为<strong>唯一同步</strong>的副本继续接收消息</li>
<li>如果首领变为不可用，另外两个副本再也无法变成同步的了</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="两难选择"><a href="#两难选择" class="headerlink" title="两难选择"></a>两难选择</h4><ol>
<li>如果不同步的副本<strong>不能</strong>被提升为新首领，那么分区在旧首领恢复之前是<strong>不可用</strong>的，牺牲了可用性</li>
<li>如果不同步的副本<strong>可以</strong>被提升为新首领，那么这个副本变为不同步之后写入旧首领的消息会全部消失，导致<strong>数据不一致</strong><ul>
<li>假设在副本0和副本1不可用时，偏移量100~200的消息被写入副本2（首领）</li>
<li>现在副本2也变为不可用，而副本0变成了可用，副本0只包含0~100的消息，不包含偏移量100~200的消息</li>
<li>如果允许副本0成为新首领，生产者可以继续写入数据，消费者可以继续读取数据，保证了可用性<ul>
<li>于是，新首领（副本0）就有了偏移量100~200的新消息</li>
</ul>
</li>
<li>但是，部分消费者会读到100~200的<strong>旧消息</strong>，部分消费者会读到为100~200的<strong>新消息</strong>，部分消费者读到<strong>两者的混合</strong></li>
</ul>
</li>
<li>小结<ul>
<li>如果<strong>不允许</strong>不同步的副本成为新首领，那么就要接受<strong>较低的可用性</strong></li>
<li>如果<strong>允许</strong>不同步的副本成为新首领，就要承担<strong>丢失数据</strong>和出现<strong>数据不一致</strong>的风险</li>
</ul>
</li>
</ol>
<h3 id="最少同步副本"><a href="#最少同步副本" class="headerlink" title="最少同步副本"></a>最少同步副本</h3><ol>
<li><code>min.insync.replicas</code>，可以在<strong>主题级别</strong>和<strong>Broker级别</strong>上进行配置</li>
<li>尽管为一个主题配置了3个副本，但还是会出现<strong>只有一个同步副本</strong>的情况</li>
<li>Kafka对<strong>可靠性保证</strong>的定义：消息只有被写入到<strong>所有同步副本</strong>之后才被认为是<strong>已提交</strong>的<ul>
<li>如果<strong>所有同步副本</strong>只剩下一个，那么在这个副本变为<strong>不可用</strong>时，数据就会<strong>丢失</strong></li>
</ul>
</li>
<li>如果<code>min.insync.replicas=2</code>，那么_<strong>至少要存在两个同步副本才能向分区写入数据</strong>_<ul>
<li>如果只有一个同步副本，那么Broker就会停止接受生产者的请求</li>
<li>此时Broker变成了<strong>只读</strong><ul>
<li>尝试发送数据的生产者会收到<code>NotEnoughReplicasException</code>异常</li>
<li>消费者仍然可以继续读取已有的数据</li>
</ul>
</li>
<li>这是为了避免发生<strong>不完全选举</strong>时数据的写入和读取出现非预期的行为</li>
</ul>
</li>
</ol>
<h2 id="在可靠的系统里使用生产者"><a href="#在可靠的系统里使用生产者" class="headerlink" title="在可靠的系统里使用生产者"></a>在可靠的系统里使用生产者</h2><h3 id="反例"><a href="#反例" class="headerlink" title="反例"></a>反例</h3><h4 id="反例1"><a href="#反例1" class="headerlink" title="反例1"></a>反例1</h4><ol>
<li>为Broker配置了<strong>3个副本</strong>，并且禁用了<strong>不完全首领选举</strong></li>
<li>把生产者的<code>acks</code>设置为<code>1</code>（只要首领接收到消息就可以认为消息写入成功）</li>
<li>生产者发送一个消息给首领，首领成功写入，但跟随者副本还没有收到这个消息</li>
<li>首领向生产者发送一个响应，告诉生产者消息写入成功，然后首领崩溃了，此时消息还没有被其他副本复制过去<ul>
<li>此时另外两个副本<strong>仍然</strong>被认为是<strong>同步</strong>的（判断一个副本不同步需要一小段时间）</li>
<li>其中一个副本成为了新的首领，因为消息还没有被写入这个副本，所以消息<strong>丢失</strong>了<ul>
<li>但<strong>生产者</strong>却认为消息已经<strong>成功写入</strong>了</li>
</ul>
</li>
</ul>
</li>
<li>因为<strong>消费者</strong>看不到丢失的消息，所以此时的系统仍然是<strong>一致</strong>的（因为副本没有收到这个消息，所以消息不算已提交）<ul>
<li>但从生产者角度来看，它丢失了一个消息</li>
</ul>
</li>
</ol>
<h4 id="反例2"><a href="#反例2" class="headerlink" title="反例2"></a>反例2</h4><ol>
<li>为Broker配置了<strong>3个副本</strong>，禁用了<strong>不完全首领选举</strong>，并且把生产者的<code>acks</code>设置为<code>all</code></li>
<li>假设现在往Kafka发送给消息，分区的首领刚好崩溃，新的首领正在选举当中，Kafka会往生产者返回<strong>首领不可用</strong>的响应</li>
<li>此时，如果生产者没能正确处理这个错误，也没有重试发送消息直到发送成功，那么消息也有可能<strong>丢失</strong></li>
<li>但这不能算是Broker的可靠性问题，因为Broker并没有收到这个消息</li>
<li>也不是一致性问题，因为消费者并没有读到这个消息</li>
</ol>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ol>
<li>根据<strong>可靠性需求</strong>配置恰当的<code>acks</code>值</li>
<li>在参数配置和代码里正确地处理错误</li>
</ol>
<h3 id="发送确认"><a href="#发送确认" class="headerlink" title="发送确认"></a>发送确认</h3><ol>
<li><code>acks=0</code>：如果生产者能够通过网络把消息发送出去，那么就认为消息已经成功写入Kafka<ul>
<li>如果<strong>分区离线</strong>或者<strong>整个集群长时间不可用</strong>，那么就<strong>不会收到任何错误</strong></li>
<li>即使在完全首领选举的情况下，仍有可能丢失消息，因为在新首领选举过程中，生产者并不知道首领已经不可用了</li>
<li>在该模式下，运行速度是非常快的，可以得到惊人的<strong>吞吐量</strong>和<strong>带宽利用率</strong>，但会<strong>丢失</strong>一些数据</li>
</ul>
</li>
<li><code>acks=1</code>：首领在收到消息并把它写入到分区数据文件（Linux文件系统缓存）时返回确认或错误响应<ul>
<li>在该模式下，如果发生正常的首领选举，生产者会在选举时收到<code>LeaderNotAvailableException</code>异常</li>
<li>如果生产者能够恰当地处理该异常，那么它就会重试发送消息，最终消息会安全到达新首领</li>
<li>但仍有可能<strong>丢失</strong>数据，例如消息已经成功写入首领，但在消息被复制到跟随者副本之前首领发生崩溃</li>
</ul>
</li>
<li><code>acks=all</code>：首领在返回确认或者错误响应之前，会等待<strong>所有同步副本</strong>都收到消息<ul>
<li>如果和<code>min.insync.replicas</code>结合，就能决定在返回确认前至少有多少个副本能够收到消息</li>
<li>这是<strong>最保险</strong>的做法，生产者会<strong>一直重试</strong>直到消息被成功提交</li>
<li>但这也是<strong>最慢</strong>的做法，生产者在继续发送其他消息之前需要等待<strong>所有副本</strong>都收到当前的消息</li>
<li>可以通过使用<strong>异步模式</strong>和<strong>更大的批次</strong>来<strong>加快速度</strong>，但这样通常会<strong>降低吞吐量</strong></li>
</ul>
</li>
</ol>
<h3 id="重试配置"><a href="#重试配置" class="headerlink" title="重试配置"></a>重试配置</h3><ol>
<li>生产者向Broker发送消息时，Broker可以返回一个<strong>成功响应码</strong>或者一个<strong>错误响应码</strong></li>
<li>错误响应码分类：一种是可以通过重试解决，一种是无法通过重试解决<ul>
<li>如果Broker返回的是<code>LeaderNotAvailableException</code>，生产者可以通过尝试重新发送消息来解决</li>
<li>如果Broker返回的是<code>InvalidConfigurationException</code>，即使通过重试也无法改变配置选项</li>
</ul>
</li>
<li>如果目标是<strong>不丢失任何消息</strong>，最好让生产者遇到<strong>可重试错误</strong>时能够_<strong>保持重试</strong>_</li>
<li>重试发送一个已经失败的消息会带来一些风险，如果两个消息都写入成功，会导致_<strong>消息重复</strong>_<ul>
<li>重试和恰当的错误处理可以保证每个消息<strong>至少被保存一次</strong></li>
<li>目前的Kafka版本无法保证每个消息只被保存一次</li>
<li>现实中的很多应用程序在消息里加入<strong>唯一标识符</strong>，用于<strong>检测重复消息</strong></li>
<li>另外还需要应用程序可以做到消息的<strong>幂等</strong></li>
</ul>
</li>
</ol>
<h2 id="在可靠的系统里使用消费者"><a href="#在可靠的系统里使用消费者" class="headerlink" title="在可靠的系统里使用消费者"></a>在可靠的系统里使用消费者</h2><ol>
<li>只有被提交到Kafka（已经被写入所有同步副本）的消息，对消费者才是可用的<ul>
<li>对消费者而言，读取到的消息已经具备了<strong>一致性</strong></li>
<li>消费者唯一要做的是要跟踪哪些消息已经读取过，哪些没有被读取过</li>
</ul>
</li>
<li>从分区读取数据时，消费者会获取一批事件，检查这批事件里<strong>最大的偏移量</strong>，然后从这个偏移量开始读取另一批事件<ul>
<li>这样保证消费者总能以<strong>正确的顺序</strong>获取新数据，不会错过任何事件</li>
</ul>
</li>
<li>如果一个消费者退出，另一个消费者需要知道前一个消费者在<strong>退出前</strong>处理的<strong>最后一个偏移量</strong>是多少<ul>
<li>因此消费者需要提交偏移量</li>
</ul>
</li>
<li>消费者把当前读取的偏移量保存起来，在退出之后，同一个群组里的其他消费者就可以接手它的工作<ul>
<li>如果消费者提交了偏移量却未能处理完消息，那么就可能会造成_<strong>消息丢失</strong>_</li>
</ul>
</li>
<li>已提交消息 VS 已提交偏移量<ul>
<li>已提交消息：已经被写入<strong>所有同步副本</strong>并且对消费者可见的消息</li>
<li>已提交偏移量：消费者发送给Kafka的偏移量，用于确认它已经<strong>收到并处理好</strong>的消息位置</li>
</ul>
</li>
</ol>
<h3 id="消费者的可靠性配置"><a href="#消费者的可靠性配置" class="headerlink" title="消费者的可靠性配置"></a>消费者的可靠性配置</h3><ol>
<li>group.id<ul>
<li>如果两个消费者具有相同的<code>group.id</code>，并且订阅了<strong>同一个主题</strong>，那么每个消费者会分到主题分区的一个_<strong>子集</strong>_</li>
</ul>
</li>
<li>auto.offset.reset<ul>
<li>指定了在<strong>没有偏移量可提交</strong>时或者<strong>请求的偏移量在Broker不存在</strong>时，消费者的行为</li>
<li><code>earliest</code>：消费者会从分区的开始位置读取数据，不管偏移量是否有效<ul>
<li>导致消费者读取大量的<strong>重复</strong>数据，但可以保证最少的数据丢失</li>
</ul>
</li>
<li><code>latest</code>：消费者会从分区的末尾开始读取数据<ul>
<li>可以减少重复处理消息，也有可能会错过一些消息</li>
</ul>
</li>
</ul>
</li>
<li>enable.auto.commit<ul>
<li>消费者基于任务调度自动提交偏移量</li>
<li>如果消费者在轮询操作里处理完所有的数据，那么自动提交可以保证_<strong>只提交已经处理过的偏移量</strong>_</li>
<li>自动提交的主要缺点<ul>
<li>无法控制<strong>重复处理消息</strong>（比如消费者在自动提交偏移量之前停止处理消息）</li>
<li>如果把消息交给另一个后台线程去处理，自动提交机制可能会在消息还没处理完毕就提交偏移量</li>
</ul>
</li>
</ul>
</li>
<li>auto.commit.interval.ms<ul>
<li>默认是每5S提交一次，频繁提交会增加额外的开销，但也会降低重复处理消息的概率</li>
</ul>
</li>
</ol>
<h3 id="显式提交偏移量"><a href="#显式提交偏移量" class="headerlink" title="显式提交偏移量"></a>显式提交偏移量</h3><ol>
<li><strong>总是在处理完事件后再提交偏移量</strong><ul>
<li>如果所有的处理都在<strong>轮询里</strong>完成，并且不需要在<strong>轮询之间</strong>维护状态（例如为了实现聚合操作）</li>
<li>那么可以使用自动提交，或者在轮询结束后进行手动提交</li>
</ul>
</li>
<li>提交频率是<strong>性能</strong>和<strong>重复消息</strong>之间的权衡<ul>
<li>即使在最简单的场景里，仍然可以在一个循环里多次提交偏移量</li>
<li>也可以在每处理完一个事件之后，或者多个循环里只提交一次</li>
</ul>
</li>
<li>确保对提交的偏移量心里有数<ul>
<li>在轮询过程中提交偏移量有个不好的地方<ul>
<li>就是提交的偏移量有可能是读取到的最新偏移量，而不是处理过的最新偏移量</li>
</ul>
</li>
<li>因此，必须确保<strong>处理完消息后再提交偏移量</strong>，否则会导致消费者错过消息</li>
</ul>
</li>
<li>再均衡<ul>
<li>在设计应用程序时要注意处理消费者的再均衡问题</li>
<li>例如，一般要在分区被撤销之前提交偏移量，并在分配到新分区时清理之前的状态</li>
</ul>
</li>
<li>消费者可能需要<strong>重试</strong><ul>
<li>场景：在进行轮询之后，有些消息没有被<strong>完全处理</strong>，需要稍候再来处理<ul>
<li>例如要把Kafka的数据写到数据库里，不过在那个时间数据库恰好不可用，需要稍候再试</li>
</ul>
</li>
<li><em><strong>提交的是偏移量，而不是对消息的确认</strong></em><ul>
<li>如果记录#30处理失败，但记录#31处理成功，那么就不应该提交#31</li>
<li>否则会导致#31以内的偏移量都被提交，包括#30</li>
</ul>
</li>
<li>解决方案<ul>
<li>方案1<ul>
<li>在遇到可重试错误时，提交最后一个处理成功的偏移量，然后把还没有处理好的消息保存到缓存区里</li>
<li>调用消费者的<code>pause()</code>方法来确保其他的轮询不会返回数据，_<strong>在保持轮询的同时尝试重新处理</strong>_</li>
<li>如果重试成功，或者重试次数达到上限并决定放弃，那么把错误记录下来并丢弃消息</li>
<li>然后调用<code>resume()</code>方法让消费者继续从轮询里获取新数据</li>
</ul>
</li>
<li>方案2<ul>
<li>在遇到可重试错误时，把错误写入一个独立的主题，然后继续</li>
<li>一个独立的消费者群组负责从该主题上读取错误消息，并进行重试</li>
<li>该模式有点类似其他消息系统的<code>dead-letter-queue</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>消费者可能需要维护状态<ul>
<li>有时会希望在多个轮询之间维护状态<ul>
<li>例如想计算消息的移动平均数，希望在首次轮询之后计算平均数，然后在后续的轮询中更新这个结果</li>
</ul>
</li>
<li>提交偏移量的同时把最近计算的平均数写到一个结果的主题上</li>
<li>消费者线程在重新启动之后，就可以拿到最近的平均事并接着计算</li>
<li>由于Kafka并没有提供<strong>事务支持</strong>，消费者有可能写入平均数之后来不及提交偏移量就崩溃了</li>
</ul>
</li>
<li>长时间处理<ul>
<li>有时候处理数据需要很长时间</li>
<li>但是暂停轮询的时间不能超过几秒钟，即使不想获得更多的数据，也要<strong>保持轮询</strong>，这样客户端才能往Broker发送<strong>心跳</strong></li>
<li>解决方案<ul>
<li>使用一个线程池来处理数据，使用多个线程可以进行并行处理，从而加快处理速度</li>
<li>把数据移交给线程池去处理之后，就可以暂停消费者，然后<strong>保持轮询</strong>，但<strong>不获取新数据</strong>，直到处理完成</li>
<li>在工作线程处理完成之后，让消费者继续获取新数据</li>
<li><em><strong>消费者一直保持轮询，心跳会正常发送，就不会发生再均衡</strong></em></li>
</ul>
</li>
</ul>
</li>
<li>仅一次传递<ul>
<li>应用程序不仅仅需要<strong>至少一次</strong>（<code>at-least-once</code>，没有数据丢失）语义，还需要<strong>仅一次</strong>（<code>exactly-once</code>）语义</li>
<li>目前Kafka还不能完全支持仅一次语义，消费者采用其他办法来保证Kafka里的每个消息只被写到外部系统一次<ul>
<li>但不会处理向Kafka<strong>写入数据</strong>时可能出现的重复数据</li>
</ul>
</li>
<li>实现<strong>仅一次</strong>处理最简单且最常用的办法是把结果写到一个支持<strong>唯一键</strong>的系统里，比如键值存储引擎，关系型数据库等<ul>
<li>这种情况下<ul>
<li>要么<strong>消息本身</strong>包含一个唯一键</li>
<li>要么使用<strong>主题、分区和偏移量</strong>的组合来创建唯一键（唯一标识一个Kafka记录）</li>
</ul>
</li>
<li>如果你把消息和一个唯一键写入系统，然后恰巧又读到一个相同的消息，只要把原先的键值覆盖掉即可</li>
<li>数据存储引擎会<strong>覆盖</strong>已经存在的键值对，就像没有出现过重复数据一样，这个模式叫作_<strong>幂等性写入</strong>_</li>
</ul>
</li>
<li>如果写入消息的系统<strong>支持事务</strong><ul>
<li>最简单的是使用关系型数据库，把<strong>消息</strong>和<strong>偏移量</strong>放到<strong>同一个事务</strong>里，这样它们就能保持<strong>同步</strong></li>
<li>在消费者启动时，会获取最近处理过的消息偏移量，然后调用<code>seek()</code>方法从该偏移量继续读取数据</li>
</ul>
</li>
</ul>
</li>
</ol>
<!-- indicate-the-source -->
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top">zhongmingmao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top/2019/03/31/kafka-reliability/">https://blog.zhongmingmao.top/2019/03/31/kafka-reliability/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/middleware/">Middleware</a><a class="post-meta__tags" href="/tags/mq/">MQ</a><a class="post-meta__tags" href="/tags/kafka/">Kafka</a><a class="post-meta__tags" href="/tags/stream/">Stream</a></div><div class="post-share"><div class="social-share" data-image="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-20.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2019/04/10/java-concurrent-overview/" title="Java并发 -- 概述"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-24.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Java并发 -- 概述</div></div><div class="info-2"><div class="info-item-1">核心问题分工 JUC中的Executor、Fork/Join和Future本质上都是一种分工方法 并发编程领域还总结了一些设计模式，基本上都是和分工方法相关 生产者-消费者 Thread-Per-Message Worker Thread      同步 在并发编程领域里的同步，主要指的就是_线程间的协作_ 一个线程执行完了一个任务，如何通知执行后续任务的线程开始工作   协作一般是与分工相关的 JUC中的Executor、Fork/Join和Future本质上都是一种分工方法 但同时也能解决线程协作的问题   例如，用Future可以发起一个异步调用 当主线程调用get()方法取结果时，主线程会等待 当异步执行的结果返回时，get()方法就自动返回了 Future工具类已经帮我们解决了_主线程和异步线程之间的协作_   JUC中的CountDownLatch、CyclicBarrier、Phaser和Exchanger都是用来解决线程协作问题的 但很多场景还是需要自己处理线程之间的协作，问题基本可以描述为 当某个条件不满足时，线程需要等待，当某个条件满足时，线程需要被唤醒执行   在Java并发编程领...</div></div></div></a><a class="pagination-related" href="/2019/03/26/kafka-internal-principle/" title="Kafka -- 内部原理"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-7.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Kafka -- 内部原理</div></div><div class="info-2"><div class="info-item-1">群组成员关系 Kakfa使用ZooKeeper来维护集群成员的信息 每个Broker都有一个唯一的ID，这个ID可以在配置文件里面指定，也可以自动生成 在Broker启动的时候，通过创建临时节点把自己的ID注册到ZooKeeper Kakfa组件订阅ZooKeeper的/brokers/ids路径，当有Broker加入集群或者退出集群时，Kafka组件能获得通知 如果要启动另一个具有相同ID的Broker，会得到一个错误，这个Broker会尝试进行注册，但会失败 在Broker停机，出现网络分区或者长时间垃圾回收停顿时，Broker会从ZooKeeper上_断开连接_ 此时，Broker在启动时创建的临时节点会从ZooKeeper上自动移除（ZooKeeper特性） 订阅Broker列表的Kafka组件会被告知该Broker已经被移除   在关闭Broker时，它对应的临时节点也会消失，不过它的ID会继续存在于其他数据结构中 例如，主题的副本列表里可能会包含这些ID   在完全关闭了一个Broker之后，如果使用相同的ID启动另一个全新的Broker 该Broker会立即加入集群，并拥有与旧Broker...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2019/09/30/kafka-tuning/" title="Kafka -- 调优"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-6.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-30</div><div class="info-item-2">Kafka -- 调优</div></div><div class="info-2"><div class="info-item-1">调优目标 主要目标：高吞吐量、低延时 吞吐量 即TPS，指的是Broker端进程或Client端应用程序每秒能处理的字节数或消息数   延时，可以有两种理解 从Producer发送消息到Broker持久化完成之间的时间间隔 端到端的延时，即从Producer发送消息到Consumer成功消费该消息的总时长      优化漏斗优化漏斗是调优过程中的分层漏斗，层级越靠上，调优的效果越明显 操作系统层 mount -o noatime 在挂载文件系统时禁用atime（Access Time）更新，记录的是文件最后被访问的时间 记录atime需要操作系统访问inode资源，禁用atime可以避免inode访问时间的写入操作   文件系统选择ext4、XFS、ZFS 将swappiness设置成一个很小的值（1~10，默认是60），防止Linux的OOM Killer开启随机杀掉进程 swappiness&#x3D;0，并不会禁止对swap的使用，只是最大限度地降低使用swap的可能性 因为一旦设置为0，当物理内存耗尽时，操作系统会触发OOM Killer OOM Killer会随机挑选一个进程然后kill掉，不...</div></div></div></a><a class="pagination-related" href="/2019/09/29/kafka-monitor/" title="Kafka -- 监控"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-4.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-29</div><div class="info-item-2">Kafka -- 监控</div></div><div class="info-2"><div class="info-item-1">主机监控 主机监控：监控Kafka集群Broker所在的节点机器的性能 常见的主机监控指标 机器负载 CPU使用率 内存使用率，包括空闲内存和已使用内存 磁盘IO使用率，包括读使用率和写使用率 网络IO使用率 TCP连接数 打开文件数 inode使用情况      JVM监控 重点指标 Full GC发生频率和时长 活跃对象大小 应用线程总数   设置堆大小 经历一次Full GC后，堆上存活的活跃对象大小为S，可以安全地将老年代堆大小设置为1.5S或者2S   从0.9.0.0版本开始，社区将默认的GC收集器设置为G1，而G1的Full GC是由单线程执行的，速度非常慢 一旦发现Broker进程频繁Full GC，可以开启G1的**-XX:+PrintAdaptiveSizePolicy，获知引发Full GC的原因**    集群监控 查看Broker进程是否启动，端口是否建立 在容器化的Kafka环境，容器虽然启动成功，但由于网络配置有误，会出现进程已经启动但端口未成功监听的情形   查看Broker端关键日志 Broker端服务器日志server.log – 最重要 控制器日志controlle...</div></div></div></a><a class="pagination-related" href="/2019/09/28/kafka-admin-client/" title="Kafka -- KafkaAdminClient"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-13.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-28</div><div class="info-item-2">Kafka -- KafkaAdminClient</div></div><div class="info-2"><div class="info-item-1">背景 命令行脚本只能运行在控制台上，在应用程序、运维框架或者监控平台中集成它们，会非常困难 很多命令行脚本都是通过连接ZK来提供服务的，这会存在潜在的问题，即绕过Kafka的安全设置 运行这些命令行脚本需要使用Kafka内部的类实现，也就是Kafka服务端的代码 社区是希望用户使用Kafka客户端代码，通过现有的请求机制来运维管理集群   基于上述原因，社区于0.11版本正式推出Java客户端版的KafkaAdminClient    功能 主题管理 主题的创建、删除、查询   权限管理 具体权限的配置和删除   配置参数管理 Kafka各种资源（Broker、主题、用户、Client-Id等）的参数设置、查询   副本日志管理 副本底层日志路径的变更和详情查询   分区管理 创建额外的主题分区   消息删除 删除指定位移之前的分区消息   Delegation Token管理 Delegation Token的创建、更新、过期、查询   消费者组管理 消费者组的查询、位移查询和删除   Preferred领导者选举 推选指定主题分区的Preferred Broker为领导者    工作原理   Kaf...</div></div></div></a><a class="pagination-related" href="/2019/09/27/kafka-shell/" title="Kafka -- 常用脚本"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-18.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-27</div><div class="info-item-2">Kafka -- 常用脚本</div></div><div class="info-2"><div class="info-item-1">脚本列表12345678connect-distributed              kafka-consumer-perf-test         kafka-reassign-partitions        kafka-verifiable-producerconnect-standalone               kafka-delegation-tokens          kafka-replica-verification       trogdorkafka-acls                       kafka-delete-records             kafka-run-class                  zookeeper-security-migrationkafka-broker-api-versions        kafka-dump-log                   kafka-server-start               zookeeper-server-startkafka-configs      ...</div></div></div></a><a class="pagination-related" href="/2019/09/26/kafka-reset-consumer-group-offset/" title="Kafka -- 重设消费者组位移"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-2.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-26</div><div class="info-item-2">Kafka -- 重设消费者组位移</div></div><div class="info-2"><div class="info-item-1">背景 Kafka和传统的消息引擎在设计上有很大的区别，Kafka消费者读取消息是可以重演的 像RabbitMQ和ActiveMQ等传统消息中间件，处理和响应消息的方式是破坏性 一旦消息被成功处理，就会从Broker上被删除   Kafka是基于日志结构（Log-based）的消息引擎 消费者在消费消息时，仅仅是从磁盘文件中读取数据而已，是只读操作，因为消费者不会删除消息数据 同时，由于位移数据是由消费者控制的，因此能够很容易地修改位移值，实现重复消费历史数据的功能   Kafka Or 传统消息中间件 传统消息中间件：消息处理逻辑非常复杂，处理代价高、又不关心消息之间的顺序 Kafka：需要较高的吞吐量、但每条消息的处理时间很短，又关心消息的顺序      重设位移策略 位移维度 直接把消费者的位移值重设成给定的位移值   时间维度 给定一个时间，让消费者把位移调整成大于该时间的最小位移       维度 策略 含义    位移维度 Earliest 把位移调整到当前最早位移处    Latest 把位移调整到当前最新位移处    Current 把位移调整到当前最新提交位移处    Specified...</div></div></div></a><a class="pagination-related" href="/2019/09/25/kafka-dynamic-config/" title="Kafka -- 动态配置"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/go-20.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-25</div><div class="info-item-2">Kafka -- 动态配置</div></div><div class="info-2"><div class="info-item-1">背景 Kafka安装目录的config路径下，有server.properties文件 通常情况下，会指定server.properties来启动Broker 如果要设置Broker端的任何参数，必须要显式修改server.properties，然后重启Broker，让参数生效 但在生产环境，不能随意重启Broker，因此需要能够动态修改Broker端参数   社区于1.1.0正式引入了动态Broker参数 动态指的是修改参数后，无需重启Broker就能立即生效，而之前server.properties中配置的参数称为静态参数   并非所有Broker端参数都可以动态调整的，官方文档中有Dynamic Update Mode一列 read-only 与原来的参数行为一样，只有重启Broker，才能令修改生效   per-broker 动态参数，修改之后，只会在对应的Broker上生效   cluster-wide 动态参数，修改之后，会在整个集群范围内生效        使用场景 动态调整Broker端各种线程池大小，实时应对突发流量 – 比较常用 动态调整Broker端连接信息或安全配置信息 动态更新...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">zhongmingmao</div><div class="author-info-description">Focus on Infrastructure.</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">642</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="mailto:zhongmingmao0625@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Things are always unexpected!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81"><span class="toc-number">1.</span> <span class="toc-text">可靠性保证</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6"><span class="toc-number">2.</span> <span class="toc-text">复制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Broker%E9%85%8D%E7%BD%AE"><span class="toc-number">3.</span> <span class="toc-text">Broker配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6%E7%B3%BB%E6%95%B0"><span class="toc-number">3.1.</span> <span class="toc-text">复制系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E5%AE%8C%E5%85%A8%E7%9A%84%E9%A6%96%E9%A2%86%E9%80%89%E4%B8%BE"><span class="toc-number">3.2.</span> <span class="toc-text">不完全的首领选举</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%A4%E9%9A%BE%E9%80%89%E6%8B%A9"><span class="toc-number">3.2.1.</span> <span class="toc-text">两难选择</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%B0%91%E5%90%8C%E6%AD%A5%E5%89%AF%E6%9C%AC"><span class="toc-number">3.3.</span> <span class="toc-text">最少同步副本</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E5%8F%AF%E9%9D%A0%E7%9A%84%E7%B3%BB%E7%BB%9F%E9%87%8C%E4%BD%BF%E7%94%A8%E7%94%9F%E4%BA%A7%E8%80%85"><span class="toc-number">4.</span> <span class="toc-text">在可靠的系统里使用生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%8D%E4%BE%8B"><span class="toc-number">4.1.</span> <span class="toc-text">反例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%8D%E4%BE%8B1"><span class="toc-number">4.1.1.</span> <span class="toc-text">反例1</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%8D%E4%BE%8B2"><span class="toc-number">4.1.2.</span> <span class="toc-text">反例2</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">4.1.3.</span> <span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E7%A1%AE%E8%AE%A4"><span class="toc-number">4.2.</span> <span class="toc-text">发送确认</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E8%AF%95%E9%85%8D%E7%BD%AE"><span class="toc-number">4.3.</span> <span class="toc-text">重试配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E5%8F%AF%E9%9D%A0%E7%9A%84%E7%B3%BB%E7%BB%9F%E9%87%8C%E4%BD%BF%E7%94%A8%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-number">5.</span> <span class="toc-text">在可靠的系统里使用消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E9%85%8D%E7%BD%AE"><span class="toc-number">5.1.</span> <span class="toc-text">消费者的可靠性配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%BE%E5%BC%8F%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F"><span class="toc-number">5.2.</span> <span class="toc-text">显式提交偏移量</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/01/24/cloud-native-observability-prometheus-server-v1/" title="Observability - Prometheus Server V1"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/prometheus-server.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - Prometheus Server V1"/></a><div class="content"><a class="title" href="/2025/01/24/cloud-native-observability-prometheus-server-v1/" title="Observability - Prometheus Server V1">Observability - Prometheus Server V1</a><time datetime="2025-01-23T16:06:25.000Z" title="Created 2025-01-24 00:06:25">2025-01-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/23/cloud-native-observability-prometheus-concepts/" title="Observability - Prometheus Concepts"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/prometheus-concepts.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - Prometheus Concepts"/></a><div class="content"><a class="title" href="/2025/01/23/cloud-native-observability-prometheus-concepts/" title="Observability - Prometheus Concepts">Observability - Prometheus Concepts</a><time datetime="2025-01-22T16:06:25.000Z" title="Created 2025-01-23 00:06:25">2025-01-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/22/cloud-native-observability-prometheus-introduction/" title="Observability - Prometheus Introduction"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/prometheus.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - Prometheus Introduction"/></a><div class="content"><a class="title" href="/2025/01/22/cloud-native-observability-prometheus-introduction/" title="Observability - Prometheus Introduction">Observability - Prometheus Introduction</a><time datetime="2025-01-21T16:06:25.000Z" title="Created 2025-01-22 00:06:25">2025-01-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java-agent.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java Zero Code"/></a><div class="content"><a class="title" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code">Observability - OpenTelemetry Java Zero Code</a><time datetime="2025-01-20T16:06:25.000Z" title="Created 2025-01-21 00:06:25">2025-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java"/></a><div class="content"><a class="title" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java">Observability - OpenTelemetry Java</a><time datetime="2025-01-19T16:06:25.000Z" title="Created 2025-01-20 00:06:25">2025-01-20</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2015 - 2025 By zhongmingmao</span></div><div class="footer_custom_text">Life is like a box of chocolates. You can't know what you'll eat until you open it.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional and Simplified Chinese">繁</button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script></div></body></html>