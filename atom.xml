<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ByteCoding</title>
  
  
  <link href="https://blog.zhongmingmao.top/atom.xml" rel="self"/>
  
  <link href="https://blog.zhongmingmao.top/"/>
  <updated>2024-08-25T10:47:50.089Z</updated>
  <id>https://blog.zhongmingmao.top/</id>
  
  <author>
    <name>zhongmingmao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>LLM Core - Transformer</title>
    <link href="https://blog.zhongmingmao.top/2024/07/08/llm-core-transformer/"/>
    <id>https://blog.zhongmingmao.top/2024/07/08/llm-core-transformer/</id>
    <published>2024-07-07T16:06:25.000Z</published>
    <updated>2024-08-25T10:47:50.089Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;不论是 &lt;strong&gt;GRU&lt;/strong&gt; 还是 &lt;strong&gt;LSTM&lt;/strong&gt; 都面临&lt;strong&gt;梯度消失&lt;/strong&gt;和&lt;strong&gt;梯度爆炸&lt;/strong&gt;的问题&lt;/li&gt;
&lt;li&gt;RNN 必须&lt;strong&gt;按照顺序处理&lt;/strong&gt;序列中的每个元素，&lt;strong&gt;无法并发处理&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;RNN 还有&lt;strong&gt;长依赖&lt;/strong&gt;问题，虽然可以处理&lt;strong&gt;长序列&lt;/strong&gt;，但&lt;strong&gt;实战效果不佳&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Attention Is All You Need - &lt;a href=&quot;http://arxiv.org/pdf/1706.03762&quot;&gt;http://arxiv.org/pdf/1706.03762&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
    <category term="Seq2Seq" scheme="https://blog.zhongmingmao.top/tags/seq2seq/"/>
    
    <category term="Transformer" scheme="https://blog.zhongmingmao.top/tags/transformer/"/>
    
    <category term="Attention" scheme="https://blog.zhongmingmao.top/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>LLM Core - Seq2Seq</title>
    <link href="https://blog.zhongmingmao.top/2024/07/07/llm-core-seq2seq/"/>
    <id>https://blog.zhongmingmao.top/2024/07/07/llm-core-seq2seq/</id>
    <published>2024-07-06T16:06:25.000Z</published>
    <updated>2024-08-24T16:38:44.933Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;简单介绍&quot;&gt;&lt;a href=&quot;#简单介绍&quot; class=&quot;headerlink&quot; title=&quot;简单介绍&quot;&gt;&lt;/a&gt;简单介绍&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Word2Vec&lt;/strong&gt; 的主要能力是将&lt;strong&gt;词汇&lt;/strong&gt;放在&lt;strong&gt;多维空间&lt;/strong&gt;中，&lt;strong&gt;相似的词汇&lt;/strong&gt;会被放在&lt;strong&gt;邻近的位置&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Seq2Seq 不仅能&lt;strong&gt;理解词汇&lt;/strong&gt;，还能将词汇&lt;strong&gt;串联&lt;/strong&gt;成完整的&lt;strong&gt;句子&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Seq2Seq 即&lt;strong&gt;从一个序列到另一个序列的转换&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;不仅仅能&lt;strong&gt;理解单词之间的关系&lt;/strong&gt;，还能把整个句子的意思&lt;strong&gt;打包&lt;/strong&gt;，并&lt;strong&gt;解压&lt;/strong&gt;成另一种形式的表达&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Seq2Seq 的核心角色 - &lt;strong&gt;编码器&lt;/strong&gt;（Encoder） + &lt;strong&gt;解码器&lt;/strong&gt;（Decoder）&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Role&lt;/th&gt;
&lt;th&gt;Desc&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Encoder&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;理解和压缩信息&lt;/strong&gt; - 把一封长信函整理成一个精简的&lt;strong&gt;摘要&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Decoder&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;将&lt;strong&gt;摘要&lt;/strong&gt;打开，并翻译成另一种语言或形式的&lt;strong&gt;完整信息&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
    <category term="Seq2Seq" scheme="https://blog.zhongmingmao.top/tags/seq2seq/"/>
    
  </entry>
  
  <entry>
    <title>LLM Core - Word2Vec</title>
    <link href="https://blog.zhongmingmao.top/2024/07/06/llm-core-word2vec/"/>
    <id>https://blog.zhongmingmao.top/2024/07/06/llm-core-word2vec/</id>
    <published>2024-07-05T16:06:25.000Z</published>
    <updated>2024-08-24T09:43:10.720Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Word2Vec&quot;&gt;&lt;a href=&quot;#Word2Vec&quot; class=&quot;headerlink&quot; title=&quot;Word2Vec&quot;&gt;&lt;/a&gt;Word2Vec&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;在 &lt;strong&gt;NLP&lt;/strong&gt; 中，在&lt;strong&gt;文本预处理&lt;/strong&gt;后，进行&lt;strong&gt;特征提取&lt;/strong&gt;，涉及到将&lt;strong&gt;词语&lt;/strong&gt;转化成&lt;strong&gt;数值&lt;/strong&gt;的形式，&lt;strong&gt;方便计算机理解&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Word2Vec 的目的 - 将&lt;strong&gt;词语&lt;/strong&gt;转换成&lt;strong&gt;向量&lt;/strong&gt;形式，使得&lt;strong&gt;计算机&lt;/strong&gt;能够&lt;strong&gt;理解&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;通过学习&lt;strong&gt;大量文本数据&lt;/strong&gt;，捕捉到&lt;strong&gt;词语之间的上下文关系&lt;/strong&gt;，进而生成&lt;strong&gt;词的高维表示&lt;/strong&gt; - 即&lt;strong&gt;词向量&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
    <category term="Word2Vec" scheme="https://blog.zhongmingmao.top/tags/word2vec/"/>
    
  </entry>
  
  <entry>
    <title>LLM Core - NLP</title>
    <link href="https://blog.zhongmingmao.top/2024/07/05/llm-core-nlp/"/>
    <id>https://blog.zhongmingmao.top/2024/07/05/llm-core-nlp/</id>
    <published>2024-07-04T16:06:25.000Z</published>
    <updated>2024-08-22T06:02:09.742Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;基础&quot;&gt;&lt;a href=&quot;#基础&quot; class=&quot;headerlink&quot; title=&quot;基础&quot;&gt;&lt;/a&gt;基础&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;NLP 的研究目的是让计算机能够&lt;strong&gt;理解&lt;/strong&gt;、&lt;strong&gt;解释&lt;/strong&gt;和&lt;strong&gt;生成&lt;/strong&gt;人类语言，一般包含 4 个步骤&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Step&lt;/th&gt;
&lt;th&gt;Desc&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;文本预处理&lt;/td&gt;
&lt;td&gt;将&lt;strong&gt;原始文本&lt;/strong&gt;转换成&lt;strong&gt;机器容易理解&lt;/strong&gt;的格式&lt;br /&gt;&lt;strong&gt;分词&lt;/strong&gt;（单词或短语）、&lt;strong&gt;去除停用词&lt;/strong&gt;、&lt;strong&gt;词干提取&lt;/strong&gt;、&lt;strong&gt;词性标注&lt;/strong&gt;等&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;特征提取&lt;/td&gt;
&lt;td&gt;从处理过的文本中提取特征，以便用于机器学习模型&lt;br /&gt;将&lt;strong&gt;文本&lt;/strong&gt;转换成&lt;strong&gt;数值&lt;/strong&gt;形式 - &lt;strong&gt;向量化&lt;/strong&gt; - &lt;strong&gt;词袋模型&lt;/strong&gt; or &lt;strong&gt;&lt;u&gt;词嵌入&lt;/u&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;模型训练&lt;/td&gt;
&lt;td&gt;使用提取到的&lt;strong&gt;特征&lt;/strong&gt;和相应的&lt;strong&gt;机器学习算法&lt;/strong&gt;来训练模型&lt;br /&gt;分类器、回归模型、聚类算法等&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;评估与应用&lt;/td&gt;
&lt;td&gt;评估模型的&lt;strong&gt;性能&lt;/strong&gt;，并在实际应用中使用模型来&lt;strong&gt;解释&lt;/strong&gt;、&lt;strong&gt;生成&lt;/strong&gt;或&lt;strong&gt;翻译&lt;/strong&gt;文本&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;应用场景 - 搜索引擎 &amp;#x2F; 语音转换 &amp;#x2F; 文本翻译 &amp;#x2F; 系统问答&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
  </entry>
  
  <entry>
    <title>LLM Core - RNN</title>
    <link href="https://blog.zhongmingmao.top/2024/07/04/llm-core-rnn/"/>
    <id>https://blog.zhongmingmao.top/2024/07/04/llm-core-rnn/</id>
    <published>2024-07-03T16:06:25.000Z</published>
    <updated>2024-08-18T17:01:37.767Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;RNN 主要用来处理&lt;strong&gt;序列数据&lt;/strong&gt;，目前大部分 &lt;strong&gt;LLM&lt;/strong&gt; 都是基于 &lt;strong&gt;Transformer&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;通过学习 RNN，有助于理解 Transformer&lt;ul&gt;
&lt;li&gt;有助于理解&lt;strong&gt;神经网络&lt;/strong&gt;如何处理&lt;strong&gt;序列中的依赖关系&lt;/strong&gt;、&lt;strong&gt;记忆过去的信息&lt;/strong&gt;，并在此基础上&lt;strong&gt;生成预测&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;有助于理解关键问题 - &lt;strong&gt;梯度消失&lt;/strong&gt; &amp;#x2F; &lt;strong&gt;梯度爆炸&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
    <category term="Machine Learning" scheme="https://blog.zhongmingmao.top/tags/machine-learning/"/>
    
    <category term="RNN" scheme="https://blog.zhongmingmao.top/tags/rnn/"/>
    
  </entry>
  
  <entry>
    <title>LLM Core - Machine Learning Algorithm</title>
    <link href="https://blog.zhongmingmao.top/2024/07/03/llm-core-ml-algorithm/"/>
    <id>https://blog.zhongmingmao.top/2024/07/03/llm-core-ml-algorithm/</id>
    <published>2024-07-02T16:06:25.000Z</published>
    <updated>2024-08-18T12:39:46.686Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;线性回归&quot;&gt;&lt;a href=&quot;#线性回归&quot; class=&quot;headerlink&quot; title=&quot;线性回归&quot;&gt;&lt;/a&gt;线性回归&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;线性回归是一种&lt;strong&gt;预测分析&lt;/strong&gt;技术，用于研究两个或者多个变量之间的关系&lt;/li&gt;
&lt;li&gt;尝试用一条&lt;strong&gt;直线&lt;/strong&gt;（二维）或者一个&lt;strong&gt;平面&lt;/strong&gt;（三维）的去&lt;strong&gt;拟合&lt;/strong&gt;数据点&lt;/li&gt;
&lt;li&gt;这条&lt;strong&gt;直线&lt;/strong&gt;或者&lt;strong&gt;平面&lt;/strong&gt;，可以用来&lt;strong&gt;预测&lt;/strong&gt;或者估计一个变量基于另一个变量的值&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
    <category term="Machine Learning" scheme="https://blog.zhongmingmao.top/tags/machine-learning/"/>
    
    <category term="SVM" scheme="https://blog.zhongmingmao.top/tags/svm/"/>
    
  </entry>
  
  <entry>
    <title>LLM Core - Machine Learning Concept</title>
    <link href="https://blog.zhongmingmao.top/2024/07/02/llm-core-ml-concept/"/>
    <id>https://blog.zhongmingmao.top/2024/07/02/llm-core-ml-concept/</id>
    <published>2024-07-01T16:06:25.000Z</published>
    <updated>2024-08-18T02:07:14.895Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;机器学习&quot;&gt;&lt;a href=&quot;#机器学习&quot; class=&quot;headerlink&quot; title=&quot;机器学习&quot;&gt;&lt;/a&gt;机器学习&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;机器学习是让计算机&lt;strong&gt;利用数据&lt;/strong&gt;来&lt;strong&gt;学习&lt;/strong&gt;如何&lt;strong&gt;完成任务&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;机器学习允许计算机通过&lt;strong&gt;分析&lt;/strong&gt;和&lt;strong&gt;学习&lt;/strong&gt;数据来&lt;strong&gt;自我改进&lt;/strong&gt;以及&lt;strong&gt;作出决策&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
    <category term="Machine Learning" scheme="https://blog.zhongmingmao.top/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>LLM - API</title>
    <link href="https://blog.zhongmingmao.top/2024/07/01/llm-api/"/>
    <id>https://blog.zhongmingmao.top/2024/07/01/llm-api/</id>
    <published>2024-06-30T16:06:25.000Z</published>
    <updated>2024-08-17T14:08:28.541Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;LLM 是没有 &lt;strong&gt;Web API&lt;/strong&gt; 的，需要进行一次&lt;strong&gt;封装&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;将 LLM 的核心接口封装成 Web API 来为用户提供服务 - &lt;strong&gt;必经之路&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
    <category term="Python" scheme="https://blog.zhongmingmao.top/tags/python/"/>
    
    <category term="FastAPI" scheme="https://blog.zhongmingmao.top/tags/fastapi/"/>
    
    <category term="Uvicorn" scheme="https://blog.zhongmingmao.top/tags/uvicorn/"/>
    
  </entry>
  
  <entry>
    <title>LLM RAG - ChatGLM3-6B + LangChain + Faiss</title>
    <link href="https://blog.zhongmingmao.top/2024/06/30/llm-rag-chatglm3-6b-langchain-faiss/"/>
    <id>https://blog.zhongmingmao.top/2024/06/30/llm-rag-chatglm3-6b-langchain-faiss/</id>
    <published>2024-06-29T16:06:25.000Z</published>
    <updated>2024-08-17T10:09:12.128Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;RAG&quot;&gt;&lt;a href=&quot;#RAG&quot; class=&quot;headerlink&quot; title=&quot;RAG&quot;&gt;&lt;/a&gt;RAG&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;使用&lt;strong&gt;知识库&lt;/strong&gt;，用来增强 LLM &lt;strong&gt;信息检索&lt;/strong&gt;的能力&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;知识准确&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;先把&lt;strong&gt;知识&lt;/strong&gt;进行&lt;strong&gt;向量化&lt;/strong&gt;，存储到&lt;strong&gt;向量数据库&lt;/strong&gt;中&lt;/li&gt;
&lt;li&gt;使用的时候通过&lt;strong&gt;向量检索&lt;/strong&gt;从向量数据库中将知识检索出来，确保知识的准确性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;更新频率快&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;当发现知识库里面的&lt;strong&gt;知识不全&lt;/strong&gt;时，可以&lt;strong&gt;随时补充&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;不需要像&lt;strong&gt;微调&lt;/strong&gt;一样，重新跑&lt;strong&gt;微调&lt;/strong&gt;任务、&lt;strong&gt;验证&lt;/strong&gt;结果、重新&lt;strong&gt;部署&lt;/strong&gt;等&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
    <category term="LangChain" scheme="https://blog.zhongmingmao.top/tags/langchain/"/>
    
    <category term="AI Agent" scheme="https://blog.zhongmingmao.top/tags/ai-agent/"/>
    
    <category term="RAG" scheme="https://blog.zhongmingmao.top/tags/rag/"/>
    
    <category term="Faiss" scheme="https://blog.zhongmingmao.top/tags/faiss/"/>
    
  </entry>
  
  <entry>
    <title>LLM PEFT - ChatGLM3-6B + LoRA</title>
    <link href="https://blog.zhongmingmao.top/2024/06/29/llm-peft-chatglm3-6b-lora/"/>
    <id>https://blog.zhongmingmao.top/2024/06/29/llm-peft-chatglm3-6b-lora/</id>
    <published>2024-06-28T16:06:25.000Z</published>
    <updated>2024-08-16T17:08:30.135Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;通用-LLM&quot;&gt;&lt;a href=&quot;#通用-LLM&quot; class=&quot;headerlink&quot; title=&quot;通用 LLM&quot;&gt;&lt;/a&gt;通用 LLM&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;千亿大模型（130B、ChatGPT）和小规模的大模型（6B、LLaMA2）都是通用 LLM&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;通用 LLM&lt;/strong&gt; 都是通过&lt;strong&gt;常识&lt;/strong&gt;进行&lt;strong&gt;预训练&lt;/strong&gt;的&lt;/li&gt;
&lt;li&gt;在实际使用过程中，需要 LLM 具备某一特定&lt;strong&gt;领域知识&lt;/strong&gt;的能力 - 对 LLM 的能力进行&lt;strong&gt;增强&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
    <category term="LangChain" scheme="https://blog.zhongmingmao.top/tags/langchain/"/>
    
    <category term="AI Agent" scheme="https://blog.zhongmingmao.top/tags/ai-agent/"/>
    
    <category term="RAG" scheme="https://blog.zhongmingmao.top/tags/rag/"/>
    
    <category term="LoRA" scheme="https://blog.zhongmingmao.top/tags/lora/"/>
    
    <category term="PEFT" scheme="https://blog.zhongmingmao.top/tags/peft/"/>
    
  </entry>
  
  <entry>
    <title>LLM Deploy - ChatGLM3-6B</title>
    <link href="https://blog.zhongmingmao.top/2024/06/28/llm-deploy-chatglm3-6b/"/>
    <id>https://blog.zhongmingmao.top/2024/06/28/llm-deploy-chatglm3-6b/</id>
    <published>2024-06-27T16:06:25.000Z</published>
    <updated>2024-08-16T08:03:15.938Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;LLM-选择&quot;&gt;&lt;a href=&quot;#LLM-选择&quot; class=&quot;headerlink&quot; title=&quot;LLM 选择&quot;&gt;&lt;/a&gt;LLM 选择&lt;/h1&gt;&lt;h2 id=&quot;核心玩家&quot;&gt;&lt;a href=&quot;#核心玩家&quot; class=&quot;headerlink&quot; title=&quot;核心玩家&quot;&gt;&lt;/a&gt;核心玩家&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;厂家很多，但没多少真正在研究技术 - 成本 - 不少厂商是基于 &lt;strong&gt;LLaMA&lt;/strong&gt; 套壳&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240815080217105.png&quot; alt=&quot;image-20240815080217105&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
    <category term="LangChain" scheme="https://blog.zhongmingmao.top/tags/langchain/"/>
    
    <category term="AI Agent" scheme="https://blog.zhongmingmao.top/tags/ai-agent/"/>
    
    <category term="RAG" scheme="https://blog.zhongmingmao.top/tags/rag/"/>
    
  </entry>
  
  <entry>
    <title>LLM - LangChain + RAG</title>
    <link href="https://blog.zhongmingmao.top/2024/06/27/llm-langchain-rag/"/>
    <id>https://blog.zhongmingmao.top/2024/06/27/llm-langchain-rag/</id>
    <published>2024-06-26T16:06:25.000Z</published>
    <updated>2024-08-14T12:09:09.499Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;局限&quot;&gt;&lt;a href=&quot;#局限&quot; class=&quot;headerlink&quot; title=&quot;局限&quot;&gt;&lt;/a&gt;局限&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;大模型的核心能力 - &lt;strong&gt;意图理解&lt;/strong&gt; + &lt;strong&gt;文本生成&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;局限&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;数据的&lt;strong&gt;及时性&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;大部分 AI 大模型都是&lt;strong&gt;预训练&lt;/strong&gt;的，如果要问一些最新的消息，大模型是不知道的&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;复杂任务&lt;/strong&gt;处理&lt;/td&gt;
&lt;td&gt;AI 大模型在&lt;strong&gt;问答&lt;/strong&gt;方面表现出色，但不总是能够处理复杂任务&lt;br /&gt;AI 大模型主要是基于&lt;strong&gt;文本&lt;/strong&gt;的交互（&lt;strong&gt;多模态&lt;/strong&gt;除外）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;代码&lt;/strong&gt;生成与下载&lt;/td&gt;
&lt;td&gt;根据需求描述生成对应的代码，并提供下载链接 - 暂时不支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;与&lt;strong&gt;企业应用&lt;/strong&gt;场景的&lt;strong&gt;集成&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;读取关系型数据库里面的数据，并根据提示进行任务处理 - 暂时不支持&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;ol&gt;
&lt;li&gt;在实际应用过程中，输入数据和输出数据，不仅仅是纯文本&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI Agent&lt;/strong&gt; - 需要&lt;strong&gt;解析&lt;/strong&gt;用户的输入输出&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
    <category term="LangChain" scheme="https://blog.zhongmingmao.top/tags/langchain/"/>
    
    <category term="AI Agent" scheme="https://blog.zhongmingmao.top/tags/ai-agent/"/>
    
    <category term="RAG" scheme="https://blog.zhongmingmao.top/tags/rag/"/>
    
  </entry>
  
  <entry>
    <title>LLM - Prompt</title>
    <link href="https://blog.zhongmingmao.top/2024/06/26/llm-prompt/"/>
    <id>https://blog.zhongmingmao.top/2024/06/26/llm-prompt/</id>
    <published>2024-06-25T16:06:25.000Z</published>
    <updated>2024-08-08T04:24:39.420Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Prompt&quot;&gt;&lt;a href=&quot;#Prompt&quot; class=&quot;headerlink&quot; title=&quot;Prompt&quot;&gt;&lt;/a&gt;Prompt&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;是否充分使用好 AI 大模型，提示是关键&lt;/li&gt;
&lt;li&gt;OpenAI&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;question &amp;#x2F; answer&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;prompt &amp;#x2F; completion - 给 LLM 一个提示，让 LLM 进行补全&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&quot;3&quot;&gt;
&lt;li&gt;LLM 训练原理&lt;ul&gt;
&lt;li&gt;GPT 系列模型基于 &lt;code&gt;Transformer&lt;/code&gt; 架构的&lt;code&gt;解码器&lt;/code&gt;机制，使用&lt;code&gt;自回归无监督&lt;/code&gt;方式进行&lt;code&gt;预训练&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;训练过程 - &lt;code&gt;大量&lt;/code&gt;的文本输入，不断进行&lt;code&gt;记忆&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;相比于监督学习，&lt;code&gt;训练效率更低&lt;/code&gt;，但&lt;code&gt;训练过程简单&lt;/code&gt;，可以喂大量的文本语料，上限比较高&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;completion&lt;ul&gt;
&lt;li&gt;根据训练过的&lt;code&gt;记忆&lt;/code&gt;，一个字一个字地计算&lt;code&gt;概率&lt;/code&gt;，取&lt;code&gt;概率最大&lt;/code&gt;的那个字进行输出&lt;/li&gt;
&lt;li&gt;因此有人吐槽 LLM 输出很慢 - &lt;code&gt;逐字计算&lt;/code&gt;并输出&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="NLP" scheme="https://blog.zhongmingmao.top/tags/nlp/"/>
    
  </entry>
  
  <entry>
    <title>LLM - ChatGPT</title>
    <link href="https://blog.zhongmingmao.top/2024/06/25/llm-chatgpt/"/>
    <id>https://blog.zhongmingmao.top/2024/06/25/llm-chatgpt/</id>
    <published>2024-06-24T16:06:25.000Z</published>
    <updated>2024-08-08T04:24:31.047Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Timeline&quot;&gt;&lt;a href=&quot;#Timeline&quot; class=&quot;headerlink&quot; title=&quot;Timeline&quot;&gt;&lt;/a&gt;Timeline&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240715121726607.png&quot; alt=&quot;image-20240715121726607&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;OpenAI 在 &lt;code&gt;NLP&lt;/code&gt; 领域取得了突破性进展&lt;/li&gt;
&lt;li&gt;ChatGPT 背后包含了一系列的资源整合 - 技术、资源、大厂背书、国际巨头的通力合作 - 工程 + 产品&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/categories/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/categories/ai/llm/"/>
    
    
    <category term="AI" scheme="https://blog.zhongmingmao.top/tags/ai/"/>
    
    <category term="LLM" scheme="https://blog.zhongmingmao.top/tags/llm/"/>
    
    <category term="ChatGPT" scheme="https://blog.zhongmingmao.top/tags/chatgpt/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes - Helm Doc</title>
    <link href="https://blog.zhongmingmao.top/2023/05/11/cloud-native-foundation-k8s-helm-doc/"/>
    <id>https://blog.zhongmingmao.top/2023/05/11/cloud-native-foundation-k8s-helm-doc/</id>
    <published>2023-05-10T16:06:25.000Z</published>
    <updated>2024-07-07T07:40:13.319Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;Chart&lt;ul&gt;
&lt;li&gt;包含在 Kubernetes 集群内部运行的应用程序、工具和服务所需的&lt;code&gt;所有资源定义&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Repository&lt;ul&gt;
&lt;li&gt;用于存放和共享 Chart&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Release&lt;ul&gt;
&lt;li&gt;运行在 Kubernetes 集群中的 Chart 实例&lt;/li&gt;
&lt;li&gt;一个 Chart 可以在同一个集群中被安装多次，每次安装都会创建一个 Release&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/categories/cloud-native/"/>
    
    <category term="Cloud Native Foundation" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/"/>
    
    <category term="Kubernetes" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/kubernetes/"/>
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/tags/cloud-native/"/>
    
    <category term="Kubernetes" scheme="https://blog.zhongmingmao.top/tags/kubernetes/"/>
    
    <category term="Cloud Native Foundation" scheme="https://blog.zhongmingmao.top/tags/cloud-native-foundation/"/>
    
  </entry>
  
  <entry>
    <title>Go Engineering - CLI</title>
    <link href="https://blog.zhongmingmao.top/2023/05/10/cloud-native-foundation-go-engineering-cli/"/>
    <id>https://blog.zhongmingmao.top/2023/05/10/cloud-native-foundation-go-engineering-cli/</id>
    <published>2023-05-09T16:06:25.000Z</published>
    <updated>2024-06-17T13:40:02.314Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;应用框架&quot;&gt;&lt;a href=&quot;#应用框架&quot; class=&quot;headerlink&quot; title=&quot;应用框架&quot;&gt;&lt;/a&gt;应用框架&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;命令行参数解析 - &lt;code&gt;Pflag&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;配置文件解析 - &lt;code&gt;Viper&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;应用的命令行框架 - &lt;code&gt;Cobra&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;命令需要具备 help 功能&lt;/li&gt;
&lt;li&gt;命令需要能够解析命令行参数和配置文件&lt;/li&gt;
&lt;li&gt;命令需要能够初始化业务代码，并最终启动业务进程&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/categories/cloud-native/"/>
    
    <category term="Cloud Native Foundation" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/"/>
    
    <category term="Go Engineering" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/go-engineering/"/>
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/tags/cloud-native/"/>
    
    <category term="Go" scheme="https://blog.zhongmingmao.top/tags/go/"/>
    
    <category term="Go Engineering" scheme="https://blog.zhongmingmao.top/tags/go-engineering/"/>
    
  </entry>
  
  <entry>
    <title>Go Engineering - Log</title>
    <link href="https://blog.zhongmingmao.top/2023/05/09/cloud-native-foundation-go-engineering-log/"/>
    <id>https://blog.zhongmingmao.top/2023/05/09/cloud-native-foundation-go-engineering-log/</id>
    <published>2023-05-08T16:06:25.000Z</published>
    <updated>2024-06-10T17:03:57.035Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;功能设计&quot;&gt;&lt;a href=&quot;#功能设计&quot; class=&quot;headerlink&quot; title=&quot;功能设计&quot;&gt;&lt;/a&gt;功能设计&lt;/h1&gt;&lt;h2 id=&quot;基础功能&quot;&gt;&lt;a href=&quot;#基础功能&quot; class=&quot;headerlink&quot; title=&quot;基础功能&quot;&gt;&lt;/a&gt;基础功能&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;支持基本的日志信息 - 时间戳、文件名、行号、日志级别、日志信息&lt;/li&gt;
&lt;li&gt;支持不同的日志级别 - Debug &amp;#x2F; Info &amp;#x2F; Warn &amp;#x2F; Error &amp;#x2F; Panic &amp;#x2F; Fatal&lt;ul&gt;
&lt;li&gt;logrus 支持 Trace 日志级别，Trace 不是必须的&lt;/li&gt;
&lt;li&gt;Trace 和 Panic 是可选的级别&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;支持自定义配置 - 不同的环境采用不同的配置&lt;ul&gt;
&lt;li&gt;开发环境的日志级别为 Debug，而生产环境的日志级别为 Info&lt;/li&gt;
&lt;li&gt;通过配置，可以在&lt;code&gt;不重新编译代码&lt;/code&gt;的情况下，改变记录日志的行为&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;支持输出到标准输出和文件&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/categories/cloud-native/"/>
    
    <category term="Cloud Native Foundation" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/"/>
    
    <category term="Go Engineering" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/go-engineering/"/>
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/tags/cloud-native/"/>
    
    <category term="Go" scheme="https://blog.zhongmingmao.top/tags/go/"/>
    
    <category term="Go Engineering" scheme="https://blog.zhongmingmao.top/tags/go-engineering/"/>
    
  </entry>
  
  <entry>
    <title>Go Engineering - Error Code</title>
    <link href="https://blog.zhongmingmao.top/2023/05/08/cloud-native-foundation-go-engineering-err-code/"/>
    <id>https://blog.zhongmingmao.top/2023/05/08/cloud-native-foundation-go-engineering-err-code/</id>
    <published>2023-05-07T16:06:25.000Z</published>
    <updated>2024-06-10T10:33:44.783Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;预期功能&quot;&gt;&lt;a href=&quot;#预期功能&quot; class=&quot;headerlink&quot; title=&quot;预期功能&quot;&gt;&lt;/a&gt;预期功能&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;有业务 Code 码标识 - HTTP Code 码有限&lt;/li&gt;
&lt;li&gt;安全 - 对内对外展示不同的错误信息&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/categories/cloud-native/"/>
    
    <category term="Cloud Native Foundation" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/"/>
    
    <category term="Go Engineering" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/go-engineering/"/>
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/tags/cloud-native/"/>
    
    <category term="Go" scheme="https://blog.zhongmingmao.top/tags/go/"/>
    
    <category term="Go Engineering" scheme="https://blog.zhongmingmao.top/tags/go-engineering/"/>
    
  </entry>
  
  <entry>
    <title>Go Engineering - Doc</title>
    <link href="https://blog.zhongmingmao.top/2023/05/07/cloud-native-foundation-go-engineering-doc/"/>
    <id>https://blog.zhongmingmao.top/2023/05/07/cloud-native-foundation-go-engineering-doc/</id>
    <published>2023-05-06T16:06:25.000Z</published>
    <updated>2024-06-10T09:18:16.882Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Swagger&quot;&gt;&lt;a href=&quot;#Swagger&quot; class=&quot;headerlink&quot; title=&quot;Swagger&quot;&gt;&lt;/a&gt;Swagger&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Swagger 是一套围绕 OpenAPI 规范构建的开源工具&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Component&lt;/th&gt;
&lt;th&gt;Desc&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;Swagger Editor&lt;/td&gt;
&lt;td&gt;基于浏览器的编辑器，可以编写 OpenAPI 规范，并实时预览&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Swagger UI&lt;/td&gt;
&lt;td&gt;将 OpenAPI 规范呈现为交互式 API 文档&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Swagger Codegen&lt;/td&gt;
&lt;td&gt;根据 OpenAPI 规范，生成&lt;code&gt;服务器存根&lt;/code&gt;和&lt;code&gt;客户端代码库&lt;/code&gt;，涵盖 40 多种语言&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/categories/cloud-native/"/>
    
    <category term="Cloud Native Foundation" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/"/>
    
    <category term="Go Engineering" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/go-engineering/"/>
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/tags/cloud-native/"/>
    
    <category term="Go" scheme="https://blog.zhongmingmao.top/tags/go/"/>
    
    <category term="Go Engineering" scheme="https://blog.zhongmingmao.top/tags/go-engineering/"/>
    
    <category term="Swagger" scheme="https://blog.zhongmingmao.top/tags/swagger/"/>
    
  </entry>
  
  <entry>
    <title>Go Engineering - Lint</title>
    <link href="https://blog.zhongmingmao.top/2023/05/06/cloud-native-foundation-go-engineering-lint/"/>
    <id>https://blog.zhongmingmao.top/2023/05/06/cloud-native-foundation-go-engineering-lint/</id>
    <published>2023-05-05T16:06:25.000Z</published>
    <updated>2024-06-10T07:26:33.221Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;golangci-lint&quot;&gt;&lt;a href=&quot;#golangci-lint&quot; class=&quot;headerlink&quot; title=&quot;golangci-lint&quot;&gt;&lt;/a&gt;golangci-lint&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;使用最多&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/categories/cloud-native/"/>
    
    <category term="Cloud Native Foundation" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/"/>
    
    <category term="Go Engineering" scheme="https://blog.zhongmingmao.top/categories/cloud-native/cloud-native-foundation/go-engineering/"/>
    
    
    <category term="Cloud Native" scheme="https://blog.zhongmingmao.top/tags/cloud-native/"/>
    
    <category term="Go" scheme="https://blog.zhongmingmao.top/tags/go/"/>
    
    <category term="Go Engineering" scheme="https://blog.zhongmingmao.top/tags/go-engineering/"/>
    
    <category term="CI" scheme="https://blog.zhongmingmao.top/tags/ci/"/>
    
  </entry>
  
</feed>
