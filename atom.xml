<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ByteCoding</title>
  
  
  <link href="https://blog.zhongmingmao.top/atom.xml" rel="self"/>
  
  <link href="https://blog.zhongmingmao.top/"/>
  <updated>2024-11-21T15:03:38.690Z</updated>
  <id>https://blog.zhongmingmao.top/</id>
  
  <author>
    <name>zhongmingmao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Beam - Streaming</title>
    <link href="https://blog.zhongmingmao.top/2024/10/04/bigdata-beam-streaming/"/>
    <id>https://blog.zhongmingmao.top/2024/10/04/bigdata-beam-streaming/</id>
    <published>2024-10-03T16:06:25.000Z</published>
    <updated>2024-11-21T15:03:38.690Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;有界数据-vs-无界数据&quot;&gt;&lt;a href=&quot;#有界数据-vs-无界数据&quot; class=&quot;headerlink&quot; title=&quot;有界数据 vs 无界数据&quot;&gt;&lt;/a&gt;有界数据 vs 无界数据&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;在 Beam 中，可以用&lt;strong&gt;同一个 Pipeline&lt;/strong&gt; 处理&lt;strong&gt;有界数据&lt;/strong&gt;和&lt;strong&gt;无界数据&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;无论是&lt;strong&gt;有界数据&lt;/strong&gt;还是&lt;strong&gt;无界数据&lt;/strong&gt;，在 Beam 中，都可以用&lt;strong&gt;窗口&lt;/strong&gt;把数据按&lt;strong&gt;时间&lt;/strong&gt;分割成一些&lt;strong&gt;有限大小&lt;/strong&gt;的集合&lt;ul&gt;
&lt;li&gt;对于&lt;strong&gt;无界&lt;/strong&gt;数据，&lt;strong&gt;必须&lt;/strong&gt;使用&lt;strong&gt;窗口&lt;/strong&gt;对数据进行&lt;strong&gt;分割&lt;/strong&gt;，然后对每个窗口内的数据集进行处理&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Beam - Window</title>
    <link href="https://blog.zhongmingmao.top/2024/10/03/bigdata-beam-window/"/>
    <id>https://blog.zhongmingmao.top/2024/10/03/bigdata-beam-window/</id>
    <published>2024-10-02T16:06:25.000Z</published>
    <updated>2024-11-21T10:33:16.900Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Window&quot;&gt;&lt;a href=&quot;#Window&quot; class=&quot;headerlink&quot; title=&quot;Window&quot;&gt;&lt;/a&gt;Window&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;在 Beam 中，&lt;strong&gt;Window&lt;/strong&gt; 将 &lt;strong&gt;PCollection&lt;/strong&gt; 里的每个&lt;strong&gt;元素&lt;/strong&gt;根据&lt;strong&gt;时间戳&lt;/strong&gt;划分成不同的&lt;strong&gt;有限数据集合&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;要将一些&lt;strong&gt;聚合操作&lt;/strong&gt;应用在 PCollection 上时，或者对不同的 PCollection 进行 &lt;strong&gt;Join&lt;/strong&gt; 操作&lt;ul&gt;
&lt;li&gt;Beam 将这些操作应用在这些被 &lt;strong&gt;Window&lt;/strong&gt; 划分好的&lt;strong&gt;不同的数据集&lt;/strong&gt;上&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;无论是&lt;strong&gt;有界数据&lt;/strong&gt;还是&lt;strong&gt;无界数据&lt;/strong&gt;，Beam 都会按&lt;strong&gt;同样的规则&lt;/strong&gt;进行处理&lt;/li&gt;
&lt;li&gt;在用 &lt;strong&gt;IO Connector&lt;/strong&gt; 读取&lt;strong&gt;有界数据集&lt;/strong&gt;的过程中，&lt;strong&gt;Read Transform&lt;/strong&gt; 会默认为&lt;strong&gt;每个元素&lt;/strong&gt;分配一个&lt;strong&gt;相同的时间戳&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;一般情况下，该时间戳为&lt;strong&gt;运行 Pipeline 的时间&lt;/strong&gt;，即&lt;strong&gt;处理时间&lt;/strong&gt; - &lt;strong&gt;Processing Time&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Beam 会为该 Pipeline 默认分配一个&lt;strong&gt;全局窗口&lt;/strong&gt; - &lt;strong&gt;Global Window&lt;/strong&gt; - 从&lt;strong&gt;无限小&lt;/strong&gt;到&lt;strong&gt;无限大&lt;/strong&gt;的时间窗口&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Beam - WordCount</title>
    <link href="https://blog.zhongmingmao.top/2024/10/02/bigdata-beam-wordcount/"/>
    <id>https://blog.zhongmingmao.top/2024/10/02/bigdata-beam-wordcount/</id>
    <published>2024-10-01T16:06:25.000Z</published>
    <updated>2024-11-21T06:51:41.687Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;步骤&quot;&gt;&lt;a href=&quot;#步骤&quot; class=&quot;headerlink&quot; title=&quot;步骤&quot;&gt;&lt;/a&gt;步骤&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;用 &lt;strong&gt;Pipeline IO&lt;/strong&gt; 读取文本&lt;/li&gt;
&lt;li&gt;用 &lt;strong&gt;Transform&lt;/strong&gt; 对文本进行分词和词频统计&lt;/li&gt;
&lt;li&gt;用 &lt;strong&gt;Pipeline IO&lt;/strong&gt; 输出结果&lt;/li&gt;
&lt;li&gt;将所有步骤打包成一个 &lt;strong&gt;Pipeline&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Beam - Execution Engine</title>
    <link href="https://blog.zhongmingmao.top/2024/10/01/bigdata-beam-execution-engine/"/>
    <id>https://blog.zhongmingmao.top/2024/10/01/bigdata-beam-execution-engine/</id>
    <published>2024-09-30T16:06:25.000Z</published>
    <updated>2024-11-20T17:25:05.594Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Pipeline&quot;&gt;&lt;a href=&quot;#Pipeline&quot; class=&quot;headerlink&quot; title=&quot;Pipeline&quot;&gt;&lt;/a&gt;Pipeline&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;读取输入数据到 PCollection&lt;/li&gt;
&lt;li&gt;对读进来的 PCollection 进行 Transform，得到另一个 PCollection&lt;/li&gt;
&lt;li&gt;输出结果 PCollection&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Beam - Pipeline Test</title>
    <link href="https://blog.zhongmingmao.top/2024/09/30/bigdata-beam-pipeline-test/"/>
    <id>https://blog.zhongmingmao.top/2024/09/30/bigdata-beam-pipeline-test/</id>
    <published>2024-09-29T16:06:25.000Z</published>
    <updated>2024-11-20T16:09:44.206Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Context&quot;&gt;&lt;a href=&quot;#Context&quot; class=&quot;headerlink&quot; title=&quot;Context&quot;&gt;&lt;/a&gt;Context&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;设计好的 Pipeline 通常需要放在&lt;strong&gt;分布式环境&lt;/strong&gt;下执行，具体每一步的 &lt;strong&gt;Transform&lt;/strong&gt; 都会被分配到&lt;strong&gt;任意机器&lt;/strong&gt;上执行&lt;/li&gt;
&lt;li&gt;如果 Pipeline &lt;strong&gt;运行出错&lt;/strong&gt;，则需要定位到&lt;strong&gt;具体机器&lt;/strong&gt;，再到上面去做&lt;strong&gt;调试&lt;/strong&gt;是&lt;strong&gt;不现实&lt;/strong&gt;的&lt;/li&gt;
&lt;li&gt;另一种办法，读取一些&lt;strong&gt;样本数据集&lt;/strong&gt;，再运行整个 Pipeline 去验证哪一步逻辑出错 - &lt;strong&gt;费时费力&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;正式将 Pipeline 放在分布式环境上运行之前，需要先&lt;strong&gt;完整地测试整个 Pipeline 逻辑&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Beam - Pattern</title>
    <link href="https://blog.zhongmingmao.top/2024/09/29/bigdata-beam-pattern/"/>
    <id>https://blog.zhongmingmao.top/2024/09/29/bigdata-beam-pattern/</id>
    <published>2024-09-28T16:06:25.000Z</published>
    <updated>2024-11-20T15:12:07.718Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Copier-Pattern&quot;&gt;&lt;a href=&quot;#Copier-Pattern&quot; class=&quot;headerlink&quot; title=&quot;Copier Pattern&quot;&gt;&lt;/a&gt;Copier Pattern&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;每个&lt;strong&gt;数据处理模块&lt;/strong&gt;的&lt;strong&gt;输入&lt;/strong&gt;都是&lt;strong&gt;相同&lt;/strong&gt;的，并且每个&lt;strong&gt;数据处理模块&lt;/strong&gt;都可以&lt;strong&gt;单独&lt;/strong&gt;并且&lt;strong&gt;同步&lt;/strong&gt;地运行处理&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/b226e637e8cba5f7c3ef938684526373.webp&quot; alt=&quot;b226e637e8cba5f7c3ef938684526373&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Beam - Pipeline IO</title>
    <link href="https://blog.zhongmingmao.top/2024/09/28/bigdata-beam-pipeline-io/"/>
    <id>https://blog.zhongmingmao.top/2024/09/28/bigdata-beam-pipeline-io/</id>
    <published>2024-09-27T16:06:25.000Z</published>
    <updated>2024-11-20T11:58:50.237Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;读取数据集&quot;&gt;&lt;a href=&quot;#读取数据集&quot; class=&quot;headerlink&quot; title=&quot;读取数据集&quot;&gt;&lt;/a&gt;读取数据集&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;一个&lt;strong&gt;输入数据集&lt;/strong&gt;的&lt;strong&gt;读取&lt;/strong&gt;通常是通过 &lt;strong&gt;Read Transform&lt;/strong&gt; 来完成&lt;/li&gt;
&lt;li&gt;Read Transform 从&lt;strong&gt;外部源&lt;/strong&gt;读取数据 - 本地文件、数据库、OSS、MQ&lt;/li&gt;
&lt;li&gt;Read Transform 返回一个 &lt;strong&gt;PCollection&lt;/strong&gt;，该 PCollection 可以作为一个&lt;strong&gt;输入数据集&lt;/strong&gt;，应用在各种 &lt;strong&gt;Transform&lt;/strong&gt; 上&lt;/li&gt;
&lt;li&gt;Pipeline &lt;strong&gt;没有限制&lt;/strong&gt;调用 Read Transform 的&lt;strong&gt;时机&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;可以在 Pipeline 最开始的时候调用&lt;/li&gt;
&lt;li&gt;也可以在经过 N 个步骤的 Transforms 后再调用它来读取另外的数据集&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Beam - Pipeline</title>
    <link href="https://blog.zhongmingmao.top/2024/09/27/bigdata-beam-pipeline/"/>
    <id>https://blog.zhongmingmao.top/2024/09/27/bigdata-beam-pipeline/</id>
    <published>2024-09-26T16:06:25.000Z</published>
    <updated>2024-11-20T10:12:01.692Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;创建&quot;&gt;&lt;a href=&quot;#创建&quot; class=&quot;headerlink&quot; title=&quot;创建&quot;&gt;&lt;/a&gt;创建&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;在 Beam 中，所有的&lt;strong&gt;数据处理逻辑&lt;/strong&gt;都会被抽象成 &lt;strong&gt;Pipeline&lt;/strong&gt; 来运行&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pipeline&lt;/strong&gt; 是对&lt;strong&gt;数据处理逻辑&lt;/strong&gt;的一个&lt;strong&gt;封装&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;包括一整套流程 - &lt;strong&gt;读取&lt;/strong&gt;数据集、将数据集&lt;strong&gt;转换&lt;/strong&gt;成想要的结果、&lt;strong&gt;输出&lt;/strong&gt;结果数据集&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Beam - Transform</title>
    <link href="https://blog.zhongmingmao.top/2024/09/26/bigdata-beam-transform/"/>
    <id>https://blog.zhongmingmao.top/2024/09/26/bigdata-beam-transform/</id>
    <published>2024-09-25T16:06:25.000Z</published>
    <updated>2024-11-20T09:02:49.745Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;DAG&quot;&gt;&lt;a href=&quot;#DAG&quot; class=&quot;headerlink&quot; title=&quot;DAG&quot;&gt;&lt;/a&gt;DAG&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Transform 是 Beam 中&lt;strong&gt;数据处理&lt;/strong&gt;的&lt;strong&gt;最基本单元&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/image-20241120160357180.png&quot; alt=&quot;image-20241120160357180&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Beam - PCollection</title>
    <link href="https://blog.zhongmingmao.top/2024/09/25/bigdata-beam-pcollection/"/>
    <id>https://blog.zhongmingmao.top/2024/09/25/bigdata-beam-pcollection/</id>
    <published>2024-09-24T16:06:25.000Z</published>
    <updated>2024-11-20T07:43:30.786Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;数据抽象&quot;&gt;&lt;a href=&quot;#数据抽象&quot; class=&quot;headerlink&quot; title=&quot;数据抽象&quot;&gt;&lt;/a&gt;数据抽象&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Spark RDD&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;不同的技术系统有不同的&lt;strong&gt;数据结构&lt;/strong&gt;， 如在 C++  中有 vector、unordered_map&lt;/li&gt;
&lt;li&gt;几乎&lt;strong&gt;所有&lt;/strong&gt;的 Beam 数据都能表达为 PCollection&lt;/li&gt;
&lt;li&gt;PCollection - &lt;strong&gt;Parallel Collection&lt;/strong&gt; - 可&lt;strong&gt;并行计算&lt;/strong&gt;的数据集，与 Spark &lt;strong&gt;RDD&lt;/strong&gt; 非常类似&lt;/li&gt;
&lt;li&gt;在一个&lt;strong&gt;分布式计算系统&lt;/strong&gt;中，需要为用户隐藏实现细节，包括&lt;strong&gt;数据&lt;/strong&gt;是怎样&lt;strong&gt;表达&lt;/strong&gt;和&lt;strong&gt;存储&lt;/strong&gt;的&lt;ul&gt;
&lt;li&gt;数据可能来自于&lt;strong&gt;内存&lt;/strong&gt;的数据，也可能来自于&lt;strong&gt;外部文件&lt;/strong&gt;，或者来自于 &lt;strong&gt;MySQL&lt;/strong&gt; 数据库&lt;/li&gt;
&lt;li&gt;如果没有一个&lt;strong&gt;统一的数据抽象&lt;/strong&gt;的话，开发者需要不停地修改代码，无法专注于业务逻辑&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Beam - Paradigm</title>
    <link href="https://blog.zhongmingmao.top/2024/09/24/bigdata-beam-paradigm/"/>
    <id>https://blog.zhongmingmao.top/2024/09/24/bigdata-beam-paradigm/</id>
    <published>2024-09-23T16:06:25.000Z</published>
    <updated>2024-11-19T15:49:37.164Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Why&quot;&gt;&lt;a href=&quot;#Why&quot; class=&quot;headerlink&quot; title=&quot;Why&quot;&gt;&lt;/a&gt;Why&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;Apache Beam 本身并不是一个&lt;strong&gt;数据处理平台&lt;/strong&gt;，本身也无法对数据进行处理&lt;ul&gt;
&lt;li&gt;Apache Beam 所提供的是一个&lt;strong&gt;统一的编程模型&lt;/strong&gt;思想&lt;/li&gt;
&lt;li&gt;通过 Apache Beam 统一的 API 来编写处理逻辑，该处理逻辑会被转化为&lt;strong&gt;底层运行引擎相应的 API&lt;/strong&gt; 去运行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SDK 会变，但背后的&lt;strong&gt;设计原理&lt;/strong&gt;却不会改变&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Beam - Context</title>
    <link href="https://blog.zhongmingmao.top/2024/09/23/bigdata-beam-context/"/>
    <id>https://blog.zhongmingmao.top/2024/09/23/bigdata-beam-context/</id>
    <published>2024-09-22T16:06:25.000Z</published>
    <updated>2024-11-19T03:44:52.539Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;MapReduce&quot;&gt;&lt;a href=&quot;#MapReduce&quot; class=&quot;headerlink&quot; title=&quot;MapReduce&quot;&gt;&lt;/a&gt;MapReduce&lt;/h1&gt;&lt;h2 id=&quot;架构思想&quot;&gt;&lt;a href=&quot;#架构思想&quot; class=&quot;headerlink&quot; title=&quot;架构思想&quot;&gt;&lt;/a&gt;架构思想&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;提供一套&lt;strong&gt;简洁的 API&lt;/strong&gt; 来表达工程师&lt;strong&gt;数据处理&lt;/strong&gt;的逻辑&lt;/li&gt;
&lt;li&gt;在这套 API 底层嵌套一套&lt;strong&gt;扩展性很强&lt;/strong&gt;的&lt;strong&gt;容错系统&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/categories/big-data/beam/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Beam" scheme="https://blog.zhongmingmao.top/tags/beam/"/>
    
  </entry>
  
  <entry>
    <title>Big Data - Spark + Flink</title>
    <link href="https://blog.zhongmingmao.top/2024/09/22/bigdata-spark-flink/"/>
    <id>https://blog.zhongmingmao.top/2024/09/22/bigdata-spark-flink/</id>
    <published>2024-09-21T16:06:25.000Z</published>
    <updated>2024-11-18T16:34:55.538Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Spark-实时性&quot;&gt;&lt;a href=&quot;#Spark-实时性&quot; class=&quot;headerlink&quot; title=&quot;Spark 实时性&quot;&gt;&lt;/a&gt;Spark 实时性&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;无论是 &lt;strong&gt;Spark Streaming&lt;/strong&gt; 还是 &lt;strong&gt;Structured Streaming&lt;/strong&gt;，Spark &lt;strong&gt;流处理&lt;/strong&gt;的&lt;strong&gt;实时性还不够&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;无法应对&lt;strong&gt;实时性要求很高&lt;/strong&gt;的流处理场景&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spark 的&lt;strong&gt;流处理&lt;/strong&gt;是基于&lt;strong&gt;微批处理&lt;/strong&gt;的思想&lt;ul&gt;
&lt;li&gt;把流处理看做批处理的一种特殊形式，没接收到一个&lt;strong&gt;时间间隔&lt;/strong&gt;的数据才会去处理&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;虽然在 Spark 2.3 中提出&lt;strong&gt;连续处理模型&lt;/strong&gt;，但只支持&lt;strong&gt;有限的功能&lt;/strong&gt;，并不能在大项目中使用&lt;/li&gt;
&lt;li&gt;要在流处理的&lt;strong&gt;实时性&lt;/strong&gt;提升，就不能继续用&lt;strong&gt;微批处理&lt;/strong&gt;的模式，而是有数据数据就&lt;strong&gt;立即处理&lt;/strong&gt;，不做等待&lt;ul&gt;
&lt;li&gt;Apache &lt;strong&gt;Flink&lt;/strong&gt; 采用了基于操作符（&lt;strong&gt;Operator&lt;/strong&gt;）的&lt;strong&gt;连续流模型&lt;/strong&gt;，可以做到&lt;strong&gt;微秒级别&lt;/strong&gt;的延迟&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/categories/big-data/spark/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/tags/spark/"/>
    
    <category term="Flink" scheme="https://blog.zhongmingmao.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Spark - Structured Streaming</title>
    <link href="https://blog.zhongmingmao.top/2024/09/21/bigdata-spark-structured-streaming/"/>
    <id>https://blog.zhongmingmao.top/2024/09/21/bigdata-spark-structured-streaming/</id>
    <published>2024-09-20T16:06:25.000Z</published>
    <updated>2024-11-18T11:44:35.080Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;Spark Streaming 将&lt;strong&gt;无边界的流数据&lt;/strong&gt;抽象成 &lt;strong&gt;DStream&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;按特定的时间间隔，把&lt;strong&gt;数据流&lt;/strong&gt;分割成一个个 &lt;strong&gt;RDD&lt;/strong&gt; 进行&lt;strong&gt;批处理&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DStream&lt;/strong&gt; API 与 &lt;strong&gt;RDD&lt;/strong&gt; API &lt;strong&gt;高度相似&lt;/strong&gt;，拥有 RDD 的各种性质&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DataSet&amp;#x2F;DataFrame&lt;ul&gt;
&lt;li&gt;DataSet&amp;#x2F;DataFrame 是&lt;strong&gt;高级 API&lt;/strong&gt;，提供类似于 &lt;strong&gt;SQL&lt;/strong&gt; 的查询接口，方便熟悉&lt;strong&gt;关系型数据库&lt;/strong&gt;的开发人员使用&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spark SQL 执行引擎&lt;/strong&gt;会&lt;strong&gt;自动优化 DataSet&amp;#x2F;DataFrame 程序&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;用 &lt;strong&gt;RDD API&lt;/strong&gt; 开发的程序本质上需要开发人员&lt;strong&gt;手工构造 RDD 的 DAG 执行图&lt;/strong&gt;，依赖于&lt;strong&gt;手工优化&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如果拥有 &lt;strong&gt;DataSet&amp;#x2F;DataFrame API&lt;/strong&gt; 的&lt;strong&gt;流处理&lt;/strong&gt;模块&lt;ul&gt;
&lt;li&gt;无需去用&lt;strong&gt;相对底层&lt;/strong&gt;的 &lt;strong&gt;DStream API&lt;/strong&gt; 去处理&lt;strong&gt;无边界数据&lt;/strong&gt;，大大提升&lt;strong&gt;开发效率&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在 &lt;strong&gt;2016&lt;/strong&gt; 年，&lt;strong&gt;Spark 2.0&lt;/strong&gt; 中推出&lt;strong&gt;结构化流处理&lt;/strong&gt;的模块 - &lt;strong&gt;Structured Streaming&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;Structured Streaming 基于 &lt;strong&gt;Spark SQL&lt;/strong&gt; 引擎实现&lt;/li&gt;
&lt;li&gt;在开发视角，&lt;strong&gt;流数据&lt;/strong&gt;和&lt;strong&gt;静态数据&lt;/strong&gt;没有区别，可以像&lt;strong&gt;批处理静态数据&lt;/strong&gt;那样处理&lt;strong&gt;流数据&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;随着&lt;strong&gt;流数据&lt;/strong&gt;的&lt;strong&gt;持续输入&lt;/strong&gt;，Spark SQL 引擎会&lt;strong&gt;持续地处理&lt;/strong&gt;新数据，并更新计算结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/categories/big-data/spark/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark - Streaming</title>
    <link href="https://blog.zhongmingmao.top/2024/09/20/bigdata-spark-streaming/"/>
    <id>https://blog.zhongmingmao.top/2024/09/20/bigdata-spark-streaming/</id>
    <published>2024-09-19T16:06:25.000Z</published>
    <updated>2024-11-18T09:59:22.825Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;流处理&quot;&gt;&lt;a href=&quot;#流处理&quot; class=&quot;headerlink&quot; title=&quot;流处理&quot;&gt;&lt;/a&gt;流处理&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;Spark SQL 中的 &lt;strong&gt;DataFrame&lt;/strong&gt; API 和 &lt;strong&gt;DataSet&lt;/strong&gt; API 都是基于&lt;strong&gt;批处理&lt;/strong&gt;模式对&lt;strong&gt;静态数据&lt;/strong&gt;进行处理&lt;/li&gt;
&lt;li&gt;在 &lt;strong&gt;2013&lt;/strong&gt;，Spark 的&lt;strong&gt;流处理组件&lt;/strong&gt; Spark Streaming 发布，现在的 Spark Streaming 已经&lt;strong&gt;非常成熟&lt;/strong&gt;，应用非常广泛&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/categories/big-data/spark/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark - SQL</title>
    <link href="https://blog.zhongmingmao.top/2024/09/19/bigdata-spark-sql/"/>
    <id>https://blog.zhongmingmao.top/2024/09/19/bigdata-spark-sql/</id>
    <published>2024-09-18T16:06:25.000Z</published>
    <updated>2024-11-18T08:12:39.644Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;历史&quot;&gt;&lt;a href=&quot;#历史&quot; class=&quot;headerlink&quot; title=&quot;历史&quot;&gt;&lt;/a&gt;历史&lt;/h1&gt;&lt;h2 id=&quot;Hive&quot;&gt;&lt;a href=&quot;#Hive&quot; class=&quot;headerlink&quot; title=&quot;Hive&quot;&gt;&lt;/a&gt;Hive&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;一开始，&lt;strong&gt;Hadoop&amp;#x2F;MapReduce&lt;/strong&gt; 在企业生产中大量使用，在 &lt;strong&gt;HDFS&lt;/strong&gt; 上积累了大量数据&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MapReduce&lt;/strong&gt; 对于开发者而言&lt;strong&gt;使用难度&lt;/strong&gt;较大，大部分开发人员最熟悉的还是&lt;strong&gt;传统的关系型数据库&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;为了方便大多数开发人员使用 Hadoop，诞生了 &lt;strong&gt;Hive&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Hive 提供类似 &lt;strong&gt;SQL&lt;/strong&gt; 的编程接口，&lt;strong&gt;HQL&lt;/strong&gt; 经过&lt;strong&gt;语法解析&lt;/strong&gt;、&lt;strong&gt;逻辑计划&lt;/strong&gt;、&lt;strong&gt;物理计划&lt;/strong&gt;转化成 &lt;strong&gt;MapReduce&lt;/strong&gt; 程序执行&lt;ul&gt;
&lt;li&gt;使得开发人员很容易对 &lt;strong&gt;HDFS&lt;/strong&gt; 上存储的数据进行&lt;strong&gt;查询&lt;/strong&gt;和&lt;strong&gt;分析&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/categories/big-data/spark/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark - RDD</title>
    <link href="https://blog.zhongmingmao.top/2024/09/18/bigdata-spark-rdd/"/>
    <id>https://blog.zhongmingmao.top/2024/09/18/bigdata-spark-rdd/</id>
    <published>2024-09-17T16:06:25.000Z</published>
    <updated>2024-11-17T17:59:51.209Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;分布式内存&quot;&gt;&lt;a href=&quot;#分布式内存&quot; class=&quot;headerlink&quot; title=&quot;分布式内存&quot;&gt;&lt;/a&gt;分布式内存&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;传统的 &lt;strong&gt;MapReduce&lt;/strong&gt; 框架&lt;strong&gt;运行缓慢&lt;/strong&gt;，主要原因是 &lt;strong&gt;DAG&lt;/strong&gt; 的&lt;strong&gt;中间计算结果&lt;/strong&gt;需要写入&lt;strong&gt;硬盘&lt;/strong&gt;来&lt;strong&gt;防止运行结果丢失&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;每次调用中间计算结果都需要进行一次硬盘的读取&lt;ul&gt;
&lt;li&gt;反复对硬盘进行&lt;strong&gt;读写&lt;/strong&gt;操作以及潜在的&lt;strong&gt;数据复制&lt;/strong&gt;和&lt;strong&gt;序列化&lt;/strong&gt;操作会大大地提高了&lt;strong&gt;计算延迟&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;新的&lt;strong&gt;分布式存储&lt;/strong&gt;方案 - 保持之前系统的稳定性、错误恢复和可扩展性，并&lt;strong&gt;尽可能地减少硬盘 IO 操作&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;RDD 是基于&lt;strong&gt;分布式内存&lt;/strong&gt;的数据抽象，不仅支持基于&lt;strong&gt;工作集&lt;/strong&gt;的应用，同时具有&lt;strong&gt;数据流模型&lt;/strong&gt;的特点&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/categories/big-data/spark/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/tags/spark/"/>
    
    <category term="RDD" scheme="https://blog.zhongmingmao.top/tags/rdd/"/>
    
  </entry>
  
  <entry>
    <title>Spark - Overview</title>
    <link href="https://blog.zhongmingmao.top/2024/09/17/bigdata-spark-overview/"/>
    <id>https://blog.zhongmingmao.top/2024/09/17/bigdata-spark-overview/</id>
    <published>2024-09-16T16:06:25.000Z</published>
    <updated>2024-11-17T14:17:58.226Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;MapReduce&quot;&gt;&lt;a href=&quot;#MapReduce&quot; class=&quot;headerlink&quot; title=&quot;MapReduce&quot;&gt;&lt;/a&gt;MapReduce&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;MapReduce 通过简单的 &lt;strong&gt;Map&lt;/strong&gt; 和 &lt;strong&gt;Reduce&lt;/strong&gt; 的&lt;strong&gt;抽象&lt;/strong&gt;提供了一个&lt;strong&gt;编程模型&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;可以在一个由上百台机器组成的集群上&lt;strong&gt;并发&lt;/strong&gt;处理大量的数据集，而把计算细节隐藏起来&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;各种各样的&lt;strong&gt;复杂数据处理&lt;/strong&gt;都可以分解为 &lt;strong&gt;Map&lt;/strong&gt; 和 &lt;strong&gt;Reduce&lt;/strong&gt; 的&lt;strong&gt;基本元素&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;复杂的数据处理可以分解成由多个 &lt;strong&gt;Job&lt;/strong&gt;（包含一个 &lt;strong&gt;Mapper&lt;/strong&gt; 和一个 &lt;strong&gt;Reducer&lt;/strong&gt;）组成的 &lt;strong&gt;DAG&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;然后，将每个 &lt;strong&gt;Mapper&lt;/strong&gt; 和 &lt;strong&gt;Reducer&lt;/strong&gt; 放到 &lt;strong&gt;Hadoop&lt;/strong&gt; 集群上执行，得到最终结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/categories/big-data/spark/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
    <category term="Spark" scheme="https://blog.zhongmingmao.top/tags/spark/"/>
    
    <category term="MapReduce" scheme="https://blog.zhongmingmao.top/tags/mapreduce/"/>
    
  </entry>
  
  <entry>
    <title>Big Data - Kappa</title>
    <link href="https://blog.zhongmingmao.top/2024/09/16/bigdata-kappa/"/>
    <id>https://blog.zhongmingmao.top/2024/09/16/bigdata-kappa/</id>
    <published>2024-09-15T16:06:25.000Z</published>
    <updated>2024-11-17T12:22:16.038Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Lambda&quot;&gt;&lt;a href=&quot;#Lambda&quot; class=&quot;headerlink&quot; title=&quot;Lambda&quot;&gt;&lt;/a&gt;Lambda&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/image-20241117181045851.png&quot; alt=&quot;image-20241117181045851&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
  </entry>
  
  <entry>
    <title>Big Data - Lambda</title>
    <link href="https://blog.zhongmingmao.top/2024/09/15/bigdata-lambda/"/>
    <id>https://blog.zhongmingmao.top/2024/09/15/bigdata-lambda/</id>
    <published>2024-09-14T16:06:25.000Z</published>
    <updated>2024-11-17T09:00:52.048Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Architecture&quot;&gt;&lt;a href=&quot;#Architecture&quot; class=&quot;headerlink&quot; title=&quot;Architecture&quot;&gt;&lt;/a&gt;Architecture&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/image-20241117154711119.png&quot; alt=&quot;image-20241117154711119&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/categories/big-data/"/>
    
    
    <category term="Big Data" scheme="https://blog.zhongmingmao.top/tags/big-data/"/>
    
  </entry>
  
</feed>
