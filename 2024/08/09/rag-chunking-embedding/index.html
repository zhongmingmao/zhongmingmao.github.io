<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>RAG - Chunking + Embedding | ByteCoding</title><meta name="author" content="zhongmingmao"><meta name="copyright" content="zhongmingmao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="概述 Chunking   Documents 经过解析后，通过 Chunking 将信息内容划分为适当大小的 Chunks - 能够高效处理和精准检索 Chunk 的本质在于依据一定的逻辑和语义原则，将长文本拆解为更小的单元 Chunking 有多种策略，各有侧重，选择适合特定场景的 Chunking 策略，有助于提升 RAG 召回率">
<meta property="og:type" content="article">
<meta property="og:title" content="RAG - Chunking + Embedding">
<meta property="og:url" content="https://blog.zhongmingmao.top/2024/08/09/rag-chunking-embedding/index.html">
<meta property="og:site_name" content="ByteCoding">
<meta property="og:description" content="概述 Chunking   Documents 经过解析后，通过 Chunking 将信息内容划分为适当大小的 Chunks - 能够高效处理和精准检索 Chunk 的本质在于依据一定的逻辑和语义原则，将长文本拆解为更小的单元 Chunking 有多种策略，各有侧重，选择适合特定场景的 Chunking 策略，有助于提升 RAG 召回率">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/vector_chunking_text.png">
<meta property="article:published_time" content="2024-08-08T16:06:25.000Z">
<meta property="article:modified_time" content="2024-09-03T02:17:03.107Z">
<meta property="article:author" content="zhongmingmao">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="RAG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/vector_chunking_text.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "RAG - Chunking + Embedding",
  "url": "https://blog.zhongmingmao.top/2024/08/09/rag-chunking-embedding/",
  "image": "https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/vector_chunking_text.png",
  "datePublished": "2024-08-08T16:06:25.000Z",
  "dateModified": "2024-09-03T02:17:03.107Z",
  "author": [
    {
      "@type": "Person",
      "name": "zhongmingmao",
      "url": "https://blog.zhongmingmao.top"
    }
  ]
}</script><link rel="shortcut icon" href="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png"><link rel="canonical" href="https://blog.zhongmingmao.top/2024/08/09/rag-chunking-embedding/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":32,"languages":{"author":"Author: zhongmingmao","link":"Link: ","source":"Source: ByteCoding","info":"Copyright belongs to the author. For commercial use, please contact the author for authorization. For non-commercial use, please indicate the source."}},
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'RAG - Chunking + Embedding',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="ByteCoding" type="application/atom+xml">
</head><body><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js/themes/blue/pace-theme-minimal.min.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg" style="background-image: url(/url(https:/cdn.pixabay.com/photo/2021/07/20/03/39/fisherman-6479663_1280.jpg));"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">642</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/vector_chunking_text.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">ByteCoding</span></a><a class="nav-page-title" href="/"><span class="site-name">RAG - Chunking + Embedding</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">RAG - Chunking + Embedding</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">Created</span><time datetime="2024-08-08T16:06:25.000Z" title="Created 2024-08-09 00:06:25">2024-08-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ai/">AI</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ai/rag/">RAG</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">2.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>8mins</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:512,&quot;messagePrev&quot;:&quot;It has been&quot;,&quot;messageNext&quot;:&quot;days since the last update, the content of the article may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2024-09-03 10:17:03&quot;}" hidden></div><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><blockquote>
<p>Chunking</p>
</blockquote>
<ol>
<li>Documents 经过解析后，通过 <strong>Chunking</strong> 将信息内容划分为适当大小的 <strong>Chunks</strong> - 能够<strong>高效处理</strong>和<strong>精准检索</strong></li>
<li>Chunk 的本质在于依据一定的<strong>逻辑</strong>和<strong>语义原则</strong>，将<strong>长文本</strong>拆解为<strong>更小的单元</strong></li>
<li>Chunking 有多种<strong>策略</strong>，各有<strong>侧重</strong>，选择<strong>适合特定场景</strong>的 Chunking 策略，有助于<strong>提升 RAG 召回率</strong></li>
</ol>
<span id="more"></span>

<blockquote>
<p>Embedding</p>
</blockquote>
<ol>
<li><strong>Embedding Model</strong> 负责将<strong>文本数据</strong>映射到<strong>高维向量空间</strong>，将输入的<strong>文档片段</strong>转换为对应的<strong>嵌入向量</strong></li>
<li><strong>嵌入向量</strong>捕捉了文本的<strong>语义</strong>信息，并存储到<strong>向量库</strong>中，以便于后续<strong>检索</strong></li>
<li><strong>Query</strong> 同样通过 <strong>Embedding Model</strong> 的处理生成 <strong>Query 的嵌入向量</strong>，在<strong>向量库</strong>中通过<strong>向量检索</strong>匹配<strong>最相似</strong>的文档片段</li>
<li>根据不同的场景，<strong>评估</strong>并选择最优的 <strong>Embedding Model</strong>，以确保 RAG 的<strong>检索性能</strong>符合要求</li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240902232040001.png" alt="image-20240902232040001"></p>
<h1 id="Chunking"><a href="#Chunking" class="headerlink" title="Chunking"></a>Chunking</h1><h2 id="影响"><a href="#影响" class="headerlink" title="影响"></a>影响</h2><ol>
<li>Documents 包含<strong>丰富的上下文信息</strong>和<strong>复杂的语义结构</strong><ul>
<li>通过 Chunking，模型可以更有效地<strong>提取关键信息</strong>，并减少不相关内容的<strong>干扰</strong></li>
</ul>
</li>
<li>Chunking 的目标<ul>
<li>确保每个片段在<strong>保留核心语义</strong>的同时，具备<strong>相对独立的语义完整性</strong></li>
<li>使得模型在处理时<strong>不必依赖</strong>广泛的上下文信息，增强<strong>检索召回</strong>的<strong>准确性</strong></li>
</ul>
</li>
<li>Chunking <strong>直接影响</strong> RAG 系统的<strong>生成质量</strong><ul>
<li>能够确保检索到片段<strong>与 Query 高度匹配</strong>，避免信息<strong>冗余</strong>或者<strong>丢失</strong></li>
<li>有助于提升<strong>生成内容的连贯性</strong>，精心设计的<strong>独立语义片段</strong>可以降低模型<strong>对上下文的依赖</strong></li>
<li>影响系统的<strong>响应速度</strong>和<strong>效率</strong></li>
</ul>
</li>
</ol>
<h2 id="尺寸"><a href="#尺寸" class="headerlink" title="尺寸"></a>尺寸</h2><ol>
<li>Chunking 最大的挑战是<strong>确定 Chunk 大小</strong></li>
<li>Chunk <strong>过大</strong> - 可能导致向量<strong>无法精确捕捉</strong>内容的特定细节并且<strong>增加计算成本</strong></li>
<li>Chunk <strong>过小</strong> - 可能<strong>丢失上下文</strong>，导致<strong>句子碎片化</strong>和<strong>语义不连贯</strong></li>
<li>适合的场景<ul>
<li><strong>小 Chunk</strong> - 需要<strong>细粒度分析</strong>的任务 - <strong>情感分析</strong></li>
<li><strong>大 Chunk</strong> - 需要<strong>保留更广泛上下文</strong>的场景 - <strong>文档摘要</strong> or <strong>主题检测</strong></li>
</ul>
</li>
<li>取舍<ul>
<li>Chunk 大小的确定必须在<strong>计算效率</strong>和<strong>上下文</strong>之间取得平衡</li>
</ul>
</li>
</ol>
<h2 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h2><ol>
<li>最佳的 <strong>Chunking 策略</strong>取决于具体的<strong>应用场景</strong> - 业界<strong>无统一标准</strong></li>
<li>选择最合适目标场景的 Chunking 策略，确保 RAG 系统中 <strong>LLM</strong> 能够<strong>更精确</strong>地处理和检索数据</li>
</ol>
<blockquote>
<p>Chunking 策略的组成</p>
</blockquote>
<table>
<thead>
<tr>
<th>Part</th>
<th>Desc</th>
</tr>
</thead>
<tbody><tr>
<td>大小</td>
<td>每个 Chunk 所允许的<strong>最大字符数</strong></td>
</tr>
<tr>
<td>重叠</td>
<td>在相邻 Chunk 之间，<strong>重叠字符</strong>的数量</td>
</tr>
<tr>
<td>拆分</td>
<td>通过<strong>段落边界</strong>、<strong>分隔符</strong>、<strong>标记</strong>、<strong>语义边界</strong>来确定 <strong>Chunk 边界</strong>的位置</td>
</tr>
</tbody></table>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/63b052c1b1639bfa66c23342cf28d9ef.png" alt="63b052c1b1639bfa66c23342cf28d9ef.jpg"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://chunkviz.up.railway.app/">https://chunkviz.up.railway.app/</a></p>
</blockquote>
<h3 id="Fixed-Size"><a href="#Fixed-Size" class="headerlink" title="Fixed Size"></a>Fixed Size</h3><blockquote>
<p>固定大小分块</p>
</blockquote>
<h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><ol>
<li>将文档按<strong>固定大小</strong>进行分块，作为 Chunking 策略的<strong>基准线</strong></li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240903001840753.png" alt="image-20240903001840753"></p>
<h4 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h4><ol>
<li>作为 Chunking 策略的<strong>基准线</strong></li>
<li>对<strong>大型数据集</strong>进行<strong>初步分析</strong></li>
<li>实现简单 + <strong>可预测性高</strong>，Chunk <strong>便于管理</strong></li>
<li>适用于<strong>格式</strong>和<strong>大小</strong>相似的<strong>同质数据集</strong> - 新闻 or 博客</li>
</ol>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><ol>
<li>不考虑内容<strong>上下文</strong>，可能在句子或者段落<strong>中断内容</strong>，导致<strong>无意义</strong>的 Chunk</li>
<li>缺乏<strong>灵活性</strong>，无法适应<strong>文本</strong>的<strong>自然结构</strong></li>
</ol>
<h3 id="Overlap"><a href="#Overlap" class="headerlink" title="Overlap"></a>Overlap</h3><blockquote>
<p>重叠分块</p>
</blockquote>
<h4 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h4><ol>
<li>通过<strong>滑动窗口</strong>技术切分 Chunk，使新 Chunk 与前一个 Chunk 的内容<strong>部分重叠</strong></li>
<li>保留 <strong>Chunk 边界</strong>处的重要<strong>上下文</strong>信息，增强系统的<strong>语义相关性</strong></li>
<li>增加了<strong>存储</strong>需求和<strong>冗余</strong>信息，有效避免了 Chunk 之间<strong>丢失</strong>关键<strong>语义</strong>或<strong>句法</strong>结构</li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240903003257672.png" alt="image-20240903003257672"></p>
<h4 id="场景-1"><a href="#场景-1" class="headerlink" title="场景"></a>场景</h4><ol>
<li>需要<strong>深入理解语义</strong>并<strong>保持完整上下文</strong>的文档 - 法律文档 &#x2F; <strong>技术手册</strong> &#x2F; 科研论文</li>
<li>提升 Chunk 的<strong>内容连贯性</strong>，以提高<strong>分析质量</strong></li>
</ol>
<h4 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h4><ol>
<li>增加<strong>计算复杂度</strong>，降低<strong>处理效率</strong></li>
<li>需要存储和管理<strong>冗余信息</strong></li>
</ol>
<h3 id="Recursive"><a href="#Recursive" class="headerlink" title="Recursive"></a>Recursive</h3><blockquote>
<p>递归分块</p>
</blockquote>
<h4 id="概述-3"><a href="#概述-3" class="headerlink" title="概述"></a>概述</h4><ol>
<li>通过<strong>预定义</strong>的文本分隔符<strong>迭代</strong>地将文本分解为更小的 Chunk - <strong>段大小的均匀性</strong> + <strong>语义的完整性</strong></li>
<li>过程 - 按<strong>较大</strong>的逻辑单元分割，然后<strong>逐步递归</strong>到<strong>较小</strong>的逻辑单元</li>
<li>确保在 Chunk 大小内，<strong>保留最强的语义片段</strong></li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240903005751718.png" alt="image-20240903005751718"></p>
<h4 id="场景-2"><a href="#场景-2" class="headerlink" title="场景"></a>场景</h4><ol>
<li>需要<strong>逐层分析</strong>的文档，或者需要分解成<strong>长片段</strong>、长段落的长文档  - 研究报告 &#x2F; 法律文档</li>
</ol>
<h4 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h4><ol>
<li>可能在 <strong>Chunk 边界</strong>处<strong>模糊语义</strong>，容易将<strong>完整的语义</strong>单元<strong>切分</strong>开</li>
</ol>
<h3 id="Document-Specific"><a href="#Document-Specific" class="headerlink" title="Document Specific"></a>Document Specific</h3><blockquote>
<p>文档特定分块</p>
</blockquote>
<h4 id="概述-4"><a href="#概述-4" class="headerlink" title="概述"></a>概述</h4><ol>
<li>根据<strong>文档格式</strong>（Markdown、Code 等）进行<strong>定制化分割</strong></li>
<li>确保 Chunk 能够<strong>准确反映</strong>文档的特点 - 优化保留了<strong>完整语义</strong>的单元，提升后续处理和分析的效果</li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240903010758462.png" alt="image-20240903010758462"></p>
<h4 id="场景-3"><a href="#场景-3" class="headerlink" title="场景"></a>场景</h4><ol>
<li>根据<strong>特定</strong>的文档结构，进行<strong>准确</strong>的语义内容切分</li>
</ol>
<h4 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h4><ol>
<li><strong>依赖性强</strong>，不同格式之间的 Chunking 策略<strong>不通用</strong></li>
<li>无法处理<strong>格式不规范</strong>和<strong>混合多种格式</strong>的情况</li>
</ol>
<h3 id="Semantic"><a href="#Semantic" class="headerlink" title="Semantic"></a>Semantic</h3><blockquote>
<p>语义分块</p>
</blockquote>
<h4 id="概述-5"><a href="#概述-5" class="headerlink" title="概述"></a>概述</h4><ol>
<li>基于文本的<strong>自然语言边界</strong>（句子、段落等）进行分段</li>
<li>需要使用 <strong>NLP</strong> 技术根据语义<strong>分词分句</strong>，旨在确保每个 Chunk 都包含<strong>语义连贯</strong>的信息单元</li>
<li>保留了较高的<strong>上下文</strong>信息，并确保每个 Chunk 都包含<strong>连贯</strong>的信息，但需要更多的<strong>计算资源</strong></li>
<li>常用 NLP 库<ul>
<li><strong>spaCy</strong> - 需要<strong>高效</strong>、<strong>精准</strong>语义切分的<strong>大规模</strong>文本处理</li>
<li><strong>NLTK</strong> - 适合<strong>教学</strong>、<strong>研究</strong>和需要<strong>灵活自定义</strong>的语义切分任务</li>
</ul>
</li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/95687f417dyy2f92ab7c9ca374619acf.png.webp" alt="95687f417dyy2f92ab7c9ca374619acf.png"></p>
<h4 id="场景-4"><a href="#场景-4" class="headerlink" title="场景"></a>场景</h4><ol>
<li>确保每个 Chunk 的<strong>信息完整</strong>且<strong>语义连贯</strong></li>
<li>提高<strong>检索结果</strong>的<strong>相关性</strong>和<strong>准确性</strong></li>
<li>适用于<strong>复杂文档</strong>和<strong>上下文敏感</strong>的<strong>精细化分析</strong></li>
</ol>
<h4 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h4><ol>
<li>需要额外的<strong>高计算资源</strong> - 动态或者大型的文档数据</li>
<li>降低<strong>处理效率</strong></li>
</ol>
<h3 id="Mix"><a href="#Mix" class="headerlink" title="Mix"></a>Mix</h3><blockquote>
<p>混合分块</p>
</blockquote>
<h4 id="概述-6"><a href="#概述-6" class="headerlink" title="概述"></a>概述</h4><ol>
<li>综合利用不同 Chunking 技术的优势，提高 Chunking 的<strong>精确性</strong>和<strong>处理效率</strong></li>
<li><strong>初始阶段</strong>使用<strong>固定长度</strong>分块<strong>快速</strong>处理大量文档，在<strong>后续阶段</strong>使用<strong>语义分块</strong>进行<strong>更精细</strong>的分类和主题提取</li>
</ol>
<h4 id="场景-5"><a href="#场景-5" class="headerlink" title="场景"></a>场景</h4><ol>
<li><strong>多层次</strong>的<strong>精细化</strong> Chunking 场景</li>
<li>数据集<strong>动态变化</strong>，包含<strong>多种格式和结构</strong></li>
<li>平衡<strong>处理速度</strong>与<strong>准确性</strong>的场景</li>
</ol>
<h4 id="问题-5"><a href="#问题-5" class="headerlink" title="问题"></a>问题</h4><ol>
<li>实现<strong>复杂度</strong>高</li>
<li><strong>调优</strong>难度高</li>
<li>增加<strong>资源消耗</strong></li>
</ol>
<h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><h3 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h3><blockquote>
<p>langchain_text_splitters</p>
</blockquote>
<table>
<thead>
<tr>
<th>Chunking</th>
<th>LangChain Text Splitter</th>
</tr>
</thead>
<tbody><tr>
<td>Fixed Size</td>
<td>CharacterTextSplitter</td>
</tr>
<tr>
<td>Overlap</td>
<td>CharacterTextSplitter</td>
</tr>
<tr>
<td>Recursive</td>
<td>RecursiveCharacterTextSplitter</td>
</tr>
<tr>
<td>Document Specific</td>
<td>MarkdownTextSplitter<br />PythonCodeTextSplitter<br />LatexTextSplitter</td>
</tr>
<tr>
<td>Semantic</td>
<td>SpacyTextSplitter<br />NLTKTextSplitter</td>
</tr>
</tbody></table>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240903014314872.png" alt="image-20240903014314872"></p>
<h3 id="Dependency"><a href="#Dependency" class="headerlink" title="Dependency"></a>Dependency</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ pip install spacy nltk</span><br><span class="line">$ python -m spacy download zh_core_web_sm</span><br><span class="line">$ python -m spacy download en_core_web_sm</span><br></pre></td></tr></table></figure>

<h3 id="TextSplitter"><a href="#TextSplitter" class="headerlink" title="TextSplitter"></a>TextSplitter</h3><blockquote>
<p>SpacyTextSplitter</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置SpacyTextSplitter分割文本块库</span></span><br><span class="line">text_splitter = SpacyTextSplitter(</span><br><span class="line">    chunk_size=<span class="number">512</span>, chunk_overlap=<span class="number">128</span>, pipeline=<span class="string">&quot;zh_core_web_sm&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置RecursiveCharacterTextSplitter分割文本块</span></span><br><span class="line"><span class="comment"># 可以更换为CharacterTextSplitter、MarkdownTextSplitter、PythonCodeTextSplitter、LatexTextSplitter、NLTKTextSplitter等</span></span><br><span class="line"><span class="comment"># text_splitter = RecursiveCharacterTextSplitter(</span></span><br><span class="line"><span class="comment">#     chunk_size=512, chunk_overlap=128)</span></span><br></pre></td></tr></table></figure>

<h1 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h1><h2 id="概述-7"><a href="#概述-7" class="headerlink" title="概述"></a>概述</h2><ol>
<li>将<strong>文本</strong>、<strong>图像</strong>、<strong>音频</strong>、<strong>视频</strong>等形式的信息映射到<strong>高维空间</strong>中的<strong>密集向量</strong>表示</li>
<li><strong>嵌入向量</strong>在<strong>语义空间</strong>中起到<strong>坐标</strong>的作用，用于捕捉对象之间的<strong>语义关系</strong>和<strong>隐含意义</strong></li>
<li>通过在<strong>向量空间</strong>中进行<strong>计算</strong>（如<strong>余弦相似度</strong>），可以量化和衡量对象之间的<strong>语义相似性</strong></li>
<li><strong>嵌入向量</strong>的<strong>每个维度</strong>通常对应文本的<strong>某种特征</strong>，通过<strong>多维度</strong>的数值表示，计算机能够<strong>理解</strong>并<strong>解析</strong>文本的<strong>复杂语义结构</strong></li>
<li><strong>向量</strong>是一组在<strong>高维空间</strong>中定义点的<strong>数值数组</strong>，而<strong>嵌入</strong>是将<strong>信息</strong>转化为某种<strong>向量表示</strong>的过程<ul>
<li><strong>嵌入向量</strong>能够捕捉数据的<strong>语义</strong>及其它<strong>重要特征</strong></li>
<li>使得<strong>语义相近</strong>的对象在向量空间中<strong>相距较近</strong>，而<strong>语义相异</strong>的对象则<strong>相距较远</strong></li>
</ul>
</li>
<li><strong>向量检索</strong><ul>
<li>通过计算 <strong>Query 向量</strong>与 <strong>Chunk 向量</strong>的<strong>相似度</strong>来识别<strong>最相关</strong>的文本数据</li>
<li>非常<strong>高效</strong>，能够在<strong>大规模数据集</strong>中<strong>快速</strong>、<strong>准确</strong>地找到与 Query 最相关的内容 - <strong>向量蕴含丰富语义</strong></li>
</ul>
</li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240903084318722.png" alt="image-20240903084318722"></p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><ol>
<li>早期 <strong>word2vec</strong>、<strong>GloVe</strong>、<strong>fastText</strong> 等嵌入模型通过分析大量文本数据，学习得出单词的<strong>嵌入向量</strong></li>
<li>从 <strong>Transformer</strong> 后，Embedding 发展非常快<ul>
<li><strong>BERT</strong>、<strong>RoBERTa</strong>、<strong>ELECTRA</strong> 等模型将 Embedding 推进到<strong>上下文敏感</strong>的阶段</li>
<li><strong>同一个单词</strong>在<strong>不同语境</strong>下的<strong>嵌入向量</strong>是<strong>不同</strong>的，提升了模型<strong>理解复杂语言结构</strong>的能力</li>
</ul>
</li>
</ol>
<h2 id="RAG"><a href="#RAG" class="headerlink" title="RAG"></a>RAG</h2><ol>
<li><strong>Embedding Model</strong> 将 <strong>Chunks</strong> 和 <strong>Query</strong> 转换为 <strong>Vectors</strong></li>
<li><strong>Vectors</strong> 捕捉了文本的<strong>语义信息</strong>，可以在<strong>向量空间</strong>中与其它嵌入向量进行<strong>比较</strong></li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240903085807853.png" alt="image-20240903085807853"></p>
<h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><ol>
<li>评估维度 - 特定<strong>领域</strong>、检索<strong>精度</strong>、支持<strong>语言</strong>、文本块<strong>长度</strong>、模型<strong>大小</strong>、检索<strong>效率</strong></li>
<li>评估标准 - 涵盖<strong>分类</strong>、<strong>聚类</strong>、<strong>语义文本相似性</strong>、<strong>重排序</strong>、<strong>检索</strong>等多个数据集的评测<ul>
<li><strong>MTEB</strong> - Massive Text Embedding Benchmark</li>
<li><strong>C-MTEB</strong> - Chinese Massive Text Embedding Benchmark</li>
</ul>
</li>
<li>根据不同任务的<strong>需求</strong>，评估并选择<strong>最优</strong>的 Embedding Model，以获得在<strong>特定场景</strong>中的<strong>最佳性能</strong></li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240903091131548.png" alt="image-20240903091131548"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/mteb/leaderboard">https://huggingface.co/spaces/mteb/leaderboard</a><br>RAG 是<strong>检索</strong>任务，按照 <strong>Retrieval Average</strong> 倒排 - 需<strong>实际实验</strong>各种高得分的模型</p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240903091617395.png" alt="image-20240903091617395"></p>
<table>
<thead>
<tr>
<th>Metrics</th>
<th>Desc</th>
</tr>
</thead>
<tbody><tr>
<td>Retrieval Average</td>
<td>检索平均值</td>
</tr>
<tr>
<td>Model Size</td>
<td>模型大小（<strong>GB</strong>）<br />模型越大，<strong>检索性能</strong>越好，但<strong>延迟</strong>也越大</td>
</tr>
<tr>
<td>Max Tokens</td>
<td>最大 Token 数，可<strong>压缩</strong>到<strong>单个 Chunk</strong> 中的最大 Token 数，经验值 <strong>512</strong></td>
</tr>
<tr>
<td>Embedding Dimensions</td>
<td>嵌入向量的维度<br />更少的嵌入维度提供<strong>更快的推理速度</strong>和<strong>更高的存储效率</strong><br />更多的维度可以捕获数据中的<strong>细微特征</strong></td>
</tr>
</tbody></table>
<h2 id="实践-1"><a href="#实践-1" class="headerlink" title="实践"></a>实践</h2><ol>
<li><strong>SentenceTransformer</strong> 模块可以用于<strong>训练和推理 Embedding Model</strong>，可以在 RAG 系统中<strong>计算嵌入向量</strong></li>
<li>支持的模型列表 - <a target="_blank" rel="noopener" href="https://www.sbert.net/docs/sentence_transformer/pretrained_models.html">https://www.sbert.net/docs/sentence_transformer/pretrained_models.html</a><ul>
<li>Original models - 124<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/models?library=sentence-transformers&author=sentence-transformers">https://huggingface.co/models?library=sentence-transformers&amp;author=sentence-transformers</a></li>
</ul>
</li>
<li>Community models - 8557<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/models?library=sentence-transformers">https://huggingface.co/models?library=sentence-transformers</a></li>
</ul>
</li>
</ul>
</li>
<li>在<strong>中文</strong>领域，<strong>BAAI</strong> 的 <strong>BGE</strong>（BAAI General Embedding） 系列模型是比较知名的，在 <strong>C-MTEB</strong> 上表现出色<ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/collections/BAAI/bge-66797a74476eb1f085c7446d">https://huggingface.co/collections/BAAI/bge-66797a74476eb1f085c7446d</a></li>
</ul>
</li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240903095158210.png" alt="image-20240903095158210"></p>
<blockquote>
<p>加载 Embedding Model</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绝对路径：SentenceTransformer读取绝对路径下的bge-small-zh-v1.5模型，如需使用其他模型，下载其他模型，并且更换绝对路径即可</span></span><br><span class="line">embedding_model = SentenceTransformer(os.path.abspath(<span class="string">&#x27;data/model/embedding/bge-large-zh-v1.5&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动下载：SentenceTransformer库自动下载BAAI/bge-large-zh-v1.5模型，如需下载其他模型，输入其他模型名称即可</span></span><br><span class="line"><span class="comment"># embedding_model = SentenceTransformer(&#x27;BAAI/bge-large-zh-v1.5&#x27;)</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>将 Chunks 转化为 Embeddings</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 文本块转化为嵌入向量列表，normalize_embeddings表示对嵌入向量进行归一化，用于准确计算相似度</span></span><br><span class="line">embeddings = []</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> all_chunks:</span><br><span class="line">    embedding = embedding_model.encode(chunk, normalize_embeddings=<span class="literal">True</span>)</span><br><span class="line">    embeddings.append(embedding)</span><br></pre></td></tr></table></figure>

<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top">zhongmingmao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top/2024/08/09/rag-chunking-embedding/">https://blog.zhongmingmao.top/2024/08/09/rag-chunking-embedding/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ai/">AI</a><a class="post-meta__tags" href="/tags/llm/">LLM</a><a class="post-meta__tags" href="/tags/rag/">RAG</a></div><div class="post-share"><div class="social-share" data-image="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/vector_chunking_text.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/08/10/rag-chatbot/" title="RAG - Chatbot"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240903105543068.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">RAG - Chatbot</div></div><div class="info-2"><div class="info-item-1">Fine-tuning vs RAG 核心诉求 - 实时更新知识库，不需要模型去深度探讨问题，使用已有知识经验去解答问题      Fine-tuning RAG    知识整合 直接把数据融入到模型参数 存储在外部知识库   知识更新 每次更新内容都需要重新训练模型，更新成本高 只需要在外部知识库插入记录，更新成本低   响应速度 很快，直接给出回答 现在外部知识库进行检索，然后再生成   实时更新 很难做到实时更新 外部知识库可以实时更新   人为干预 只能通过 Prompt 干预 可以通过外部知识库的语料和 Prompt 控制   领域定制 可以针对特定领域进行深度定制 依赖通用模型能力      适合使用 Fine-tuning 的场景   特定场景下的高一致性和定制化 数据量充足且稳定 训练 - 拥有高质量的对话原始数据 微调 - 基于现有对话数据做对话助手   强个性化需求 文言文的理解和输出 - 需要使用大量文言文语料微调后，才能满足需求   高速响应 Fine-tuning 能够直接输出有效内容，而 RAG 需要先检索再生成    LLM LLM 针对输入是有长度限制的，计量单位为 To...</div></div></div></a><a class="pagination-related" href="/2024/08/08/rag-frameworks/" title="RAG - Frameworks"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-frameworks.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">RAG - Frameworks</div></div><div class="info-2"><div class="info-item-1">Overview Retrieval-Augmented Generation (RAG) is an AI framework that enhances the capabilities of large language models (LLMs) by incorporating external knowledge sources. It helps overcome limitations such as knowledge cutoff dates and reduces the risk of hallucinations in LLM outputs. RAG works by retrieving relevant information from a knowledge base and using it to augment the LLM’s input, allowing the model to generate more accurate, up-to-date, and contextually relevant responses.     Haystack Hays...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/09/09/rag-vector-qdrant/" title="RAG - Qdrant"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/qdrant.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-09</div><div class="info-item-2">RAG - Qdrant</div></div><div class="info-2"><div class="info-item-1">Features   Getting StartedIntroduction Vector databases are a relatively new way for interacting with abstract data representations derived from opaque machine learning models such as deep learning architectures. These representations are often called vectors or embeddings and they are a compressed version of the data used to train a machine learning model to accomplish a task like sentiment analysis, speech recognition, object detection, and many others.  What is Qdrant? Qdrant “is a vector similarity s...</div></div></div></a><a class="pagination-related" href="/2024/08/17/rag-graphrag/" title="RAG - GraphRAG"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/graphrag-9781829.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-17</div><div class="info-item-2">RAG - GraphRAG</div></div><div class="info-2"><div class="info-item-1">向量检索 信息片段之间的连接能力有限   RAG 在跨越多个信息片段以获取综合见解时表现不足 当要回答一个复杂问题时，必须要通过共享属性在不同信息之间建立联系 RAG 无法有效捕捉这些关系 限制了 RAG 在处理需要多跳推理或整合多源数据的复杂查询时的能力       归纳总结能力不足   在处理大型数据集或长文档时，RAG 难以有效地归纳和总结复杂的语义概念 RAG 在需要全面理解和总结复杂语义信息的场景中表现不佳  GraphRAG 利用 LLM 生成的知识图谱来改进 RAG 的检索部分   GraphRAG 利用结构化的实体和关系信息，使得检索过程更加精准和全面 GraphRAG 在处理多跳问题和复杂文档分析时表现出色 GraphRAG 在处理复杂信息处理任务时，显著提升问答性能，提供比 RAG 更为准确和全面的答案 GraphRAG 通过知识图谱有效地连接不同的信息片段 不仅能够提供准确答案，还能展示答案之间的内在联系，提供更丰富和有价值的结果     GraphRAG 先利用知识图谱，关联查询的实体和关系从与知识图谱实体直接相关的文档中检索片段，提供一个更全面、指标化、高信息密度的总结   主...</div></div></div></a><a class="pagination-related" href="/2024/08/16/rag-evolution/" title="RAG - Evolution"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-evolution.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-16</div><div class="info-item-2">RAG - Evolution</div></div><div class="info-2"><div class="info-item-1">演进    Naive RAG -&gt; Advanced RAG -&gt; Modular RAG 三个范式之间具有继承与发展的关系 Advanced RAG 是 Modular RAG 的一种特例形式 Naive RAG 是 Advanced RAG 的基础特例   RAG 技术不断演进，以适应更复杂的任务和场景需求  Naive RAG Naive RAG 是最基础的形式，依赖核心的索引和检索策略来增强生成模型的输出 Naive RAG 适用于一些基础任务和产品 MVP 阶段  Advanced RAG 通过增加检索前、检索中以及检索后的优化策略，提高检索的准确性和生成的关联性 - 适用于复杂任务    Advanced RAG 通过优化检索前、检索中、检索后的各个环节 在索引质量、检索效果以及生成内容的上下文相关性方面都取得显著提升  检索前 通过索引、分块、查询优化和内容向量化等技术手段，提高检索内容的精确性和生成内容的相关性  滑动窗口 overlap   经典的 Chunking 技术，通过在相邻的 Chunk 之间创建重叠区域，确保关键信息不会因简单的 Chunking 而丢失 在 ...</div></div></div></a><a class="pagination-related" href="/2024/08/15/rag-optimization-evaluation/" title="RAG - Optimization + Evaluation"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-evaluation.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-15</div><div class="info-item-2">RAG - Optimization + Evaluation</div></div><div class="info-2"><div class="info-item-1">RAG   检索优化数据清洗和预处理 在 RAG 索引流程中，文档解析之后，文档切块之前，进行数据清洗和预处理 减少脏数据和噪音，提升文本的整体质量和信息密度   手段：清除冗余信息、统一格式、处理异常字符等 处理冗余的模板内容 消除文档中的额外空白和格式不一致 去除文档脚注、页眉页脚、版权信息    查询扩写 在 RAG 系统的检索步骤中，用户的查询会转换为向量后进行检索 单个向量查询只能覆盖向量空间中一个有限区域 如果查询中的嵌入向量未能包含所有关键信息，则可能检索到不相关的 Chunk 单点查询的局限性 - 限制系统在庞大文档库中的搜索范围，导致错失与查询语义相关的内容   查询扩写 通过 LLM 从原始查询语句生成多个语义相关的查询，可以覆盖向量空间中的不同区域 提高检索的全面性和准确性 扩写后的查询在被嵌入后，能够击中不同的语义区域 确保系统能够从更广泛的文档中检索到与用户需求相关的有用信息     通过查询扩写，原始问题被分解为多个子查询 每个子查询独立检索相关文档并生成相应的结果 系统将所有子查询的检索结果进行合并和重新排序   能够有效扩展用户的查询意图，确保在复杂信息库中进行更全面的文...</div></div></div></a><a class="pagination-related" href="/2024/08/14/rag-llm-prompt-engineering/" title="RAG - LLM + Prompt Engineering"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/llm-prompting.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-14</div><div class="info-item-2">RAG - LLM + Prompt Engineering</div></div><div class="info-2"><div class="info-item-1">RAG 生成流程    经过 RAG 索引流程（外部知识的解析和向量化）和 RAG 检索流程（语义相似性的匹配及混合检索），进入到 RAG 生成流程 在 RAG 生成流程中，需要组合指令，即携带查询问题及检索到的相关信息输入的 LLM，由 LLM 理解并生成最终的回复 RAG 的本质是通过 LLM 提供外部知识来增强其理解和回答领域问题的能力 LLM 在 RAG 系统中起到了大脑的作用 在面对复杂且多样化的 RAG 任务时，LLM 的性能直接决定了系统的整体效果   提示词工程是生成流程中的另一个关键环节 通过有效的指令的设计和组合，可以帮助 LLM 更好地理解输入内容，从而生成更加精确和相关的回答 精心设计的问题提示词，往往能提升生成效果    LLM发展  RAG 目前更关注通用大模型   原理 Google 于 2017 年发布论文 Attention Is All You Need，引入了 Transformer 模型 Transformer 模型是深度学习领域的一个突破性架构，LLM 的成功得益于对 Transformer 模型的应用 与传统的 RNN（循环神经网络） 相比，Transform...</div></div></div></a><a class="pagination-related" href="/2024/08/13/rag-hybrid-retrieval-rerank/" title="RAG - Hybrid retrieval + Rerank"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-rerank-9097303.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-13</div><div class="info-item-2">RAG - Hybrid retrieval + Rerank</div></div><div class="info-2"><div class="info-item-1">向量检索 当前主流的 RAG 检索方式主要采用向量检索，通过语义相似度来匹配 Chunk 向量检索并非万能，在某些场景下无法替代传统关键词检索的优势 当需要精准搜索的时候，向量检索的准确性就往往不如关键词检索 当用户输入的问题非常简短，语义匹配的效果可能不尽理想   关键词检索的适用场景 精确匹配 少量字符的匹配 - 不适合用向量检索 低频词汇的匹配       混合检索 结合关键词检索和语义匹配的优势   在 RAG 检索场景中，首要目标是确保最相关的结果能够出现在候选列表中 向量检索和关键词检索各具优势，混合检索通过结合多种检索技术，弥补各自不足，提供一种更加全面的搜索方案 重排序技术在检索系统中扮演着至关重要的角色 即使检索算法已经能够捕捉到所有相关的结果，重排序过程依然不可或缺 确保最符合用户意图和查询语义的结果优先展示，提升用户的搜索体验和结果的准确性     在多个数据集和多个检索任务中，混合检索和重排序的组合均取得了最佳表现     融合检索 &#x2F; 多路召回    https://python.langchain.com/v0.2/api_reference/community/r...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">zhongmingmao</div><div class="author-info-description">Focus on Infrastructure.</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">642</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="mailto:zhongmingmao0625@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Things are always unexpected!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chunking"><span class="toc-number">2.</span> <span class="toc-text">Chunking</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BD%B1%E5%93%8D"><span class="toc-number">2.1.</span> <span class="toc-text">影响</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%BA%E5%AF%B8"><span class="toc-number">2.2.</span> <span class="toc-text">尺寸</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AD%96%E7%95%A5"><span class="toc-number">2.3.</span> <span class="toc-text">策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Fixed-Size"><span class="toc-number">2.3.1.</span> <span class="toc-text">Fixed Size</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-1"><span class="toc-number">2.3.1.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF"><span class="toc-number">2.3.1.2.</span> <span class="toc-text">场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-number">2.3.1.3.</span> <span class="toc-text">问题</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Overlap"><span class="toc-number">2.3.2.</span> <span class="toc-text">Overlap</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-2"><span class="toc-number">2.3.2.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF-1"><span class="toc-number">2.3.2.2.</span> <span class="toc-text">场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98-1"><span class="toc-number">2.3.2.3.</span> <span class="toc-text">问题</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Recursive"><span class="toc-number">2.3.3.</span> <span class="toc-text">Recursive</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-3"><span class="toc-number">2.3.3.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF-2"><span class="toc-number">2.3.3.2.</span> <span class="toc-text">场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98-2"><span class="toc-number">2.3.3.3.</span> <span class="toc-text">问题</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Document-Specific"><span class="toc-number">2.3.4.</span> <span class="toc-text">Document Specific</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-4"><span class="toc-number">2.3.4.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF-3"><span class="toc-number">2.3.4.2.</span> <span class="toc-text">场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98-3"><span class="toc-number">2.3.4.3.</span> <span class="toc-text">问题</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Semantic"><span class="toc-number">2.3.5.</span> <span class="toc-text">Semantic</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-5"><span class="toc-number">2.3.5.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF-4"><span class="toc-number">2.3.5.2.</span> <span class="toc-text">场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98-4"><span class="toc-number">2.3.5.3.</span> <span class="toc-text">问题</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Mix"><span class="toc-number">2.3.6.</span> <span class="toc-text">Mix</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-6"><span class="toc-number">2.3.6.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF-5"><span class="toc-number">2.3.6.2.</span> <span class="toc-text">场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98-5"><span class="toc-number">2.3.6.3.</span> <span class="toc-text">问题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E8%B7%B5"><span class="toc-number">2.4.</span> <span class="toc-text">实践</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#LangChain"><span class="toc-number">2.4.1.</span> <span class="toc-text">LangChain</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dependency"><span class="toc-number">2.4.2.</span> <span class="toc-text">Dependency</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TextSplitter"><span class="toc-number">2.4.3.</span> <span class="toc-text">TextSplitter</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Embedding"><span class="toc-number">3.</span> <span class="toc-text">Embedding</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-7"><span class="toc-number">3.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.</span> <span class="toc-text">模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RAG"><span class="toc-number">3.3.</span> <span class="toc-text">RAG</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0"><span class="toc-number">3.4.</span> <span class="toc-text">评估</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E8%B7%B5-1"><span class="toc-number">3.5.</span> <span class="toc-text">实践</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/01/24/cloud-native-observability-prometheus-server-v1/" title="Observability - Prometheus Server V1"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/prometheus-server.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - Prometheus Server V1"/></a><div class="content"><a class="title" href="/2025/01/24/cloud-native-observability-prometheus-server-v1/" title="Observability - Prometheus Server V1">Observability - Prometheus Server V1</a><time datetime="2025-01-23T16:06:25.000Z" title="Created 2025-01-24 00:06:25">2025-01-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/23/cloud-native-observability-prometheus-concepts/" title="Observability - Prometheus Concepts"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/prometheus-concepts.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - Prometheus Concepts"/></a><div class="content"><a class="title" href="/2025/01/23/cloud-native-observability-prometheus-concepts/" title="Observability - Prometheus Concepts">Observability - Prometheus Concepts</a><time datetime="2025-01-22T16:06:25.000Z" title="Created 2025-01-23 00:06:25">2025-01-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/22/cloud-native-observability-prometheus-introduction/" title="Observability - Prometheus Introduction"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/prometheus.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - Prometheus Introduction"/></a><div class="content"><a class="title" href="/2025/01/22/cloud-native-observability-prometheus-introduction/" title="Observability - Prometheus Introduction">Observability - Prometheus Introduction</a><time datetime="2025-01-21T16:06:25.000Z" title="Created 2025-01-22 00:06:25">2025-01-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java-agent.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java Zero Code"/></a><div class="content"><a class="title" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code">Observability - OpenTelemetry Java Zero Code</a><time datetime="2025-01-20T16:06:25.000Z" title="Created 2025-01-21 00:06:25">2025-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java"/></a><div class="content"><a class="title" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java">Observability - OpenTelemetry Java</a><time datetime="2025-01-19T16:06:25.000Z" title="Created 2025-01-20 00:06:25">2025-01-20</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2015 - 2025 By zhongmingmao</span></div><div class="footer_custom_text">Life is like a box of chocolates. You can't know what you'll eat until you open it.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional and Simplified Chinese">繁</button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script></div></body></html>