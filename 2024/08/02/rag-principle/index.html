<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>RAG -Principle | ByteCoding</title><meta name="author" content="zhongmingmao"><meta name="copyright" content="zhongmingmao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="LLM 局限 当设计一个 LLM 问答应用，模型需要处理用户的领域问题时，LLM 通常表现出色 但有时提供的答案并不准确，甚至出现错误 当用户需要获取实时信息时，LLM 无法及时提供最新的答案 LLM 在知识、理解和推理方面展现了卓越的能力，在复杂交互场景中表现尤为突出 LLM 存在无法忽略的局限性">
<meta property="og:type" content="article">
<meta property="og:title" content="RAG -Principle">
<meta property="og:url" content="https://blog.zhongmingmao.top/2024/08/02/rag-principle/index.html">
<meta property="og:site_name" content="ByteCoding">
<meta property="og:description" content="LLM 局限 当设计一个 LLM 问答应用，模型需要处理用户的领域问题时，LLM 通常表现出色 但有时提供的答案并不准确，甚至出现错误 当用户需要获取实时信息时，LLM 无法及时提供最新的答案 LLM 在知识、理解和推理方面展现了卓越的能力，在复杂交互场景中表现尤为突出 LLM 存在无法忽略的局限性">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-principle-4736980.png">
<meta property="article:published_time" content="2024-08-01T16:06:25.000Z">
<meta property="article:modified_time" content="2024-08-27T09:47:40.614Z">
<meta property="article:author" content="zhongmingmao">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="RAG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-principle-4736980.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "RAG -Principle",
  "url": "https://blog.zhongmingmao.top/2024/08/02/rag-principle/",
  "image": "https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-principle-4736980.png",
  "datePublished": "2024-08-01T16:06:25.000Z",
  "dateModified": "2024-08-27T09:47:40.614Z",
  "author": [
    {
      "@type": "Person",
      "name": "zhongmingmao",
      "url": "https://blog.zhongmingmao.top"
    }
  ]
}</script><link rel="shortcut icon" href="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png"><link rel="canonical" href="https://blog.zhongmingmao.top/2024/08/02/rag-principle/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":32,"languages":{"author":"Author: zhongmingmao","link":"Link: ","source":"Source: ByteCoding","info":"Copyright belongs to the author. For commercial use, please contact the author for authorization. For non-commercial use, please indicate the source."}},
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'RAG -Principle',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="ByteCoding" type="application/atom+xml">
</head><body><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js/themes/blue/pace-theme-minimal.min.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg" style="background-image: url(/url(https:/cdn.pixabay.com/photo/2021/07/20/03/39/fisherman-6479663_1280.jpg));"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">641</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-principle-4736980.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">ByteCoding</span></a><a class="nav-page-title" href="/"><span class="site-name">RAG -Principle</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">RAG -Principle</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">Created</span><time datetime="2024-08-01T16:06:25.000Z" title="Created 2024-08-02 00:06:25">2024-08-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ai/">AI</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ai/rag/">RAG</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">1.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>5mins</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:512,&quot;messagePrev&quot;:&quot;It has been&quot;,&quot;messageNext&quot;:&quot;days since the last update, the content of the article may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2024-08-27 17:47:40&quot;}" hidden></div><h1 id="LLM-局限"><a href="#LLM-局限" class="headerlink" title="LLM 局限"></a>LLM 局限</h1><ol>
<li>当设计一个 LLM <strong>问答</strong>应用，模型需要处理用户的<strong>领域问题</strong>时，LLM <strong>通常</strong>表现<strong>出色</strong></li>
<li>但有时提供的答案并<strong>不准确</strong>，甚至出现<strong>错误</strong></li>
<li>当用户需要<strong>获取实时信息</strong>时，LLM 无法及时提供最新的答案</li>
<li>LLM 在<strong>知识</strong>、<strong>理解</strong>和<strong>推理</strong>方面展现了<strong>卓越</strong>的能力，在<strong>复杂交互场景</strong>中表现尤为突出</li>
<li>LLM 存在无法忽略的局限性</li>
</ol>
<span id="more"></span>

<blockquote>
<p>LLM 局限</p>
</blockquote>
<table>
<thead>
<tr>
<th>Limitation</th>
<th>Desc</th>
</tr>
</thead>
<tbody><tr>
<td><strong>领域知识</strong>缺乏</td>
<td>LLM 的知识来源于<strong>训练数据</strong>，主要为<strong>公开数据集</strong>，无法覆盖<strong>特定领域</strong>或<strong>高度专业化</strong>的内部知识</td>
</tr>
<tr>
<td>信息<strong>过时</strong></td>
<td>LLM 难以处理<strong>实时信息</strong>，训练过程<strong>耗时</strong>且<strong>成本高昂</strong>，模型一旦训练完成，就难以处理和获取信息</td>
</tr>
<tr>
<td><strong>幻觉</strong></td>
<td>模型基于<strong>概率</strong>生成文本，有时会输出<strong>看似合理</strong>但<strong>实际错误</strong>的答案</td>
</tr>
<tr>
<td><strong>数据安全</strong></td>
<td>需要在<strong>确保数据安全</strong>的前提下，使 LLM 有效利用<strong>私有数据</strong>进行<strong>推理</strong>和<strong>生成</strong></td>
</tr>
</tbody></table>
<blockquote>
<p>RAG 应运而生</p>
</blockquote>
<ol>
<li>将<strong>非参数化</strong>的<strong>外部知识库和文档</strong>与 LLM 结合</li>
<li>RAG 使 LLM 在<strong>生成内容之前</strong>，能够<strong>先检索</strong>相关信息<ul>
<li>弥补 LLM 在<strong>知识专业性</strong>和<strong>时效性</strong>的不足</li>
<li>在确保<strong>数据安全</strong>的同时，充分利用<strong>领域知识</strong>和<strong>私有数据</strong></li>
</ul>
</li>
</ol>
<blockquote>
<p>选择 <strong>RAG</strong> 而不是直接将<strong>所有知识库数据</strong>交给 LLM</p>
</blockquote>
<ol>
<li>LLM 能够处理的 <strong>Token 数有限</strong>，输入过多的 Token 会<strong>增加成本</strong></li>
<li>提供少量相关的<strong>关键信息</strong>能够带来<strong>更优质的回答</strong></li>
</ol>
<blockquote>
<p>将相关的<strong>实时信息</strong>转化为<strong>知识库内容</strong>，并通过<strong>检索模块</strong>检索到与用户查询<strong>高度相关</strong>的文档片段，提供<strong>更有价值的回答</strong></p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/5f10a52ebc4d00ed4bc3ceyy756c6d0a.png" alt="5f10a52ebc4d00ed4bc3ceyy756c6d0a"></p>
<h1 id="RAG-定义"><a href="#RAG-定义" class="headerlink" title="RAG 定义"></a>RAG 定义</h1><ol>
<li>RAG 是一种结合<strong>检索</strong>和<strong>生成</strong>的 <strong>NLP</strong> 模型架构</li>
<li>RAG 由 <strong>Facebook AI</strong> 于 <strong>2022</strong> 提出，主要是为了提升<strong>生成式模型</strong>在处理<strong>开放域问答</strong>、<strong>对话生成</strong>等复杂任务中的性能</li>
<li>RAG 通过引入<strong>外部知识库</strong><ul>
<li>利用检索模块（<strong>Retriever</strong>）从<strong>大量文档</strong>中<strong>提取相关信息</strong></li>
<li>然后将这些信息<strong>传递</strong>给生成模块（<strong>Generator</strong>），从而生成更<strong>准确</strong>且<strong>有用</strong>的回答</li>
</ul>
</li>
<li>核心思想 - 通过<strong>检索</strong>与<strong>生成</strong>的有机结合，弥补 <strong>LLM</strong> 在处理<strong>领域问题</strong>和<strong>实时任务</strong>时的不足<ul>
<li><strong>传统</strong>的<strong>生成模型</strong>在面对<strong>复杂问题</strong>时，由于<strong>知识储备不足</strong>，会生成出<strong>错误</strong>或<strong>无关</strong>的回答</li>
<li><strong>RAG</strong> 通过 <strong>Retriever</strong> 获取<strong>相关的背景信息</strong>，使 <strong>Generator</strong> 能够<strong>参考这些信息</strong>，生成更具<strong>可信度</strong>和<strong>准确性</strong>的答案</li>
<li>增强了生成内容的<strong>准确性</strong>，提高了 LLM 在应对<strong>特定领域知识</strong>和<strong>动态信息</strong>的<strong>适应能力</strong></li>
</ul>
</li>
</ol>
<h1 id="RAG-应用"><a href="#RAG-应用" class="headerlink" title="RAG 应用"></a>RAG 应用</h1><blockquote>
<p>RAG 的应用有效<strong>优化</strong>了 <strong>LLM 的固有缺陷</strong>，为 LLM 应用提供了<strong>更高的可靠性</strong>和<strong>场景可落地性</strong></p>
</blockquote>
<ol>
<li><strong>RAG</strong> 结合了<strong>检索</strong>和<strong>生成</strong>，满足了 <strong>LLM</strong> 在<strong>实时性</strong>、<strong>高准确性</strong>和<strong>领域专有知识获取</strong>的需求</li>
<li><strong>企业</strong>或<strong>领域</strong>的<strong>知识管理</strong>与<strong>问答系统</strong><ul>
<li>RAG 能<strong>实时</strong>从<strong>企业</strong>或<strong>领域</strong>的<strong>私有知识库</strong>中检索相关信息</li>
<li>确保生成的回答不仅<strong>准确</strong>且符合企业内部的<strong>最新动态</strong>，解决了 LLM 在处理特定领域知识时的局限性</li>
</ul>
</li>
<li><strong>客户支持</strong>与智能<strong>客服</strong>系统<ul>
<li>RAG 可以动态地将<strong>用户的询问</strong>与最新的产品信息、客服知识等<strong>外部数据</strong>相结合</li>
<li>生成的回答更加<strong>贴合用户的实际需求</strong>，且满足企业需求</li>
</ul>
</li>
<li><strong>医疗 + 金融</strong><ul>
<li>对<strong>数据准确性</strong>和<strong>时效性</strong>有极高的要求，RAG 通过<strong>实时检索最新</strong>的研究成果、市场动态或文档资料</li>
<li>RAG 确保生成的内容不仅<strong>基于最新信息</strong>，同时具备<strong>领域专有知识</strong>的<strong>深度分析</strong>能力</li>
</ul>
</li>
</ol>
<h1 id="RAG-流程"><a href="#RAG-流程" class="headerlink" title="RAG 流程"></a>RAG 流程</h1><blockquote>
<p>实现了<strong>检索</strong>和<strong>生成</strong>的有机结合，显著提升了 <strong>LLM</strong> 在<strong>领域任务</strong>中的<strong>准确性</strong>和<strong>实时性</strong></p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/7bc529003e05a3ab0561204230a83bdc.png" alt="7bc529003e05a3ab0561204230a83bdc"></p>
<h2 id="Indexing"><a href="#Indexing" class="headerlink" title="Indexing"></a>Indexing</h2><blockquote>
<p>将<strong>外部文档</strong>转化为<strong>可检索的向量</strong>，支撑后续的<strong>检索</strong>和<strong>生成</strong>环节</p>
</blockquote>
<ol>
<li>将各类数据源及其格式统一解析为<strong>纯文本</strong>格式</li>
<li>根据文本的<strong>语义</strong>或<strong>结构</strong>，将文档分割成为<strong>小而语义完整</strong>的<strong>文本块</strong>（<strong>chunk</strong>）<ul>
<li>确保系统能够<strong>高效检索和利用</strong> chunk 中包含的<strong>信息</strong></li>
</ul>
</li>
<li>然后，使用<strong>文本嵌入模型</strong>（<strong>embedding model</strong>），将这些 <strong>chunk</strong> 进行<strong>向量化</strong><ul>
<li>生成<strong>高维稠密向量</strong>，转换为<strong>计算机</strong>能够<strong>理解</strong>的<strong>语义表示</strong></li>
</ul>
</li>
<li>最后，将这些<strong>向量</strong>存储在<strong>向量数据库</strong>（<strong>vector database</strong>）中，并<strong>构建索引</strong>，完成<strong>知识库</strong>的<strong>构建</strong></li>
</ol>
<h2 id="Retrieval"><a href="#Retrieval" class="headerlink" title="Retrieval"></a>Retrieval</h2><blockquote>
<p>连接<strong>用户查询</strong>和<strong>知识库</strong></p>
</blockquote>
<ol>
<li>将用户<strong>查询</strong>（<strong>query</strong>）通过<strong>同样</strong>的<strong>文本嵌入模型</strong>（<strong>embedding model</strong>）转换为<strong>向量</strong>表示<ul>
<li>将查询（query）<strong>映射</strong>到知识库内容<strong>相同</strong>的<strong>向量空间</strong>中</li>
</ul>
</li>
<li>通过<strong>相似度</strong>度量方法，<strong>Retriever</strong> 从<strong>向量数据库</strong>中筛选出与 query <strong>最相关</strong>的前 K 个 <strong>chunk</strong><ul>
<li>通过<strong>相似性搜索</strong>，Retriever 有效获取了与 query <strong>切实相关</strong>的<strong>外部知识</strong></li>
<li>为<strong>生成阶段</strong>提供了<strong>精确</strong>且<strong>有意义</strong>的<strong>上下文支持</strong></li>
</ul>
</li>
<li>这些 <strong>chunk</strong> 将作为<strong>生成阶段输入</strong>的一部分</li>
</ol>
<h2 id="Generation"><a href="#Generation" class="headerlink" title="Generation"></a>Generation</h2><blockquote>
<p>具备<strong>领域知识</strong>和<strong>私有信息</strong>的<strong>精确内容生成</strong></p>
</blockquote>
<ol>
<li>检索到的<strong>文本块</strong>（<strong>chunk</strong>）与<strong>原始查询</strong>（<strong>query</strong>）共同构成<strong>增强提示词</strong>（<strong>prompt</strong>），输入到 <strong>LLM</strong></li>
<li>LLM 生成<strong>精确</strong>且具备<strong>上下文关联</strong>的回答<ul>
<li>符合用户的<strong>查询意图</strong> + 充分利用<strong>检索到的上下文信息</strong></li>
</ul>
</li>
</ol>
<h1 id="RAG-vs-Fine-tuning"><a href="#RAG-vs-Fine-tuning" class="headerlink" title="RAG vs Fine-tuning"></a>RAG vs Fine-tuning</h1><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-fine-tuning.png" alt="rag-fine-tuning"></p>
<ol>
<li>在 LLM <strong>专业领域</strong>场景的应用中，<strong>RAG</strong>（<strong>外部知识</strong>） 和 <strong>Fine-tuning</strong>（<strong>领域能力</strong>） 都是可行的选择</li>
<li><strong>RAG</strong> - 外部知识 - 动态响应 - 频繁更新<ul>
<li>场景 - <strong>频繁</strong>处理<strong>实时</strong>信息、回答<strong>复杂</strong>且<strong>依赖外部知识</strong>的问题、回答需具备<strong>可解释性</strong></li>
<li>RAG 通过结合<strong>检索系统</strong>和<strong>生成模型</strong>，能够<strong>实时利用最新信息</strong>，生成<strong>上下文相关</strong>且<strong>准确</strong>的答案</li>
</ul>
</li>
<li><strong>Fine-tuning</strong> - 领域能力 - 深度优化推理<ul>
<li>场景 - 需求<strong>稳定</strong>、领域知识<strong>固定</strong>、不需要频繁更新知识库的场景</li>
<li>通过使用<strong>特定领域的数据</strong>对<strong>模型</strong>进行<strong>深度优化</strong></li>
<li>Fine-tuning 可以提升模型在<strong>特定</strong>任务或领域中的<strong>推理</strong>能力，确保输出内容的<strong>专业性</strong>和<strong>一致性</strong></li>
</ul>
</li>
</ol>
<blockquote>
<p>如果即需要利用最新的外部知识，又需要保持高水平的领域推理能力，可以<strong>结合 RAG 和 Fine-tuning</strong>，以实现最佳的性能和效果</p>
</blockquote>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top">zhongmingmao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top/2024/08/02/rag-principle/">https://blog.zhongmingmao.top/2024/08/02/rag-principle/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ai/">AI</a><a class="post-meta__tags" href="/tags/llm/">LLM</a><a class="post-meta__tags" href="/tags/rag/">RAG</a></div><div class="post-share"><div class="social-share" data-image="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-principle-4736980.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/08/03/rag-in-action/" title="RAG - In Action"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-in-action.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">RAG - In Action</div></div><div class="info-2"><div class="info-item-1">技术选型LangChain LangChain 是专门为开发基于 LLM 应用而设计的全面框架 LangChain 的核心目标是简化开发者的构建流程，使其能够高效地创建 LLM 驱动的应用    索引文档解析 pypdf 专门用于处理 PDF 文档 pypdf 支持 PDF 文档的创建、读取、编辑和转换，能够有效地提取和处理文本、图像及页面内容  文档分块 RecursiveCharacterTextSplitter 是 LangChain 默认的文本分割器 RecursiveCharacterTextSplitter 通过层次化的分隔符（从双换行符到单字符）拆分文本 旨在保持文本的结构和连贯性，优先考虑自然边界（如段落和句子）    索引 + 检索向量化模型 bge-small-zh-v1.5 是由北京智源人工智能研究院（BAAI）开发的开源向量模型 bge-small-zh-v1.5 的模型体积较小，但仍能提供高精度和高效的中文向量检索 bge-small-zh-v1.5 的向量维度为 512，最大输入长度同样为 512  向量库 Faiss - Facebook AI Similarity Sea...</div></div></div></a><a class="pagination-related" href="/2024/08/01/rag-ai-2/" title="RAG - AI 2.0"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-ai-2.0.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">RAG - AI 2.0</div></div><div class="info-2"><div class="info-item-1">AI 技术 做 AI 产品的工程研发需充分掌握 AI 技术 AI 产品从 MVP 到 PMF 的演进过程中会面临非常多的挑战 MVP - Minimum Viable Product - 最小可用产品 PMF - Product-Market Fit - 产品市场契合   要实现 AI 产品的 PMF 首先需要充分了解 AI 技术，明确技术边界，找到合适 AI 技术的应用场景 其次，需要深刻理解业务，用户需求决定产品方向，AI 技术是为业务服务的工具   在验证阶段，优先使用最佳 AI 模型以确保产品满足市场需求，确认后再逐步降低模型成本 坚持业务优先、价值至上的原则，避免纯 AI 科研化，脱离实际场景做 AI 技术选型    RAG LLM 局限 - 幻觉 + 知识实效性 + 领域知识不足 + 数据安全问题   由 OpenAI ChatGPT 引领的 AI 2.0 LLM 时代，见证了 LLM 在知识、逻辑、推理能力上的突破 Scaling Law、压缩产生智能、边际成本为零为理想中的 AGI 尽管 LLM 功能强大，但仍存在幻觉、知识实效性、领域知识不足以及数据安全问题的局限性 - RAG 文档问...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/09/09/rag-vector-qdrant/" title="RAG - Qdrant"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/qdrant.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-09</div><div class="info-item-2">RAG - Qdrant</div></div><div class="info-2"><div class="info-item-1">Features   Getting StartedIntroduction Vector databases are a relatively new way for interacting with abstract data representations derived from opaque machine learning models such as deep learning architectures. These representations are often called vectors or embeddings and they are a compressed version of the data used to train a machine learning model to accomplish a task like sentiment analysis, speech recognition, object detection, and many others.  What is Qdrant? Qdrant “is a vector similarity s...</div></div></div></a><a class="pagination-related" href="/2024/08/17/rag-graphrag/" title="RAG - GraphRAG"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/graphrag-9781829.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-17</div><div class="info-item-2">RAG - GraphRAG</div></div><div class="info-2"><div class="info-item-1">向量检索 信息片段之间的连接能力有限   RAG 在跨越多个信息片段以获取综合见解时表现不足 当要回答一个复杂问题时，必须要通过共享属性在不同信息之间建立联系 RAG 无法有效捕捉这些关系 限制了 RAG 在处理需要多跳推理或整合多源数据的复杂查询时的能力       归纳总结能力不足   在处理大型数据集或长文档时，RAG 难以有效地归纳和总结复杂的语义概念 RAG 在需要全面理解和总结复杂语义信息的场景中表现不佳  GraphRAG 利用 LLM 生成的知识图谱来改进 RAG 的检索部分   GraphRAG 利用结构化的实体和关系信息，使得检索过程更加精准和全面 GraphRAG 在处理多跳问题和复杂文档分析时表现出色 GraphRAG 在处理复杂信息处理任务时，显著提升问答性能，提供比 RAG 更为准确和全面的答案 GraphRAG 通过知识图谱有效地连接不同的信息片段 不仅能够提供准确答案，还能展示答案之间的内在联系，提供更丰富和有价值的结果     GraphRAG 先利用知识图谱，关联查询的实体和关系从与知识图谱实体直接相关的文档中检索片段，提供一个更全面、指标化、高信息密度的总结   主...</div></div></div></a><a class="pagination-related" href="/2024/08/16/rag-evolution/" title="RAG - Evolution"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-evolution.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-16</div><div class="info-item-2">RAG - Evolution</div></div><div class="info-2"><div class="info-item-1">演进    Naive RAG -&gt; Advanced RAG -&gt; Modular RAG 三个范式之间具有继承与发展的关系 Advanced RAG 是 Modular RAG 的一种特例形式 Naive RAG 是 Advanced RAG 的基础特例   RAG 技术不断演进，以适应更复杂的任务和场景需求  Naive RAG Naive RAG 是最基础的形式，依赖核心的索引和检索策略来增强生成模型的输出 Naive RAG 适用于一些基础任务和产品 MVP 阶段  Advanced RAG 通过增加检索前、检索中以及检索后的优化策略，提高检索的准确性和生成的关联性 - 适用于复杂任务    Advanced RAG 通过优化检索前、检索中、检索后的各个环节 在索引质量、检索效果以及生成内容的上下文相关性方面都取得显著提升  检索前 通过索引、分块、查询优化和内容向量化等技术手段，提高检索内容的精确性和生成内容的相关性  滑动窗口 overlap   经典的 Chunking 技术，通过在相邻的 Chunk 之间创建重叠区域，确保关键信息不会因简单的 Chunking 而丢失 在 ...</div></div></div></a><a class="pagination-related" href="/2024/08/15/rag-optimization-evaluation/" title="RAG - Optimization + Evaluation"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-evaluation.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-15</div><div class="info-item-2">RAG - Optimization + Evaluation</div></div><div class="info-2"><div class="info-item-1">RAG   检索优化数据清洗和预处理 在 RAG 索引流程中，文档解析之后，文档切块之前，进行数据清洗和预处理 减少脏数据和噪音，提升文本的整体质量和信息密度   手段：清除冗余信息、统一格式、处理异常字符等 处理冗余的模板内容 消除文档中的额外空白和格式不一致 去除文档脚注、页眉页脚、版权信息    查询扩写 在 RAG 系统的检索步骤中，用户的查询会转换为向量后进行检索 单个向量查询只能覆盖向量空间中一个有限区域 如果查询中的嵌入向量未能包含所有关键信息，则可能检索到不相关的 Chunk 单点查询的局限性 - 限制系统在庞大文档库中的搜索范围，导致错失与查询语义相关的内容   查询扩写 通过 LLM 从原始查询语句生成多个语义相关的查询，可以覆盖向量空间中的不同区域 提高检索的全面性和准确性 扩写后的查询在被嵌入后，能够击中不同的语义区域 确保系统能够从更广泛的文档中检索到与用户需求相关的有用信息     通过查询扩写，原始问题被分解为多个子查询 每个子查询独立检索相关文档并生成相应的结果 系统将所有子查询的检索结果进行合并和重新排序   能够有效扩展用户的查询意图，确保在复杂信息库中进行更全面的文...</div></div></div></a><a class="pagination-related" href="/2024/08/14/rag-llm-prompt-engineering/" title="RAG - LLM + Prompt Engineering"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/llm-prompting.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-14</div><div class="info-item-2">RAG - LLM + Prompt Engineering</div></div><div class="info-2"><div class="info-item-1">RAG 生成流程    经过 RAG 索引流程（外部知识的解析和向量化）和 RAG 检索流程（语义相似性的匹配及混合检索），进入到 RAG 生成流程 在 RAG 生成流程中，需要组合指令，即携带查询问题及检索到的相关信息输入的 LLM，由 LLM 理解并生成最终的回复 RAG 的本质是通过 LLM 提供外部知识来增强其理解和回答领域问题的能力 LLM 在 RAG 系统中起到了大脑的作用 在面对复杂且多样化的 RAG 任务时，LLM 的性能直接决定了系统的整体效果   提示词工程是生成流程中的另一个关键环节 通过有效的指令的设计和组合，可以帮助 LLM 更好地理解输入内容，从而生成更加精确和相关的回答 精心设计的问题提示词，往往能提升生成效果    LLM发展  RAG 目前更关注通用大模型   原理 Google 于 2017 年发布论文 Attention Is All You Need，引入了 Transformer 模型 Transformer 模型是深度学习领域的一个突破性架构，LLM 的成功得益于对 Transformer 模型的应用 与传统的 RNN（循环神经网络） 相比，Transform...</div></div></div></a><a class="pagination-related" href="/2024/08/13/rag-hybrid-retrieval-rerank/" title="RAG - Hybrid retrieval + Rerank"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-rerank-9097303.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-13</div><div class="info-item-2">RAG - Hybrid retrieval + Rerank</div></div><div class="info-2"><div class="info-item-1">向量检索 当前主流的 RAG 检索方式主要采用向量检索，通过语义相似度来匹配 Chunk 向量检索并非万能，在某些场景下无法替代传统关键词检索的优势 当需要精准搜索的时候，向量检索的准确性就往往不如关键词检索 当用户输入的问题非常简短，语义匹配的效果可能不尽理想   关键词检索的适用场景 精确匹配 少量字符的匹配 - 不适合用向量检索 低频词汇的匹配       混合检索 结合关键词检索和语义匹配的优势   在 RAG 检索场景中，首要目标是确保最相关的结果能够出现在候选列表中 向量检索和关键词检索各具优势，混合检索通过结合多种检索技术，弥补各自不足，提供一种更加全面的搜索方案 重排序技术在检索系统中扮演着至关重要的角色 即使检索算法已经能够捕捉到所有相关的结果，重排序过程依然不可或缺 确保最符合用户意图和查询语义的结果优先展示，提升用户的搜索体验和结果的准确性     在多个数据集和多个检索任务中，混合检索和重排序的组合均取得了最佳表现     融合检索 &#x2F; 多路召回    https://python.langchain.com/v0.2/api_reference/community/r...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">zhongmingmao</div><div class="author-info-description">Focus on Infrastructure.</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">641</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="mailto:zhongmingmao0625@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Things are always unexpected!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#LLM-%E5%B1%80%E9%99%90"><span class="toc-number">1.</span> <span class="toc-text">LLM 局限</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RAG-%E5%AE%9A%E4%B9%89"><span class="toc-number">2.</span> <span class="toc-text">RAG 定义</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RAG-%E5%BA%94%E7%94%A8"><span class="toc-number">3.</span> <span class="toc-text">RAG 应用</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RAG-%E6%B5%81%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">RAG 流程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Indexing"><span class="toc-number">4.1.</span> <span class="toc-text">Indexing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Retrieval"><span class="toc-number">4.2.</span> <span class="toc-text">Retrieval</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Generation"><span class="toc-number">4.3.</span> <span class="toc-text">Generation</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RAG-vs-Fine-tuning"><span class="toc-number">5.</span> <span class="toc-text">RAG vs Fine-tuning</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/01/23/cloud-native-observability-prometheus-concepts/" title="Observability - Prometheus Concepts"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/prometheus-concepts.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - Prometheus Concepts"/></a><div class="content"><a class="title" href="/2025/01/23/cloud-native-observability-prometheus-concepts/" title="Observability - Prometheus Concepts">Observability - Prometheus Concepts</a><time datetime="2025-01-22T16:06:25.000Z" title="Created 2025-01-23 00:06:25">2025-01-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/22/cloud-native-observability-prometheus-introduction/" title="Observability - Prometheus Introduction"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/prometheus.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - Prometheus Introduction"/></a><div class="content"><a class="title" href="/2025/01/22/cloud-native-observability-prometheus-introduction/" title="Observability - Prometheus Introduction">Observability - Prometheus Introduction</a><time datetime="2025-01-21T16:06:25.000Z" title="Created 2025-01-22 00:06:25">2025-01-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java-agent.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java Zero Code"/></a><div class="content"><a class="title" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code">Observability - OpenTelemetry Java Zero Code</a><time datetime="2025-01-20T16:06:25.000Z" title="Created 2025-01-21 00:06:25">2025-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java"/></a><div class="content"><a class="title" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java">Observability - OpenTelemetry Java</a><time datetime="2025-01-19T16:06:25.000Z" title="Created 2025-01-20 00:06:25">2025-01-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/19/ai-agent-overview-mcp/" title="AI Agent - MCP Overview"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/mcp.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AI Agent - MCP Overview"/></a><div class="content"><a class="title" href="/2025/01/19/ai-agent-overview-mcp/" title="AI Agent - MCP Overview">AI Agent - MCP Overview</a><time datetime="2025-01-18T16:06:25.000Z" title="Created 2025-01-19 00:06:25">2025-01-19</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2015 - 2025 By zhongmingmao</span></div><div class="footer_custom_text">Life is like a box of chocolates. You can't know what you'll eat until you open it.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional and Simplified Chinese">繁</button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script></div></body></html>