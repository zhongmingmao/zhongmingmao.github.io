<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>RAG - LangChain | ByteCoding</title><meta name="author" content="zhongmingmao"><meta name="copyright" content="zhongmingmao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="Practice">
<meta property="og:type" content="article">
<meta property="og:title" content="RAG - LangChain">
<meta property="og:url" content="https://blog.zhongmingmao.top/2024/08/04/rag-langchain/index.html">
<meta property="og:site_name" content="ByteCoding">
<meta property="og:description" content="Practice">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-agent.webp">
<meta property="article:published_time" content="2024-08-03T16:06:25.000Z">
<meta property="article:modified_time" content="2024-08-29T16:49:15.415Z">
<meta property="article:author" content="zhongmingmao">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="LangChain">
<meta property="article:tag" content="RAG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-agent.webp"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "RAG - LangChain",
  "url": "https://blog.zhongmingmao.top/2024/08/04/rag-langchain/",
  "image": "https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-agent.webp",
  "datePublished": "2024-08-03T16:06:25.000Z",
  "dateModified": "2024-08-29T16:49:15.415Z",
  "author": [
    {
      "@type": "Person",
      "name": "zhongmingmao",
      "url": "https://blog.zhongmingmao.top"
    }
  ]
}</script><link rel="shortcut icon" href="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png"><link rel="canonical" href="https://blog.zhongmingmao.top/2024/08/04/rag-langchain/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":32,"languages":{"author":"Author: zhongmingmao","link":"Link: ","source":"Source: ByteCoding","info":"Copyright belongs to the author. For commercial use, please contact the author for authorization. For non-commercial use, please indicate the source."}},
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'RAG - LangChain',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="ByteCoding" type="application/atom+xml">
</head><body><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js/themes/blue/pace-theme-minimal.min.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg" style="background-image: url(/url(https:/cdn.pixabay.com/photo/2021/07/20/03/39/fisherman-6479663_1280.jpg));"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">639</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-agent.webp);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">ByteCoding</span></a><a class="nav-page-title" href="/"><span class="site-name">RAG - LangChain</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">RAG - LangChain</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">Created</span><time datetime="2024-08-03T16:06:25.000Z" title="Created 2024-08-04 00:06:25">2024-08-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ai/">AI</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ai/rag/">RAG</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">2.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>9mins</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:512,&quot;messagePrev&quot;:&quot;It has been&quot;,&quot;messageNext&quot;:&quot;days since the last update, the content of the article may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2024-08-30 00:49:15&quot;}" hidden></div><h1 id="Practice"><a href="#Practice" class="headerlink" title="Practice"></a>Practice</h1><span id="more"></span>

<ol>
<li>LangChain RAG<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/rag-from-scratch">https://github.com/langchain-ai/rag-from-scratch</a></li>
</ul>
</li>
<li>RAG 如何随着长期 LLM 而改变<ul>
<li>Is RAG Really Dead?<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=SsHUNfhF32s">https://www.youtube.com/watch?v=SsHUNfhF32s</a></li>
</ul>
</li>
</ul>
</li>
<li>自适应 RAG<ul>
<li>根据复杂程度动态地将查询路由到不同的 RAG 方法 - <strong>Command-R</strong> @ <strong>LangGraph</strong></li>
<li>Adaptive RAG<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=04ighIjMcAI">https://www.youtube.com/watch?v=04ighIjMcAI</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_adaptive_rag_cohere.ipynb">https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_adaptive_rag_cohere.ipynb</a></li>
</ul>
</li>
<li>Paper<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.14403">https://arxiv.org/abs/2403.14403</a></li>
</ul>
</li>
</ul>
</li>
<li>Adaptive RAG<ul>
<li>在<strong>循环单元测试</strong>中<strong>自我纠正检索错误</strong>，以确定<strong>文档相关性</strong>并返回到<strong>网络搜索</strong></li>
<li>在 <strong>LangGraph</strong> 中实现 <strong>Mistral 7B + Ollama</strong>，以便在<strong>本地</strong>运行</li>
<li>Local CRAG + LangGraph<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=E2shqsYwxck">https://www.youtube.com/watch?v=E2shqsYwxck</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_crag.ipynb">https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_crag.ipynb</a></li>
</ul>
</li>
<li>Paper<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.15884.pdf">https://arxiv.org/pdf/2401.15884.pdf</a></li>
</ul>
</li>
</ul>
</li>
<li>Self-RAG<ul>
<li>Self-RAG and CRAG<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=pbAd8O1Lvm4">https://www.youtube.com/watch?v=pbAd8O1Lvm4</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_self_rag.ipynb">https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_self_rag.ipynb</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_self_rag_local.ipynb">https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_self_rag_local.ipynb</a></li>
</ul>
</li>
<li>Paper<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.11511">https://arxiv.org/abs/2310.11511</a></li>
</ul>
</li>
</ul>
</li>
<li>查询路由<ul>
<li>将问题引导至正确数据源的各种方法（如逻辑、语义等）</li>
<li>Routing<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=pfpIndq7Fi8">https://www.youtube.com/watch?v=pfpIndq7Fi8</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_10_and_11.ipynb">https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_10_and_11.ipynb</a></li>
</ul>
</li>
</ul>
</li>
<li>查询结构<ul>
<li>使用 LLM 将自然语言转换为 DSL（如 SQL 等）</li>
<li>Query Structuring<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=kl6NwWYxvbM">https://www.youtube.com/watch?v=kl6NwWYxvbM</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_10_and_11.ipynb">https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_10_and_11.ipynb</a></li>
</ul>
</li>
<li>Blog<ul>
<li><a target="_blank" rel="noopener" href="https://blog.langchain.dev/query-construction/">https://blog.langchain.dev/query-construction/</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/">https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/</a></li>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/use_cases/query_analysis/techniques/structuring/">https://python.langchain.com/v0.1/docs/use_cases/query_analysis/techniques/structuring/</a></li>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/self_query/">https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/self_query/</a></li>
</ul>
</li>
</ul>
</li>
<li>多表示索引<ul>
<li>使用 LLM 生成针对检索进行优化的文档摘要（命题）</li>
<li>嵌入这些摘要以进行相似性搜索，但将完整文档返回给 LLM 进行生成</li>
<li>Multi-Representation Indexing<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=gTCU9I6QqCE">https://www.youtube.com/watch?v=gTCU9I6QqCE</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_12_to_14.ipynb">https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_12_to_14.ipynb</a></li>
</ul>
</li>
<li>Paper<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.06648">https://arxiv.org/pdf/2312.06648</a></li>
</ul>
</li>
</ul>
</li>
<li>RAPTOR<ul>
<li>将语料库中的文档聚类，并递归地总结相似的文档</li>
<li>将它们全部编入索引，生成较低级别的文档和摘要</li>
<li>可以检索这些文档和摘要来回答更高级别的问题</li>
<li>RAPTOR<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=z_6EeA2LDSw">https://www.youtube.com/watch?v=z_6EeA2LDSw</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/cookbook/RAPTOR.ipynb">https://github.com/langchain-ai/langchain/blob/master/cookbook/RAPTOR.ipynb</a></li>
</ul>
</li>
<li>Paper<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.18059">https://arxiv.org/pdf/2401.18059</a></li>
</ul>
</li>
</ul>
</li>
<li>ColBERT Token 级检索<ul>
<li>使用受上下文影响的嵌入来提高文档和查询中每个 Token 的嵌入粒度</li>
<li>ColBERT<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=cN6S0Ehm7_8">https://www.youtube.com/watch?v=cN6S0Ehm7_8</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_12_to_14.ipynb">https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_12_to_14.ipynb</a></li>
</ul>
</li>
<li>Paper<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2004.12832">https://arxiv.org/abs/2004.12832</a></li>
</ul>
</li>
</ul>
</li>
<li>多次查询<ul>
<li>从多个角度重写用户问题，为每个重写的问题检索文档，返回所有查询的唯一文档</li>
<li>Query Translation – Multi Query<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=JChPi0CRnDY">https://www.youtube.com/watch?v=JChPi0CRnDY</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb">https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb</a></li>
</ul>
</li>
<li>Paper<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.14283">https://arxiv.org/pdf/2305.14283</a></li>
</ul>
</li>
</ul>
</li>
<li>RAG 融合<ul>
<li>从多个角度重写用户问题，检索每个重写问题的文档</li>
<li>并组合成多个搜索结果列表的排名，以使用倒数排名融合生成单一统一的排名</li>
<li>Query Translation – RAG Fusion<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=77qELPbNgxA">https://www.youtube.com/watch?v=77qELPbNgxA</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb">https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb</a></li>
</ul>
</li>
<li>Project<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/Raudaschl/rag-fusion">https://github.com/Raudaschl/rag-fusion</a></li>
</ul>
</li>
</ul>
</li>
<li>问题分解<ul>
<li>将问题分解成一组子问题</li>
<li>可以按串行解决（使用第一个问题的答案和检索来回答第二个问题）</li>
<li>也可以并行解决（将每个答案合并为最终答案）</li>
<li>各种工作，如从最少到最多提示和 IRCoT 提出了可以利用的想法</li>
<li>Query Translation – Decomposition<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=h0OPWlEOank">https://www.youtube.com/watch?v=h0OPWlEOank</a></li>
</ul>
</li>
<li>Paper<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2205.10625">https://arxiv.org/pdf/2205.10625</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2212.10509">https://arxiv.org/pdf/2212.10509</a></li>
</ul>
</li>
</ul>
</li>
<li>回退提示<ul>
<li>首先提示 LLM 提出一个关于高级概念或原则的通用后退问题，并检索相关事实</li>
<li>使用此基础来帮助回答用户问题</li>
<li>Query Translation – Step Back<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xn1jEjRyJ2U">https://www.youtube.com/watch?v=xn1jEjRyJ2U</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb">https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb</a></li>
</ul>
</li>
<li>Paper<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.06117">https://arxiv.org/pdf/2310.06117</a></li>
</ul>
</li>
</ul>
</li>
<li>HyDE 混合匹配<ul>
<li>LLM 将问题转换为回答问题的假设文档，使用嵌入的假设文档检索真实文档</li>
<li>前提是 doc-doc 相似性搜索可以产生更多相关匹配</li>
<li>Query Translation – HyDE<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=SaDzIVkYqyY">https://www.youtube.com/watch?v=SaDzIVkYqyY</a></li>
</ul>
</li>
<li>Code<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb">https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb</a></li>
</ul>
</li>
<li>Paper<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2212.10496">https://arxiv.org/abs/2212.10496</a></li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="Query-Translation"><a href="#Query-Translation" class="headerlink" title="Query Translation"></a>Query Translation</h1><blockquote>
<p>Query Translation - 侧重于重写或者修改问题以便于检索</p>
</blockquote>
<h2 id="Multi-Query"><a href="#Multi-Query" class="headerlink" title="Multi Query"></a>Multi Query</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/MultiQueryRetriever/">https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/MultiQueryRetriever/</a></p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829214748213.png" alt="image-20240829214748213"></p>
<ol>
<li>从多个角度重写用户问题，为每个重写的问题检索文档，返回所有查询的唯一文档</li>
<li>在实现上，将一个查询变成多个查询</li>
<li>本质上是用 LLM 生成 Query</li>
</ol>
<h2 id="RAG-Fusion"><a href="#RAG-Fusion" class="headerlink" title="RAG Fusion"></a>RAG Fusion</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829215802032.png" alt="image-20240829215802032"></p>
<ol>
<li>从多个角度重写用户问题，检索每个重写问题的文档，并组合多个搜索结果列表的排名</li>
<li>以使用倒数排名融合（<strong>RRF</strong>）生成单一统一的排名</li>
<li>核心思想 - 将多个召回查询的结果进行合并</li>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/cookbook/rag_fusion.ipynb">https://github.com/langchain-ai/langchain/blob/master/cookbook/rag_fusion.ipynb</a></li>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1">https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1</a></li>
</ol>
<h2 id="Decomposition"><a href="#Decomposition" class="headerlink" title="Decomposition"></a>Decomposition</h2><ol>
<li>将一个复杂问题分解成多个子问题</li>
<li>可以串行解决 - 使用前一个问题的答案和检索来回答第二个问题</li>
<li>可以并行解决 - 将每个答案合并为最终答案</li>
<li>Decomposition 是向下分解，与 Multi Query 不同</li>
</ol>
<blockquote>
<p>串行 - 迭代式回答 - 在问题分解的基础上，逐步迭代出答案<br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2205.10625">https://arxiv.org/pdf/2205.10625</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2212.10509">https://arxiv.org/pdf/2212.10509</a></p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829221026283.png" alt="image-20240829221026283"></p>
<blockquote>
<p>并行 - 让每个 SubQuery 分别进行处理，然后得到答案，再拼接成一个 <strong>QA Pairs Prompt</strong> 最终形成答案</p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829221229712.png" alt="image-20240829221229712"></p>
<h2 id="Step-Back"><a href="#Step-Back" class="headerlink" title="Step Back"></a>Step Back</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829221654689.png" alt="image-20240829221654689"></p>
<ol>
<li>首先提示 LLM 提出一个关于<strong>高级</strong>概念或原则的通用后退问题，并检索有关它们的相关事实</li>
<li>使用此基础来帮助回答用户问题</li>
<li>构成上包括<strong>抽象</strong>（<strong>Abstraction</strong>）和<strong>推理</strong>（<strong>Reasoning</strong>）两步<ul>
<li>给定一个问题，提示 LLM，找到回答该问题的一个<strong>前置</strong>问题</li>
<li>得到前置问题及其答案后，再将其整体和当前问题进行<strong>合并</strong>，最后送入 LLM 进行问答，得到最终答案</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.06117">https://arxiv.org/pdf/2310.06117</a></li>
</ol>
<h2 id="HyDE"><a href="#HyDE" class="headerlink" title="HyDE"></a>HyDE</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829223153087.png" alt="image-20240829223153087"></p>
<ol>
<li>LLM 将问题转换为回答问题的<strong>假设文档</strong>（很容易引入<strong>幻觉</strong>），使用嵌入的假设文档检索<strong>真实文档</strong></li>
<li>前提是 <strong>Doc-Doc</strong> 相似性搜索可以产生<strong>更多相关匹配</strong></li>
<li>由于 Query 和 Doc 之间是<strong>不对称检索</strong><ul>
<li>先根据 Query 生成一个 Doc，然后根据该 Doc 生成对应的 Embedding</li>
<li>再跟原先的 Docs 进行检索</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2212.10496">https://arxiv.org/abs/2212.10496</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/cookbook/hypothetical_document_embeddings.ipynb">https://github.com/langchain-ai/langchain/blob/master/cookbook/hypothetical_document_embeddings.ipynb</a></li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829224327060.png" alt="image-20240829224327060"></p>
<ol>
<li>每个 query 都有对应的 instruction</li>
<li>通过 ChatGPT 生成 generated document，然后以此进行召回，最后生成 real document</li>
</ol>
<h2 id="Routing"><a href="#Routing" class="headerlink" title="Routing"></a>Routing</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829225010521.png" alt="image-20240829225010521"></p>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829225117769.png" alt="image-20240829225117769"></p>
<ol>
<li>从获取 query 之后，所需要执行的问题<strong>意图分类</strong>的问题，处理的是<strong>问题域选择</strong>问题</li>
<li>可用方案 1 - <strong>Logical</strong> and <strong>Semantic</strong> routing - 基于<strong>逻辑</strong>和<strong>语义</strong>的路由分发<ul>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/use_cases/query_analysis/techniques/routing/#routing-to-multiple-indexes">https://python.langchain.com/v0.1/docs/use_cases/query_analysis/techniques/routing/#routing-to-multiple-indexes</a></li>
</ul>
</li>
<li>可用方案 2 - <strong>Semantic</strong> routing - 基于<strong>语义</strong>来实现分发</li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829230351685.png" alt="image-20240829230351685"></p>
<h2 id="Query-Structuring"><a href="#Query-Structuring" class="headerlink" title="Query Structuring"></a>Query Structuring</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829232333633.png" alt="image-20240829232333633"></p>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829232352441.png" alt="image-20240829232352441"></p>
<ol>
<li>不同的检索知识库，如 MySQL、GraphDB、VectorDB 的<strong>查询转换</strong></li>
<li>使用 LLM 将<strong>自然语言</strong>转换为其中一种 <strong>DSL</strong> - 借助 <strong>Text to SQL</strong> 模型</li>
<li><a target="_blank" rel="noopener" href="https://blog.langchain.dev/query-construction/">https://blog.langchain.dev/query-construction/</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/">https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/</a></li>
<li>可用方案 - query structuring for metadata filter - 基于元数据过滤器的问题构建<ol>
<li>许多<strong>向量化存储</strong>都包含<strong>元数据</strong>字段，可以根据元数据过滤特定的数据 Chunk</li>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/use_cases/query_analysis/techniques/structuring/">https://python.langchain.com/v0.1/docs/use_cases/query_analysis/techniques/structuring/</a></li>
</ol>
</li>
</ol>
<h2 id="Indexing"><a href="#Indexing" class="headerlink" title="Indexing"></a>Indexing</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829232418483.png" alt="image-20240829232418483"></p>
<blockquote>
<p>先生成摘要，再索引</p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829232436647.png" alt="image-20240829232436647"></p>
<ol>
<li><a target="_blank" rel="noopener" href="https://blog.langchain.dev/semi-structured-multi-modal-rag/">https://blog.langchain.dev/semi-structured-multi-modal-rag/</a></li>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/multi_vector/">https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/multi_vector/</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.06648">https://arxiv.org/abs/2312.06648</a></li>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/">https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/</a></li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829232854378.png" alt="image-20240829232854378"></p>
<blockquote>
<p>层级性索引 - <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.18059">https://arxiv.org/pdf/2401.18059</a><br><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/cookbook/RAPTOR.ipynb">https://github.com/langchain-ai/langchain/blob/master/cookbook/RAPTOR.ipynb</a></p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240829234146776.png" alt="image-20240829234146776"></p>
<ol>
<li>对文档进行生成聚类摘要，然后设计成层级性</li>
<li>具体实现，将语料库中的文档聚类，并递归地总结相似的文档</li>
<li>将它们全部编入索引，生成低级别的文档和摘要</li>
<li>可以索引这些文档和摘要来回答从详细到更高级别的问题</li>
</ol>
<blockquote>
<p>ColBERT - 做到 Token 级别 - 类似于<strong>关键词</strong>的召回<br><a target="_blank" rel="noopener" href="https://hackernoon.com/how-colbert-helps-developers-overcome-the-limits-of-rag">https://hackernoon.com/how-colbert-helps-developers-overcome-the-limits-of-rag</a></p>
</blockquote>
<ol>
<li>为段落中的每个 <strong>Token</strong> 生成一个<strong>受上下文影响</strong>的<strong>向量</strong></li>
<li>ColBERT 同样为 Query 中的每个 Token 生成向量</li>
<li>然后，每个文档的得分是 Query 嵌入与任意文档嵌入的最大相似度之和</li>
</ol>
<h2 id="Retrieval"><a href="#Retrieval" class="headerlink" title="Retrieval"></a>Retrieval</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240830002051143.png" alt="image-20240830002051143"></p>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240830002105203.png" alt="image-20240830002105203"></p>
<ol>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/integrations/retrievers/cohere-reranker/#doing-reranking-with-coherererank">https://python.langchain.com/v0.2/docs/integrations/retrievers/cohere-reranker/#doing-reranking-with-coherererank</a></li>
<li><a target="_blank" rel="noopener" href="https://cohere.com/blog/rerank">https://cohere.com/blog/rerank</a></li>
<li>Ranking &#x2F; Refinement &#x2F; Active Retrieval</li>
<li>做 RAG 的时候，尽量不要去动原始的 Embedding 模型，而是动 <strong>Rerank</strong> 模型（很小，几百兆）</li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240830002623978.png" alt="image-20240830002623978"></p>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240830002658589.png" alt="image-20240830002658589"></p>
<blockquote>
<p>CRAG（Corrective RAG），本质也是一种 <strong>Adaptive RAG</strong><br>为在循环单元测试中自我纠正检索错误，以确定文档相关性并返回到网络搜索<br>对检索文档的自我反思和自我评分</p>
<p><strong>AI 搜索</strong><br>如果至少有一个文档超过了<strong>相关性阈值</strong>，则进入生成阶段<br>在生成之前，进行知识细化，将文档化为条带，对每个知识条进行分级，过滤不相关的知识条<br>如果所有文档都低于相关性阈值，或者分级者不确定，那么框架会寻找额外的数据源，使用网络补充搜索</p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240830003933737.png" alt="image-20240830003933737"></p>
<h2 id="Self-RAG"><a href="#Self-RAG" class="headerlink" title="Self-RAG"></a>Self-RAG</h2><blockquote>
<p>使用循环单元测试自我纠正 RAG 错误，以检查文档相关性、答案幻觉和答案质量</p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240830004226151.png" alt="image-20240830004226151"></p>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top">zhongmingmao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top/2024/08/04/rag-langchain/">https://blog.zhongmingmao.top/2024/08/04/rag-langchain/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ai/">AI</a><a class="post-meta__tags" href="/tags/llm/">LLM</a><a class="post-meta__tags" href="/tags/langchain/">LangChain</a><a class="post-meta__tags" href="/tags/rag/">RAG</a></div><div class="post-share"><div class="social-share" data-image="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-agent.webp" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/08/05/rag-doc-parse/" title="RAG - Document Parsing"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240830092249777.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">RAG - Document Parsing</div></div><div class="info-2"><div class="info-item-1">文档解析 文档解析的本质 - 将格式各异、版本多样、元素多种的文档数据，转化为阅读顺序正确的字符串信息 Quality in, Quality out 是 LLM 的典型特征 高质量的文档解析能够从各种复杂格式的非结构化数据中提取出高精度信息 对 RAG 系统的最终效果起到决定性作用   RAG 系统的应用场景主要集中在专业领域和企业场景 除了数据库，更多的数据以 PDF、Word 等多种格式存储 PDF 文件有统一的排版和多样化的结构形式，是最为常见的文档数据格式和交换格式       Quality in, Quality out   LangChainDocument Loaders LangChain 提供了一套功能强大的文档加载器（Document Loaders） LangChain 定义了 BaseLoader 类和 Document 类 BaseLoader - 定义如何从不同数据源加载文档 Document - 统一描述不同文档类型的元数据   开发者可以基于 BaseLoader 为特定数据源创建自定义加载器，将其内容加载为 Document 对象 Document Loader 模...</div></div></div></a><a class="pagination-related" href="/2024/08/03/rag-in-action/" title="RAG - In Action"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-in-action.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">RAG - In Action</div></div><div class="info-2"><div class="info-item-1">技术选型LangChain LangChain 是专门为开发基于 LLM 应用而设计的全面框架 LangChain 的核心目标是简化开发者的构建流程，使其能够高效地创建 LLM 驱动的应用    索引文档解析 pypdf 专门用于处理 PDF 文档 pypdf 支持 PDF 文档的创建、读取、编辑和转换，能够有效地提取和处理文本、图像及页面内容  文档分块 RecursiveCharacterTextSplitter 是 LangChain 默认的文本分割器 RecursiveCharacterTextSplitter 通过层次化的分隔符（从双换行符到单字符）拆分文本 旨在保持文本的结构和连贯性，优先考虑自然边界（如段落和句子）    索引 + 检索向量化模型 bge-small-zh-v1.5 是由北京智源人工智能研究院（BAAI）开发的开源向量模型 bge-small-zh-v1.5 的模型体积较小，但仍能提供高精度和高效的中文向量检索 bge-small-zh-v1.5 的向量维度为 512，最大输入长度同样为 512  向量库 Faiss - Facebook AI Similarity Sea...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/06/30/llm-rag-chatglm3-6b-langchain-faiss/" title="LLM RAG - ChatGLM3-6B + LangChain + Faiss"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/rag.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-30</div><div class="info-item-2">LLM RAG - ChatGLM3-6B + LangChain + Faiss</div></div><div class="info-2"><div class="info-item-1">RAG 使用知识库，用来增强 LLM 信息检索的能力   知识准确 先把知识进行向量化，存储到向量数据库中 使用的时候通过向量检索从向量数据库中将知识检索出来，确保知识的准确性   更新频率快 当发现知识库里面的知识不全时，可以随时补充 不需要像微调一样，重新跑微调任务、验证结果、重新部署等      应用场景 ChatOps   知识库模式适用于相对固定的场景做推理 如企业内部使用的员工小助手，不需要太多的逻辑推理 使用知识库模式检索精度高，且可以随时更新 LLM 基础能力 + Agent 进行堆叠，可以产生智能化的效果  LangChain-Chatchat组成模块   模块 作用 支持列表    大语言模型 智能体核心引擎 ChatGLM &#x2F; Qwen &#x2F; Baichuan &#x2F; LLaMa   Embedding 模型 文本向量化 m3e-* &#x2F; bge-*   分词器 按照规则将句子分成短句或者单词 LangChain Text Splitter   向量数据库 向量化数据存储 Faiss &#x2F; Milvus   Agent Tools 调用第三方...</div></div></div></a><a class="pagination-related" href="/2024/06/29/llm-peft-chatglm3-6b-lora/" title="LLM PEFT - ChatGLM3-6B + LoRA"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/lora.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-29</div><div class="info-item-2">LLM PEFT - ChatGLM3-6B + LoRA</div></div><div class="info-2"><div class="info-item-1">通用 LLM 千亿大模型（130B、ChatGPT）和小规模的大模型（6B、LLaMA2）都是通用 LLM   通用 LLM 都是通过常识进行预训练的 在实际使用过程中，需要 LLM 具备某一特定领域知识的能力 - 对 LLM 的能力进行增强    增强方式   Method Desc    微调 让预先训练好的 LLM 适应特定任务或数据集的方案，成本相对低LLM 学会训练者提供的微调数据，并具备一定的理解能力   知识库 使用向量数据库或者其它数据库存储数据，为 LLM 提供信息来源外挂   API 与知识库类似，为 LLM 提供信息来源外挂    互不冲突，可以同时使用几种方案来优化 LLM，提升内容输出能力   LoRA &#x2F; QLoRA &#x2F; 知识库 &#x2F; API    LLM Performance &#x3D; 推理效果  落地过程   Method Pipeline    微调 准备数据 -&gt; 微调 -&gt; 验证 -&gt; 提供服务   知识库 准备数据 -&gt; 构建向量库 -&gt; 构建智能体 -&gt; 提供服务   API 准备数据 -&g...</div></div></div></a><a class="pagination-related" href="/2024/06/28/llm-deploy-chatglm3-6b/" title="LLM Deploy - ChatGLM3-6B"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/chatglm3-6b.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-28</div><div class="info-item-2">LLM Deploy - ChatGLM3-6B</div></div><div class="info-2"><div class="info-item-1">LLM 选择核心玩家 厂家很多，但没多少真正在研究技术 - 成本 - 不少厂商是基于 LLaMA 套壳     ChatGLM-6B ChatGLM-6B 和 LLaMA2 是比较热门的开源项目，国产 LLM 是首选 企业布局 LLM 选择 MaaS 服务，调用大厂 LLM API，但会面临数据安全问题 选择开源 LLM，自己微调、部署、为上层应用提供服务   企业一般会选择私有化部署 + 公有云 MaaS 的混合架构 在国产厂商中，从技术角度来看，智谱 AI 是国内 LLM 研发水平最高的厂商 6B 的参数规模为 62 亿，单张 3090 显卡就可以进行微调和推理 企业预算充足（百万以上，GPU 费用 + 商业授权） 可以尝试 GLM-130B，千亿参数规模，推理能力更强 GLM-130B 轻量化后，可以在 3090 × 4 上进行推理 训练 GLM-130B 大概需要 96 台 A100（320G），历时两个多月     计算资源 适合 CPU 计算的 LLM 不多 有些 LLM 可以在 CPU 上进行推理，但需要使用低精度轻量化的 LLM 但在低精度下，LLM 会失真，效果较差   要真正体验并应...</div></div></div></a><a class="pagination-related" href="/2024/06/27/llm-langchain-rag/" title="LLM - LangChain + RAG"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/rag.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-27</div><div class="info-item-2">LLM - LangChain + RAG</div></div><div class="info-2"><div class="info-item-1">局限 大模型的核心能力 - 意图理解 + 文本生成     局限 描述    数据的及时性 大部分 AI 大模型都是预训练的，如果要问一些最新的消息，大模型是不知道的   复杂任务处理 AI 大模型在问答方面表现出色，但不总是能够处理复杂任务AI 大模型主要是基于文本的交互（多模态除外）   代码生成与下载 根据需求描述生成对应的代码，并提供下载链接 - 暂时不支持   与企业应用场景的集成 读取关系型数据库里面的数据，并根据提示进行任务处理 - 暂时不支持    在实际应用过程中，输入数据和输出数据，不仅仅是纯文本 AI Agent - 需要解析用户的输入输出    AI Agent AI Agent 是以 LLM 为核心控制器的一套代理系统    控制端处于核心地位，承担记忆、思考以及决策等基础工作 感知模块负责接收和处理来自于外部环境的多样化信息 - 文字、声音、图片、位置等 行动模块通过生成文本、API 调用、使用工具等方式来执行任务以及改变环境   LangChain - 开源 + 提供一整套围绕 LLM 的 Agent 工具   AI Agent 很有可能在未来一段时间内成为 AI 发展的一...</div></div></div></a><a class="pagination-related" href="/2024/09/09/rag-vector-qdrant/" title="RAG - Qdrant"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/qdrant.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-09</div><div class="info-item-2">RAG - Qdrant</div></div><div class="info-2"><div class="info-item-1">Features   Getting StartedIntroduction Vector databases are a relatively new way for interacting with abstract data representations derived from opaque machine learning models such as deep learning architectures. These representations are often called vectors or embeddings and they are a compressed version of the data used to train a machine learning model to accomplish a task like sentiment analysis, speech recognition, object detection, and many others.  What is Qdrant? Qdrant “is a vector similarity s...</div></div></div></a><a class="pagination-related" href="/2024/08/17/rag-graphrag/" title="RAG - GraphRAG"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/graphrag-9781829.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-17</div><div class="info-item-2">RAG - GraphRAG</div></div><div class="info-2"><div class="info-item-1">向量检索 信息片段之间的连接能力有限   RAG 在跨越多个信息片段以获取综合见解时表现不足 当要回答一个复杂问题时，必须要通过共享属性在不同信息之间建立联系 RAG 无法有效捕捉这些关系 限制了 RAG 在处理需要多跳推理或整合多源数据的复杂查询时的能力       归纳总结能力不足   在处理大型数据集或长文档时，RAG 难以有效地归纳和总结复杂的语义概念 RAG 在需要全面理解和总结复杂语义信息的场景中表现不佳  GraphRAG 利用 LLM 生成的知识图谱来改进 RAG 的检索部分   GraphRAG 利用结构化的实体和关系信息，使得检索过程更加精准和全面 GraphRAG 在处理多跳问题和复杂文档分析时表现出色 GraphRAG 在处理复杂信息处理任务时，显著提升问答性能，提供比 RAG 更为准确和全面的答案 GraphRAG 通过知识图谱有效地连接不同的信息片段 不仅能够提供准确答案，还能展示答案之间的内在联系，提供更丰富和有价值的结果     GraphRAG 先利用知识图谱，关联查询的实体和关系从与知识图谱实体直接相关的文档中检索片段，提供一个更全面、指标化、高信息密度的总结   主...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">zhongmingmao</div><div class="author-info-description">Focus on Infrastructure.</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">639</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="mailto:zhongmingmao0625@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Things are always unexpected!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Practice"><span class="toc-number">1.</span> <span class="toc-text">Practice</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Query-Translation"><span class="toc-number">2.</span> <span class="toc-text">Query Translation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Multi-Query"><span class="toc-number">2.1.</span> <span class="toc-text">Multi Query</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RAG-Fusion"><span class="toc-number">2.2.</span> <span class="toc-text">RAG Fusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Decomposition"><span class="toc-number">2.3.</span> <span class="toc-text">Decomposition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-Back"><span class="toc-number">2.4.</span> <span class="toc-text">Step Back</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HyDE"><span class="toc-number">2.5.</span> <span class="toc-text">HyDE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Routing"><span class="toc-number">2.6.</span> <span class="toc-text">Routing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Query-Structuring"><span class="toc-number">2.7.</span> <span class="toc-text">Query Structuring</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Indexing"><span class="toc-number">2.8.</span> <span class="toc-text">Indexing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Retrieval"><span class="toc-number">2.9.</span> <span class="toc-text">Retrieval</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Self-RAG"><span class="toc-number">2.10.</span> <span class="toc-text">Self-RAG</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java-agent.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java Zero Code"/></a><div class="content"><a class="title" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code">Observability - OpenTelemetry Java Zero Code</a><time datetime="2025-01-20T16:06:25.000Z" title="Created 2025-01-21 00:06:25">2025-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java"/></a><div class="content"><a class="title" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java">Observability - OpenTelemetry Java</a><time datetime="2025-01-19T16:06:25.000Z" title="Created 2025-01-20 00:06:25">2025-01-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/19/ai-agent-overview-mcp/" title="AI Agent - MCP Overview"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/mcp.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AI Agent - MCP Overview"/></a><div class="content"><a class="title" href="/2025/01/19/ai-agent-overview-mcp/" title="AI Agent - MCP Overview">AI Agent - MCP Overview</a><time datetime="2025-01-18T16:06:25.000Z" title="Created 2025-01-19 00:06:25">2025-01-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/18/ai-agent-overview/" title="AI Agent - Overview"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/ai-agent.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AI Agent - Overview"/></a><div class="content"><a class="title" href="/2025/01/18/ai-agent-overview/" title="AI Agent - Overview">AI Agent - Overview</a><time datetime="2025-01-17T16:06:25.000Z" title="Created 2025-01-18 00:06:25">2025-01-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/17/new-java-feature-foreign-function-api/" title="New Java Feature - Foreign Function API"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://java-feature-1253868755.cos.ap-guangzhou.myqcloud.com/Java-Foreign-Function-API.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="New Java Feature - Foreign Function API"/></a><div class="content"><a class="title" href="/2025/01/17/new-java-feature-foreign-function-api/" title="New Java Feature - Foreign Function API">New Java Feature - Foreign Function API</a><time datetime="2025-01-16T16:06:25.000Z" title="Created 2025-01-17 00:06:25">2025-01-17</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2015 - 2025 By zhongmingmao</span></div><div class="footer_custom_text">Life is like a box of chocolates. You can't know what you'll eat until you open it.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional and Simplified Chinese">繁</button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script></div></body></html>