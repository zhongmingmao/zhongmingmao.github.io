<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LLM - ChatGPT | ByteCoding</title><meta name="author" content="zhongmingmao"><meta name="copyright" content="zhongmingmao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="Timeline  OpenAI 在 NLP 领域取得了突破性进展 ChatGPT 背后包含了一系列的资源整合 - 技术、资源、大厂背书、国际巨头的通力合作 - 工程 + 产品">
<meta property="og:type" content="article">
<meta property="og:title" content="LLM - ChatGPT">
<meta property="og:url" content="https://blog.zhongmingmao.top/2024/06/25/llm-chatgpt/index.html">
<meta property="og:site_name" content="ByteCoding">
<meta property="og:description" content="Timeline  OpenAI 在 NLP 领域取得了突破性进展 ChatGPT 背后包含了一系列的资源整合 - 技术、资源、大厂背书、国际巨头的通力合作 - 工程 + 产品">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/llm-chatgpt.png">
<meta property="article:published_time" content="2024-06-24T16:06:25.000Z">
<meta property="article:modified_time" content="2024-08-08T04:24:31.047Z">
<meta property="article:author" content="zhongmingmao">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="ChatGPT">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/llm-chatgpt.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LLM - ChatGPT",
  "url": "https://blog.zhongmingmao.top/2024/06/25/llm-chatgpt/",
  "image": "https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/llm-chatgpt.png",
  "datePublished": "2024-06-24T16:06:25.000Z",
  "dateModified": "2024-08-08T04:24:31.047Z",
  "author": [
    {
      "@type": "Person",
      "name": "zhongmingmao",
      "url": "https://blog.zhongmingmao.top"
    }
  ]
}</script><link rel="shortcut icon" href="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png"><link rel="canonical" href="https://blog.zhongmingmao.top/2024/06/25/llm-chatgpt/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":32,"languages":{"author":"Author: zhongmingmao","link":"Link: ","source":"Source: ByteCoding","info":"Copyright belongs to the author. For commercial use, please contact the author for authorization. For non-commercial use, please indicate the source."}},
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LLM - ChatGPT',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="ByteCoding" type="application/atom+xml">
</head><body><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js/themes/blue/pace-theme-minimal.min.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg" style="background-image: url(/url(https:/cdn.pixabay.com/photo/2021/07/20/03/39/fisherman-6479663_1280.jpg));"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">641</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/llm-chatgpt.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">ByteCoding</span></a><a class="nav-page-title" href="/"><span class="site-name">LLM - ChatGPT</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">LLM - ChatGPT</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">Created</span><time datetime="2024-06-24T16:06:25.000Z" title="Created 2024-06-25 00:06:25">2024-06-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ai/">AI</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ai/llm/">LLM</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">1.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>4mins</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:512,&quot;messagePrev&quot;:&quot;It has been&quot;,&quot;messageNext&quot;:&quot;days since the last update, the content of the article may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2024-08-08 12:24:31&quot;}" hidden></div><h1 id="Timeline"><a href="#Timeline" class="headerlink" title="Timeline"></a>Timeline</h1><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240715121726607.png" alt="image-20240715121726607"></p>
<ol>
<li>OpenAI 在 <code>NLP</code> 领域取得了突破性进展</li>
<li>ChatGPT 背后包含了一系列的资源整合 - 技术、资源、大厂背书、国际巨头的通力合作 - 工程 + 产品</li>
</ol>
<span id="more"></span>

<h1 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h1><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><blockquote>
<p>基于 Transformer 架构的<code>语言模型</code>大体可分为两类</p>
</blockquote>
<ol>
<li>以 <code>BERT</code> 为代表的掩码语言模型 - <code>Masked Language Model</code> - MLM</li>
<li>以 <code>GPT</code> 为代表的自回归语言模型 - <code>Autoregressive Language Mode</code> - ALM</li>
</ol>
<blockquote>
<p>OpenAI</p>
</blockquote>
<ol>
<li>创造造福全人类的安全通用人工智能 - <code>Artificial general intelligence</code> - AGI</li>
<li>创立之初就摒弃了传统 AI <code>模型标注</code>式的训练方式<ul>
<li>可用来标注的数据总是<code>有限</code>的，而且很难做得非常<code>通用</code></li>
</ul>
</li>
</ol>
<h2 id="Autoregressive"><a href="#Autoregressive" class="headerlink" title="Autoregressive"></a>Autoregressive</h2><blockquote>
<p>基于<code>自回归</code>的<code>无监督</code>训练</p>
</blockquote>
<ol>
<li>BERT 由 Google 发布，非常权威，GPT 早期压力巨大 - <code>GPT-2</code> 引入了 <code>zero-shot</code></li>
<li>按照人类语言的习惯，语言本身是有<code>先后顺序</code>的，下文依赖上文<ul>
<li>自回归语言模型代表了标准的语言模型 - <code>利用上文信息预测下文</code></li>
<li>比传统 AI 预测<code>更加复杂</code>，但<code>上限更高</code>，有望通向 <code>AGI</code></li>
</ul>
</li>
<li>在 GPT-1 和 GPT-2 的探索中没有取得压倒性的效果<ul>
<li>但验证了<code>标准语言模型</code>在 <code>zero-shot</code> 等当面的潜在能力</li>
</ul>
</li>
<li><code>无监督自回归</code>的训练方式，使 GPT 模型可以接受<code>大量文本数据</code><ul>
<li>GPT-3 的参数规模为 <code>1750 亿</code>，使用了大约 <code>45 TB</code> 的文本数据，一次训练费用为 <code>460 万美元</code></li>
</ul>
</li>
<li>GPT-3 还不具备直接和人类对话的能力，而 <code>ChatGPT</code> 所使用的模型为 <code>GPT-3.5</code></li>
</ol>
<h2 id="Alignment"><a href="#Alignment" class="headerlink" title="Alignment"></a>Alignment</h2><blockquote>
<p>与人类意识对齐</p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240716090842759.png" alt="image-20240716090842759"></p>
<ol>
<li>GPT-3 和 GPT-3.5 是不同的系列</li>
<li><code>GPT-3</code> 经过<code>充分训练</code>，但依然不是一个适合与人类进行对话的模型</li>
<li>从 GPT-3 到 GPT-3.5 再到 InstructGPT 和 ChatGPT，<code>参数规模</code>并没有太大变化，主要是经历了各种技术的<code>微调</code> <ul>
<li>适配<code>人类</code>场景 - RLHF - Reinforcement Learning From Human Feedback</li>
</ul>
</li>
</ol>
<h2 id="Emergent-Ability"><a href="#Emergent-Ability" class="headerlink" title="Emergent Ability"></a>Emergent Ability</h2><blockquote>
<p><code>突现能力</code> - 大语言模型展现出来的特有的强大能力 - 复杂推理 + 思维链 - NLP 领域所追求</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">问题：小明每天早饭吃2个馒头，他一个月会吃掉多少包馒头？</span><br><span class="line"></span><br><span class="line">一个月按30天说，共吃掉60个馒头，每包5个馒头的话，总共12包。</span><br><span class="line"></span><br><span class="line">答案：12</span><br></pre></td></tr></table></figure>

<ol>
<li>语言和数学混在一起，在早期 <code>GPT-3</code> 模型上进行类型的<code>推理</code>，准确率低于 <code>40%</code></li>
<li>后来在 <code>code-davinci-002</code> 上进行推理，准确率能达到 <code>80%</code><ul>
<li><code>code-davinci-002</code> 在<code>模型规模</code>上并没有扩大，而是<code>基于代码进行训练</code>的</li>
<li>这些突现能力是大模型经过<code>大量代码训练</code>后展现出来的能力</li>
<li><code>代码训练</code>和<code>思维链及复杂推理</code>有很强的相关性 - 暂无确定证据</li>
</ul>
</li>
</ol>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ol>
<li>模型<code>并非越大越好</code><ul>
<li>GPT-3 的参数规模为 1750 亿</li>
<li>微软与英伟达联合开发的 Megatron-Turing 模型拥有超过 5000 个参数<ul>
<li>但在性能方面却不是最好的，因为模型未经过充分训练</li>
</ul>
</li>
</ul>
</li>
<li><code>RLHF</code> 并不是最早用在 GPT 上，而且在<code>恰当的时机</code>用到了 ChatGPT 上</li>
<li>只有 codex 使用了大量代码进行训练</li>
</ol>
<blockquote>
<p><code>自回归</code>语言模型 + 充分<code>无监督</code>训练 + 大量<code>代码</code>训练 + 有监督指令<code>微调</code> + <code>RLHF</code></p>
</blockquote>
<h1 id="超大规模预训练"><a href="#超大规模预训练" class="headerlink" title="超大规模预训练"></a>超大规模预训练</h1><blockquote>
<p>超过 40T 的文本数据，<code>大模型训练</code> 首先需要高质量的数据集</p>
</blockquote>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h3 id="GPT-3"><a href="#GPT-3" class="headerlink" title="GPT-3"></a>GPT-3</h3><blockquote>
<p>基础模型 GPT-3 具有 <code>1750</code> 亿个参数，训练数据集大约 <code>500B</code> 个 Token</p>
</blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240716234626294.png" alt="image-20240716234626294"></p>
<blockquote>
<p>原始大约 45T 的纯文本数据，经过<code>过滤</code>后，大概是 750G 的<code>高质量</code>文本数据</p>
</blockquote>
<h3 id="ChatGPT"><a href="#ChatGPT" class="headerlink" title="ChatGPT"></a>ChatGPT</h3><ol>
<li>ChatGPT 属于 GPT-3.5 系列</li>
<li>大概率上，ChatGPT 的参数规模要<code>小于</code> GPT-3，其训练数据基于大量<code>对话型数据</code>进行指令微调<ul>
<li>典型数据集 - Persona-Chat 的数据集、康奈尔电影对话语料库、Ubuntu 对话语料库、DailyDialog</li>
<li>互联网上大量<code>非结构化</code>数据的训练 - 网站、书籍、其它文本源<ul>
<li>ChatGPT 能够从更一般的意义上了解语言的<code>结构</code>和<code>模式</code>，然后可以针对对话管理或者情感分析等特定应用进行<code>微调</code></li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="训练成本"><a href="#训练成本" class="headerlink" title="训练成本"></a>训练成本</h2><ol>
<li>GPT-3 的单次训练成本高达 460 万美元，为了<code>找钱</code>，OpenAI 从开源转为了<code>闭源</code></li>
<li>早期的 OpenAI 是开源的，创办宗旨为创建<code>通用人工智能</code></li>
<li>为了引入资金，OpenAI 从开源转为闭源，设计了一种<code>商业模式</code>来吸引投资人，最主要为<code>微软</code></li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240717000304560.png" alt="image-20240717000304560"></p>
<ol>
<li>OpenAI 的母公司为 <code>OpenAI Inc</code> - 为<code>非营利性组织</code></li>
<li>后来成立一家子公司，<code>OpenAI LP</code>，即常说的 <code>OpenAI</code> - 为一家纯粹的<code>商业化公司</code>，设置了最高 <code>100</code> 倍的<code>回报上限</code></li>
</ol>
<h1 id="产品化"><a href="#产品化" class="headerlink" title="产品化"></a>产品化</h1><ol>
<li>ChatGPT 在真正<code>产品化</code>后愿意<code>公开免费</code>给普通用户使用</li>
<li>大部分的 AI 厂家只<code>发布模型</code>，技术人员去 <code>Huggingface</code> 下载然后部署，但这样会将模型限制在一个<code>非常小的范围</code></li>
<li>ChatGPT 发布的是<code>普通大众用户</code>都可以使用的产品（使用门槛非常低） - 邮箱注册 + 全天候不限时 + 网页对话</li>
</ol>
<h1 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h1><ol>
<li>适用场景多<ul>
<li>代码编写、代码翻译、智能问答、语言识别等</li>
</ul>
</li>
<li>使用效果好<ul>
<li>微软小冰由<code>小模型</code>组成，只能同时处理<code>特定类型</code>的任务，<code>无法相互关联</code>，此类产品无法做<code>通用性回答</code></li>
<li>ChatGPT 像<code>真人</code>在回答，甚至有<code>记忆</code>和<code>感情</code></li>
</ul>
</li>
<li>工程化应用<ul>
<li>ChatGPT 是以<code>大模型为内核</code>的整套技术完成了<code>产品化</code> - 两个月注册用户过亿的世界级产品</li>
</ul>
</li>
</ol>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top">zhongmingmao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://blog.zhongmingmao.top/2024/06/25/llm-chatgpt/">https://blog.zhongmingmao.top/2024/06/25/llm-chatgpt/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ai/">AI</a><a class="post-meta__tags" href="/tags/llm/">LLM</a><a class="post-meta__tags" href="/tags/chatgpt/">ChatGPT</a></div><div class="post-share"><div class="social-share" data-image="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/llm-chatgpt.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/06/26/llm-prompt/" title="LLM - Prompt"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/llm-prompt.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">LLM - Prompt</div></div><div class="info-2"><div class="info-item-1">Prompt 是否充分使用好 AI 大模型，提示是关键 OpenAI   question &#x2F; answer prompt &#x2F; completion - 给 LLM 一个提示，让 LLM 进行补全   LLM 训练原理 GPT 系列模型基于 Transformer 架构的解码器机制，使用自回归无监督方式进行预训练 训练过程 - 大量的文本输入，不断进行记忆 相比于监督学习，训练效率更低，但训练过程简单，可以喂大量的文本语料，上限比较高   completion 根据训练过的记忆，一个字一个字地计算概率，取概率最大的那个字进行输出 因此有人吐槽 LLM 输出很慢 - 逐字计算并输出      Prompt Engineering 需求描述越详细越准确，LLM 输出的内容就越符合要求 Prompt Engineering 是一门专门研究与 LLM 交互的新型学科 通过不断地开发和优化，帮助用户更好地了解 LLM 的能力和局限性   探讨如何设计出最佳提示，用于指导 LLM 帮助我们高效完成某项任务 不仅仅是设计和研发提示，还包含了与 LLM 交互的各种技能和技术 在实现与 LLM 交互、...</div></div></div></a><a class="pagination-related" href="/2023/05/11/cloud-native-foundation-k8s-helm-doc/" title="Kubernetes - Helm Doc"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cnf-1253868755.cos.ap-guangzhou.myqcloud.com/k8s/helm.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Kubernetes - Helm Doc</div></div><div class="info-2"><div class="info-item-1">基本概念 Chart 包含在 Kubernetes 集群内部运行的应用程序、工具和服务所需的所有资源定义   Repository 用于存放和共享 Chart   Release 运行在 Kubernetes 集群中的 Chart 实例 一个 Chart 可以在同一个集群中被安装多次，每次安装都会创建一个 Release      基本使用Search   Source Desc    hub 从 Artifact Hub 中搜索   repo 基于本地 repo 搜索，无需联网   hub123456$ h search hub wordpressURL                                                   CHART VERSION	APP VERSION        	DESCRIPTIONhttps://artifacthub.io/packages/helm/kube-wordp...    0.1.0        	1.1                	this is my wordpress packagehttps://artifact...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/09/09/rag-vector-qdrant/" title="RAG - Qdrant"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/qdrant.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-09</div><div class="info-item-2">RAG - Qdrant</div></div><div class="info-2"><div class="info-item-1">Features   Getting StartedIntroduction Vector databases are a relatively new way for interacting with abstract data representations derived from opaque machine learning models such as deep learning architectures. These representations are often called vectors or embeddings and they are a compressed version of the data used to train a machine learning model to accomplish a task like sentiment analysis, speech recognition, object detection, and many others.  What is Qdrant? Qdrant “is a vector similarity s...</div></div></div></a><a class="pagination-related" href="/2024/08/17/rag-graphrag/" title="RAG - GraphRAG"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/graphrag-9781829.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-17</div><div class="info-item-2">RAG - GraphRAG</div></div><div class="info-2"><div class="info-item-1">向量检索 信息片段之间的连接能力有限   RAG 在跨越多个信息片段以获取综合见解时表现不足 当要回答一个复杂问题时，必须要通过共享属性在不同信息之间建立联系 RAG 无法有效捕捉这些关系 限制了 RAG 在处理需要多跳推理或整合多源数据的复杂查询时的能力       归纳总结能力不足   在处理大型数据集或长文档时，RAG 难以有效地归纳和总结复杂的语义概念 RAG 在需要全面理解和总结复杂语义信息的场景中表现不佳  GraphRAG 利用 LLM 生成的知识图谱来改进 RAG 的检索部分   GraphRAG 利用结构化的实体和关系信息，使得检索过程更加精准和全面 GraphRAG 在处理多跳问题和复杂文档分析时表现出色 GraphRAG 在处理复杂信息处理任务时，显著提升问答性能，提供比 RAG 更为准确和全面的答案 GraphRAG 通过知识图谱有效地连接不同的信息片段 不仅能够提供准确答案，还能展示答案之间的内在联系，提供更丰富和有价值的结果     GraphRAG 先利用知识图谱，关联查询的实体和关系从与知识图谱实体直接相关的文档中检索片段，提供一个更全面、指标化、高信息密度的总结   主...</div></div></div></a><a class="pagination-related" href="/2024/08/16/rag-evolution/" title="RAG - Evolution"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-evolution.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-16</div><div class="info-item-2">RAG - Evolution</div></div><div class="info-2"><div class="info-item-1">演进    Naive RAG -&gt; Advanced RAG -&gt; Modular RAG 三个范式之间具有继承与发展的关系 Advanced RAG 是 Modular RAG 的一种特例形式 Naive RAG 是 Advanced RAG 的基础特例   RAG 技术不断演进，以适应更复杂的任务和场景需求  Naive RAG Naive RAG 是最基础的形式，依赖核心的索引和检索策略来增强生成模型的输出 Naive RAG 适用于一些基础任务和产品 MVP 阶段  Advanced RAG 通过增加检索前、检索中以及检索后的优化策略，提高检索的准确性和生成的关联性 - 适用于复杂任务    Advanced RAG 通过优化检索前、检索中、检索后的各个环节 在索引质量、检索效果以及生成内容的上下文相关性方面都取得显著提升  检索前 通过索引、分块、查询优化和内容向量化等技术手段，提高检索内容的精确性和生成内容的相关性  滑动窗口 overlap   经典的 Chunking 技术，通过在相邻的 Chunk 之间创建重叠区域，确保关键信息不会因简单的 Chunking 而丢失 在 ...</div></div></div></a><a class="pagination-related" href="/2024/08/15/rag-optimization-evaluation/" title="RAG - Optimization + Evaluation"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-evaluation.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-15</div><div class="info-item-2">RAG - Optimization + Evaluation</div></div><div class="info-2"><div class="info-item-1">RAG   检索优化数据清洗和预处理 在 RAG 索引流程中，文档解析之后，文档切块之前，进行数据清洗和预处理 减少脏数据和噪音，提升文本的整体质量和信息密度   手段：清除冗余信息、统一格式、处理异常字符等 处理冗余的模板内容 消除文档中的额外空白和格式不一致 去除文档脚注、页眉页脚、版权信息    查询扩写 在 RAG 系统的检索步骤中，用户的查询会转换为向量后进行检索 单个向量查询只能覆盖向量空间中一个有限区域 如果查询中的嵌入向量未能包含所有关键信息，则可能检索到不相关的 Chunk 单点查询的局限性 - 限制系统在庞大文档库中的搜索范围，导致错失与查询语义相关的内容   查询扩写 通过 LLM 从原始查询语句生成多个语义相关的查询，可以覆盖向量空间中的不同区域 提高检索的全面性和准确性 扩写后的查询在被嵌入后，能够击中不同的语义区域 确保系统能够从更广泛的文档中检索到与用户需求相关的有用信息     通过查询扩写，原始问题被分解为多个子查询 每个子查询独立检索相关文档并生成相应的结果 系统将所有子查询的检索结果进行合并和重新排序   能够有效扩展用户的查询意图，确保在复杂信息库中进行更全面的文...</div></div></div></a><a class="pagination-related" href="/2024/08/14/rag-llm-prompt-engineering/" title="RAG - LLM + Prompt Engineering"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/llm-prompting.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-14</div><div class="info-item-2">RAG - LLM + Prompt Engineering</div></div><div class="info-2"><div class="info-item-1">RAG 生成流程    经过 RAG 索引流程（外部知识的解析和向量化）和 RAG 检索流程（语义相似性的匹配及混合检索），进入到 RAG 生成流程 在 RAG 生成流程中，需要组合指令，即携带查询问题及检索到的相关信息输入的 LLM，由 LLM 理解并生成最终的回复 RAG 的本质是通过 LLM 提供外部知识来增强其理解和回答领域问题的能力 LLM 在 RAG 系统中起到了大脑的作用 在面对复杂且多样化的 RAG 任务时，LLM 的性能直接决定了系统的整体效果   提示词工程是生成流程中的另一个关键环节 通过有效的指令的设计和组合，可以帮助 LLM 更好地理解输入内容，从而生成更加精确和相关的回答 精心设计的问题提示词，往往能提升生成效果    LLM发展  RAG 目前更关注通用大模型   原理 Google 于 2017 年发布论文 Attention Is All You Need，引入了 Transformer 模型 Transformer 模型是深度学习领域的一个突破性架构，LLM 的成功得益于对 Transformer 模型的应用 与传统的 RNN（循环神经网络） 相比，Transform...</div></div></div></a><a class="pagination-related" href="/2024/08/13/rag-hybrid-retrieval-rerank/" title="RAG - Hybrid retrieval + Rerank"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/rag-rerank-9097303.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-13</div><div class="info-item-2">RAG - Hybrid retrieval + Rerank</div></div><div class="info-2"><div class="info-item-1">向量检索 当前主流的 RAG 检索方式主要采用向量检索，通过语义相似度来匹配 Chunk 向量检索并非万能，在某些场景下无法替代传统关键词检索的优势 当需要精准搜索的时候，向量检索的准确性就往往不如关键词检索 当用户输入的问题非常简短，语义匹配的效果可能不尽理想   关键词检索的适用场景 精确匹配 少量字符的匹配 - 不适合用向量检索 低频词汇的匹配       混合检索 结合关键词检索和语义匹配的优势   在 RAG 检索场景中，首要目标是确保最相关的结果能够出现在候选列表中 向量检索和关键词检索各具优势，混合检索通过结合多种检索技术，弥补各自不足，提供一种更加全面的搜索方案 重排序技术在检索系统中扮演着至关重要的角色 即使检索算法已经能够捕捉到所有相关的结果，重排序过程依然不可或缺 确保最符合用户意图和查询语义的结果优先展示，提升用户的搜索体验和结果的准确性     在多个数据集和多个检索任务中，混合检索和重排序的组合均取得了最佳表现     融合检索 &#x2F; 多路召回    https://python.langchain.com/v0.2/api_reference/community/r...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://zhongmingmao-1253868755.cos.ap-guangzhou.myqcloud.com/z.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">zhongmingmao</div><div class="author-info-description">Focus on Infrastructure.</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">641</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">191</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">83</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="mailto:zhongmingmao0625@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Things are always unexpected!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Timeline"><span class="toc-number">1.</span> <span class="toc-text">Timeline</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#NLP"><span class="toc-number">2.</span> <span class="toc-text">NLP</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Transformer"><span class="toc-number">2.1.</span> <span class="toc-text">Transformer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Autoregressive"><span class="toc-number">2.2.</span> <span class="toc-text">Autoregressive</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Alignment"><span class="toc-number">2.3.</span> <span class="toc-text">Alignment</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Emergent-Ability"><span class="toc-number">2.4.</span> <span class="toc-text">Emergent Ability</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">2.5.</span> <span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="toc-number">3.</span> <span class="toc-text">超大规模预训练</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.1.</span> <span class="toc-text">数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#GPT-3"><span class="toc-number">3.1.1.</span> <span class="toc-text">GPT-3</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ChatGPT"><span class="toc-number">3.1.2.</span> <span class="toc-text">ChatGPT</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%88%90%E6%9C%AC"><span class="toc-number">3.2.</span> <span class="toc-text">训练成本</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%A7%E5%93%81%E5%8C%96"><span class="toc-number">4.</span> <span class="toc-text">产品化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">5.</span> <span class="toc-text">优点</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/01/23/cloud-native-observability-prometheus-concepts/" title="Observability - Prometheus Concepts"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/prometheus-concepts.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - Prometheus Concepts"/></a><div class="content"><a class="title" href="/2025/01/23/cloud-native-observability-prometheus-concepts/" title="Observability - Prometheus Concepts">Observability - Prometheus Concepts</a><time datetime="2025-01-22T16:06:25.000Z" title="Created 2025-01-23 00:06:25">2025-01-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/22/cloud-native-observability-prometheus-introduction/" title="Observability - Prometheus Introduction"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/prometheus.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - Prometheus Introduction"/></a><div class="content"><a class="title" href="/2025/01/22/cloud-native-observability-prometheus-introduction/" title="Observability - Prometheus Introduction">Observability - Prometheus Introduction</a><time datetime="2025-01-21T16:06:25.000Z" title="Created 2025-01-22 00:06:25">2025-01-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java-agent.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java Zero Code"/></a><div class="content"><a class="title" href="/2025/01/21/cloud-native-observability-opentelemetry-java-zero-code/" title="Observability - OpenTelemetry Java Zero Code">Observability - OpenTelemetry Java Zero Code</a><time datetime="2025-01-20T16:06:25.000Z" title="Created 2025-01-21 00:06:25">2025-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/otel-java.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Observability - OpenTelemetry Java"/></a><div class="content"><a class="title" href="/2025/01/20/cloud-native-observability-opentelemetry-java/" title="Observability - OpenTelemetry Java">Observability - OpenTelemetry Java</a><time datetime="2025-01-19T16:06:25.000Z" title="Created 2025-01-20 00:06:25">2025-01-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/19/ai-agent-overview-mcp/" title="AI Agent - MCP Overview"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/mcp.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AI Agent - MCP Overview"/></a><div class="content"><a class="title" href="/2025/01/19/ai-agent-overview-mcp/" title="AI Agent - MCP Overview">AI Agent - MCP Overview</a><time datetime="2025-01-18T16:06:25.000Z" title="Created 2025-01-19 00:06:25">2025-01-19</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2015 - 2025 By zhongmingmao</span></div><div class="footer_custom_text">Life is like a box of chocolates. You can't know what you'll eat until you open it.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Toggle Between Traditional and Simplified Chinese">繁</button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script></div></body></html>