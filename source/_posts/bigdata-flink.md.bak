---
title: Big Data - Apache Flink
mathjax: true
date: 2024-10-06 00:06:25
cover: https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/bigdata-apache-flink.webp
categories:
  - Big Data
  - Flink
tags:
  - Big Data
  - Flink
---

# 架构

1. Apache Flink 是一个**框架**和**分布式处理引擎**，用于在**无边界**和**有边界**数据流上进行**有状态**的**计算**
2. Flink 能在所有**常见集群环境**中运行，并能以**内存速度**和**任意规模**进行计算

<!-- more -->

## 有界数据 vs  无界数据

1. 任何类型的数据都可以形成一种**事件流**
2. 数据可以被作为**无界流**或者**有界流**来处理

![bounded-unbounded](/Users/zhongmingmao/data/typora/bounded-unbounded.png)

### 无界流

> 流处理

1. 有定义流的开始，但没有定义流的结束
2. 无界流会**无休止地产生数据**
   - 无界流的数据必须**持续处理**，即数据被摄取后需要立刻处理
   - 不能等到所有数据都到达再处理，因为**输入**是**无限**的，在任何时候输入都不会完成
3. 处理无界数据通常要求以**特定顺序**摄取事件，例如**事件发生**的顺序，以便能够推断结果的**完整性**

### 有界流

> 批处理

1. 有定义流的开始，也有定义流的结束
2. 有界流可以在摄取**所有数据**后再进行计算
3. 有界流**所有数据**可以**被排序**，所以并**不需要有序摄取**
4. 有界流处理通常被称为**批处理**

### Flink

> Apache Flink 擅长处理无界和有界数据集

1. **精确**的**时间控制**和**状态化**使得 Flink 的运行时(**runtime**)能够运行**任何**处理**无界流**的应用
2. **有界流**则由一些专为**固定大小数据集**特殊设计的**算法**和**数据结构**进行内部处理，产生了**出色的性能**

## 部署

1. Apache Flink 是一个**分布式系统**，它需要**计算资源**来执行应用程序
2. Flink 集成了所有常见的**集群资源管理器** - Hadoop YARN、Apache Mesos、**Kubernetes**
   - Flink 同时也可以作为**独立集群**运行
3. Flink 被设计为能够很好地工作在上述每个**集群资源管理器**中
   - 这是通过**资源管理器特定**(resource-manager-specific)的**部署模式**实现的，Flink 可以采用与当前集群资源管理器**相适应的方式**进行交互
4. 部署 Flink 应用程序时，Flink 会**根据应用程序配置的并行性自动标识所需的资源**，并从**集群资源管理器**请求这些资源
5. 在发生**故障**的情况下，Flink 通过**请求新资源**来**替换**发生**故障的容器**
6. **提交**或**控制**应用程序的**所有通信**都是通过 **REST** 调用进行的，这可以**简化** Flink 与各种环境中的**集成**

## 任意规模应用

1. Flink 旨在**任意规模**上运行**有状态**流式应用
2. 应用程序被**并行化**为可能数千个任务，这些任务分布在**集群**中**并发执行**
3. 应用程序能够充分利用**无尽**的 **CPU**、**内存**、**磁盘**和**网络 IO**
4. Flink 很容易维护**非常大**的**应用程序状态**
   - 其**异步**和**增量**的**检查点算法**对**处理延迟**产生**最小的影响**，同时保证**精确一次**状态的一致性

## 利用内存性能

1. **有状态**的 Flink 程序针对**本地状态访问**进行了优化
2. **任务的状态**始终保留在**内存**中，如果**状态大小**超过**可用内存**，则会保存在能**高效访问**的**磁盘数据结构**中
3. 任务通过**访问本地**（通常在**内存**中）状态来进行**所有的计算**，从而产生**非常低的处理延迟**
4. Flink 通过**定期**和**异步**地对**本地状态**进行**持久化存储**来保证**故障**场景下**精确一次**的**状态一致性**

![local-state](/Users/zhongmingmao/data/typora/local-state.png)

# 应用

1. Apache Flink 是一个针对**无界**和**有界**数据流进行**有状态计算**的框架
2. Flink **自底向上**在**不同的抽象级别**提供了多种 API，并且针对**常见的使用场景**开发了**专用的扩展库**

## 基本组件

> 流处理应用

### 流

> **数据流**是流处理的基本要素，**流**也拥有着**多种特征** - 决定了流**如何**以及**何时**被处理 - Flink 是一个能够处理**任何类型数据流**的强大处理框架

1. **有界** vs **无界**
   - 流可以是无界的；也可以是有界的，例如**固定大小**的数据集
   - Flink 在**无界**的数据流处理上拥有诸多**功能强大**的**特性**
   - 同时也针对**有界**的数据流开发了**专用**的**高效算子**
2. **实时** vs **历史记录**
   - **所有的数据**都是以**流**的方式产生，但用户通常会使用两种**截然不同的方法**处理数据
   - 或是在**数据生成时**进行**实时**的处理
   - 亦或是先将数据流**持久化**到**存储系统**中——例如**文件系统**或**对象存储**，然后再进行**批处理**
3. Flink 的应用能够**同时**支持**处理实时**以及**历史记录数据流**

### 状态

1. 只有在每一个**单独的事件**上进行**转换**操作的应用**才不需要状态**，换言之，每一个**具有一定复杂度**的流处理应用都是**有状态**的
2. 任何运行基本业务逻辑的流处理应用都需要在**一定时间内存储**所接收的**事件**或**中间结果**
   - 以供后续的**某个时间点**（例如收到下一个事件或者经过一段特定时间）进行**访问**并进行**后续处理**

![function-state](/Users/zhongmingmao/data/typora/function-state.png)

> **应用状态**是 Flink 中的**一等公民**，Flink 提供了许多**状态管理**相关的特性支持

1. 多种**状态基础类型**
   - Flink 为多种不同的数据结构提供了相对应的状态基础类型，例如原子值（**value**），列表（**list**）以及映射（**map**）
   - 开发者可以基于处理函数**对状态的访问方式**，选择**最高效**、**最适合**的状态基础类型
2. **插件化**的 **State Backend**
   - State Backend 负责**管理应用程序状态**，并在需要的时候进行 **checkpoint**
   - Flink 支持多种 state backend，可以将状态存在**内存**或者 **RocksDB**
     - RocksDB 是一种**高效的嵌入式、持久化键值存储引擎**
   - Flink 也支持插件式的**自定义** State Backend 进行状态存储
3. **精确一次语义**
   - Flink 的 **checkpoint** 和**故障恢复算法**保证了**故障**发生后**应用状态的一致性**
   - 因此，Flink 能够在应用程序发生故障时，对应用程序透明，**不造成正确性的影响**
4. **超大数据量状态**
   - Flink 能够利用其**异步**以及**增量式**的 **checkpoint** 算法，存储数 **TB** 级别的应用状态
5. **可弹性伸缩**的应用
   - Flink 能够通过在**更多**或**更少**的**工作节点**上对**状态**进行**重新分布**，支持**有状态应用**的**分布式**的**横向伸缩**

### 时间

1. 时间是流处理应用另一个重要的组成部分
2. 因为**事件**总是**在特定时间点发生**，所以大多数的事件流都拥有**事件本身所固有的时间语义**
3. 进一步而言，许多常见的**流计算**都基于**时间语义**，例如**窗口聚合**、**会话计算**、**模式检测**和**基于时间的 join**
4. 流处理的一个重要方面是应用程序**如何衡量时间**，即区分事件时间（**event-time**）和处理时间（**processing-time**）

> Flink 提供了丰富的**时间语义**支持

1. **事件时间**模式
   - 使用**事件时间语义**的流处理应用根据**事件本身自带的时间戳**进行结果的计算
   - 因此，无论处理的是**历史记录的事件**还是**实时的事件**，事件时间模式的处理总能保证**结果**的**准确性**和**一致性**
2. **Watermark** 支持
   - Flink 引入了 watermark 的概念，用以**衡量事件时间进展**
   - Watermark 也是一种平衡**处理延时**和**完整性**的灵活机制
3. **迟到数据处理**
   - 当以带有 **watermark** 的**事件时间模式**处理数据流时，在**计算完成之后**仍会有**相关数据到达** - 这样的事件被称为**迟到事件**
   - Flink 提供了多种处理迟到数据的选项，例如将这些数据**重定向到旁路输出**（**side output**）或者**更新之前完成计算的结果**
4. **处理时间**模式
   - 处理时间模式根据**处理引擎**的**机器时钟**触发计算，一般适用于有着**严格的低延迟需求**，并且能够**容忍近似结果**的流处理应用

## 分层 API

> Flink 根据**抽象程度**分层，提供了三种不同的 API - 每一种 API 在**简洁性**和**表达力**上有着不同的侧重，并且针对不同的应用场景

![api-stack](/Users/zhongmingmao/data/typora/api-stack.png)

### ProcessFunction

1. **ProcessFunction** 是 Flink 所提供的**最具表达力**的接口
   - ProcessFunction 可以处理**一或两条输入数据流**中的**单个事件**或者**归入一个特定窗口**内的**多个事件**
   - 它提供了对于**时间**和**状态**的**细粒度控制** - 开发者可以在其中**任意地修改状态**，也能够**注册定时器**用以在**未来的某一时刻**触发**回调函数**
2. 利用 **ProcessFunction** 实现许多**有状态**的**事件驱动应用**所需要的**基于单个事件**的复杂业务逻辑

### DataStream API

1. DataStream API 为许多**通用的流处理操作**提供了**处理原语**
   - 这些操作包括**窗口**、逐条**记录**的**转换**操作，在处理事件时进行**外部数据库查询**等
2. DataStream API 支持 **Java** 语言，预先定义了例如 **map**()、**reduce**()、**aggregate**() 等函数
   - 你可以通过**扩展实现预定义接口**或使用 Java 的 **Lambda 表达式**实现自定义的函数

### SQL & Table API

1. Flink 支持两种**关系型**的 API， **Table API** 和 **SQL** 
2. 这两个 API 都是**批处理和流处理统一的 API**
   - 这意味着在**无边界的实时数据流**和**有边界的历史记录数据流**上，关系型 API 会以**相同的语义**执行查询，并产生**相同的结果**
3. Table API 和 SQL 借助了 **Apache Calcite** 来进行**查询**的**解析**，**校验**以及**优化**
4. 可以与 **DataStream API** 无缝集成，并支持用户**自定义**的**标量函数**，**聚合函数**以及**表值函数**
5. Flink 的关系型 API 旨在简化**数据分析**、**数据流水线和 ETL 应用**的定义

# 运维

1. Apache Flink 是一个针对**无界**和**有界**数据流进行**有状态计算**的框架
2. 由于许多**流应用程序**旨在**以最短的停机时间连续运行**，因此**流处理器**必须提供**出色的故障恢复能力**，以及在**应用程序运行期间**进行**监控**和**维护**的工具
3. Apache Flink 非常注重**流数据处理**的**可运维性**

## 7 × 24

1. **流处理器**不仅要能在**服务出现故障**时候能够**重启服务**
2. 而且还要当**故障发生**时，保证能够**持久化服务内部各个组件的当前状态**
3. 只有这样才能保证在**故障恢复**时候，**服务**能够**继续正常运行**，好像故障就没有发生过一样

> Flink 通过以下多种机制维护应用**可持续运行**及其

1. **检查点**的**一致性**
   - Flink 的**故障恢复机制**是通过建立**分布式应用服务状态一致性检查点**实现的
   - 当有故障产生时，**应用服务**会**重启**后，再**重新加载上一次成功备份的状态检查点信息**
   - 结合**可重放**的**数据源**，该特性可保证精确一次（**exactly-once**）的**状态一致性**
2. **高效**的**检查点**
   - 如果一个应用要维护一个 **TB** 级的**状态信息**，对此应用的状态建立**检查点服务**的**资源开销**是**很高**的
   - 为了减小因**检查点服务**对**应用**的**延迟性**（SLAs）的影响，Flink 采用**异步**及**增量**的方式**构建检查点服务**
3. **端到端**的**精确一次**
   - Flink 为某些**特定的存储**支持了**事务型输出**的功能，及时在**发生故障**的情况下，也能够保证**精确一次**的**输出**
4. 集成多种**集群管理服务**
   - Flink 已与多种**集群管理服务**紧密集成 - Hadoop YARN、Apache Mesos、**Kubernetes**
   - 当集群中某个流程任务失败后，一个新的流程服务会**自动启动**并**替代**它继续执行
5. 内置**高可用**服务
   - Flink 内置了为解决**单点故障**问题的**高可用性**服务模块，此模块是基于 **Apache ZooKeeper** 技术实现的
   - Apache ZooKeeper 是一种**可靠的、交互式的、分布式协调服务组件**

## 应用 - 升级+迁移+暂停+恢复

1. 驱动**关键业务**服务的流应用是**经常需要维护**的
   - **升级**一个**有状态的流应用**并不是简单的事情
   - 为了升级一个改进后版本而简单**停止**当前流应用并**重启**时，我们还**不能丢失掉**当前流应用的所处于的**状态信息**
2. Flink 的 **Savepoint** 服务就是为解决**升级服务过程中记录流应用状态信息**及其相关难题而产生的一种**唯一**的、**强大**的组件
   - 一个 **Savepoint**，就是一个**应用服务状态**的**一致性快照**
   - 与 **Checkpoint** 组件的很相似，但是与 **Checkpoint** 相比，**Savepoint** 需要**手动触发启动**，而且当**流应用服务停止**时，它并**不会自动删除**
3. **Savepoint** 常被应用于启动一个**已含有状态的流服务**，并**初始化**其（备份时）状态

> Savepoint 有以下特点

1. 便于**升级应用服务版本**
   - Savepoint 常在**应用版本升级**时使用，当前应用的新版本更新升级时，可以根据上一个版本程序记录的 **Savepoint 内的服务状态信息**来**重启服务**
   - 也可能会使用**更早的 Savepoint 还原点**来重启服务，以便于修复由于**有缺陷的程序版本**导致的**不正确的程序运行结果**
2. 方便**集群服务移植**
   - 通过使用 Savepoint，**流服务应用**可以自由的在**不同集群**中迁移部署
3. 方便 **Flink 版本升级**
   - 通过使用 Savepoint，可以使应用服务在**升级 Flink** 时，更加**安全便捷**
4. 增加**应用并行服务**的**扩展性**
   - Savepoint 也常在**增加**或**减少**应用服务集群的**并行度**时使用
5. 便于 **A/B 测试**及**假设分析**场景对比结果
   - 通过把**同一应用**在使用**不同版本的应用程序**，基于**同一个 Savepoint 还原点**启动服务时，可以测试对比2个或多个版本程序的性能及服务质量
6. **暂停和恢复应用服务**
   - 一个**应用服务**可以在**新建一个 Savepoint** 后再**停止服务**，以便于**后面任何时间点**再根据这个**实时刷新的 Savepoint 还原点**进行**恢复**服务
7. **归档服务**
   - Savepoint 还提供**还原点的归档服务**，以便于用户能够**指定时间点的 Savepoint 的服务数据**进行**重置应用服务的状态**，进行**恢复服务**

## 应用 - 监控+控制

1. 如其它应用服务一样，持续运行的**流应用服务**也需要**监控**及集成到一些**基础设施资源管理服务**中，例如一个组件的**监控服务**及**日志服务**等
2. **监控服务**有助于**预测问题**并**提前做出反应**
3. **日志服务**提供日志记录能够帮助**追踪**、**调查**、**分析**故障发生的根本原因

> Flink 与许多常见的**日志记录**和**监视服务**集成得很好，并提供了一个 **REST API** 来**控制应用服务**和**查询应用信息**

1. **Web UI**
   - Flink 提供了一个 Web UI 来**观察**、**监视**和**调试**正在运行的应用服务
   - 并且还可以**执行**或**取消**组件或任务的**执行**
2. **日志集成服务**
   - Flink 实现了流行的 **slf4j 日志接口**，并与日志框架 **log4j** 或 **logback** 集成
3. **指标服务**
   - Flink 提供了一个**复杂的度量系统**来收集和报告**系统**和**用户定义**的**度量指标信息**
   - 度量信息可以**导出**到多个**报表组件服务** - JMX、**Prometheus** 等
4. **REST API**
   - Flink 提供多种 REST API 接口，有提交新应用程序、获取正在运行的应用程序的 Savepoint 服务信息、取消应用服务等接口
   - REST API 还提供元数据信息和已采集的运行中或完成后的应用服务的指标信息

# 场景

1. Apache Flink 功能强大，支持开发和运行**多种不同种类**的应用程序
2. 主要特性包括：**批流一体化**、**精密的状态管理**、**事件时间支持**以及**精确一次的状态一致性保障**等
3. Flink 不仅可以运行在包括 YARN、 Mesos、**Kubernetes** 在内的多种**资源管理框架**上，还支持在**裸机集群**上独立部署
4. 在启用**高可用**选项的情况下，它**不存在单点失效**问题
5. Flink 已经可以扩展到**数千核心**，其**状态**可以达到 **TB 级别**，且仍能保持**高吞吐**、**低延迟**的特性

## 事件驱动

> 什么是事件驱动型应用

1. 事件驱动型应用是一类**具有状态的应用**，它从**一个或多个事件流**提取数据，并根据到来的事件触发**计算**、**状态更新**或**其他外部动作**
2. 事件驱动型应用是在**计算存储分离**的传统应用基础上进化而来 - 在**传统架构**中，应用需要**读写远程事务型数据库**
3. 事件驱动型应用是基于**状态化流处理**来完成
   - 在该设计中，**数据和计算不会分离**，应用只需访问本地（**内存**或**磁盘**）即可获取数据
4. **系统容错性**的实现依赖于**定期**向**远程持久化存储**写入 **Checkpoint**

![usecases-eventdrivenapps](/Users/zhongmingmao/data/typora/usecases-eventdrivenapps.png)

> 事件驱动型应用的优势

1. 事件驱动型应用**无须查询远程数据库**，本地数据访问使得它具有**更高的吞吐**和**更低的延迟**
2. 而由于**定期**向**远程持久化存储**的 **checkpoint** 工作可以**异步**、**增量式**完成，因此对于正常事件处理的**影响甚微**
3. **传统分层架构**下，通常**多个应用**会**共享同一个数据库**，因而任何对数据库自身的**更改**都需要**谨慎协调**
   - 事件驱动型应用，由于**只需考虑自身数据**，因此在更改数据表示或服务扩容时所需的协调工作将大大减少

> Flink 如何支持事件驱动型应用

1. 事件驱动型应用会受制于**底层流处理系统**对**时间**和**状态**的**把控能力**，Flink 诸多优秀特质都是围绕这些方面来设计的
   - Flink 提供了一系列丰富的**状态操作原语**，允许以**精确一次**的**一致性语义**合并海量规模（**TB** 级别）的**状态数据**
   - 此外，Flink 还支持**事件时间**和**自由度极高的定制化窗口逻辑**，而且它内置的 **ProcessFunction** 支持**细粒度时间控制**，方便实现一些高级业务逻辑
   - 同时，Flink 还拥有一个**复杂事件处理**（CEP）类库，可以用来**检测数据流中的模式**
2. Flink 中针对事件驱动应用的明星特性当属 **Savepoint**
   - Savepoint 是一个**一致性的状态映像**，它可以用来初始化任意**状态兼容**的应用
   - 在完成一次 Savepoint 后，即可放心对应用**升级**或**扩容**，还可以启动多个版本的应用来完成 **A/B** 测试

## 数据分析

> 什么是数据分析应用

1. 数据分析任务需要从**原始数据**中提取**有价值**的**信息**和**指标**
2. 传统的分析方式通常是利用**批查询**，或将事件记录下来并基于此**有限数据集**构建应用来完成
   - 为了得到**最新数据的分析结果**，必须先将它们加入**分析数据集**并**重新执行查询**或**运行应用**，随后**将结果写入存储系统**或**生成报告**
3. 借助一些先进的**流处理引擎**，还可以**实时**地进行**数据分析**
   - 和传统模式下读取**有限数据集**不同，流式查询或应用会接入**实时事件流**，并**随着事件消费持续产生和更新结果**
   - 这些结果数据可能会**写入外部数据库系统**或以**内部状态**的形式维护，**仪表展示应用**可以相应地**从外部数据库读取数据**或**直接查询应用的内部状态**

![usecases-analytics](/Users/zhongmingmao/data/typora/usecases-analytics.png)

> 流式分析应用的优势

1. 和**批量分析**相比，由于**流式分析**省掉了**周期性**的**数据导入**和**查询过程**，因此从**事件**中**获取指标**的**延迟更低**
2. 不仅如此，**批量查询**必须处理那些由定期导入和输入**有界性**导致的**人工数据边界**，而流式查询则无须考虑该问题
3. **流式分析**会**简化应用抽象**
   - **批量查询**的**流水线**通常由**多个独立部件**组成，需要**周期性**地调度**提取数据**和**执行查询**，一旦某个组件出错将会影响流水线的后续步骤
   - **流式分析应用**整体运行在 **Flink** 之类的**高端流处理系统**之上，涵盖了从**数据接入**到**连续结果计算**的所有步骤，因此可以依赖**底层引擎**提供的**故障恢复**机制

> Flink 如何支持数据分析类应用

1. Flink 为**持续流式分析**和**批量分析**都提供了良好的支持
2. Flink 内置了一个符合 **ANSI** 标准的 **SQL** 接口，**将批、流查询的语义统一起来**
3. 无论是在记录事件的**静态数据集**上还是**实时事件流**上，**相同 SQL** 查询都会得到**一致的结果**
4. 同时 Flink 还支持丰富的**用户自定义函数**，允许在 **SQL** 中执行**定制化代码**
5. 如果还需**进一步定制逻辑**，可以利用 Flink **DataStream API** 和 **DataSet API** 进行**更低层次的控制**

## 数据管道

1. 提取-转换-加载（**ETL**）是一种在**存储系统之间**进行**数据转换和迁移**的常用方法
   - ETL 作业通常会**周期性地触发**，将数据从**事务型数据库**拷贝到**分析型数据库**或**数据仓库**
2. **数据管道**和 **ETL** 作业的用途相似，都可以**转换、丰富数据**，并将其从某个**存储系统**移动到另一个
   - 但**数据管道**是以**持续流模式**运行，而非周期性触发
   - 因此它支持从一个**不断生成数据的源头**读取记录，并将它们以**低延迟**移动到**终点**

![usecases-datapipelines](/Users/zhongmingmao/data/typora/usecases-datapipelines.png)

> 数据管道的优势

1. 和**周期性 ETL 作业**相比，**持续数据管道**可以明显**降低**将数据移动到目的端的**延迟**
2. 数据管道能够**持续**消费和发送数据，因此**用途更广**，支持用例更多

> Flink 如何支持数据管道应用

1. 很多常见的数据**转换**和**增强**操作可以利用 Flink 的 **SQL** 接口（或 **Table API**）及**用户自定义函数**解决
2. 如果数据管道有更高级的需求，可以选择**更通用**的 **DataStream API** 来实现
3. Flink 为多种**数据存储系统**内置了连接器 - **Kafka**、Kinesis、Elasticsearch、JDBC
4. 同时它还提供了**文件系统**的**连续型数据源及数据汇**，可用来**监控目录变化**和以**时间分区**的方式**写入文件**

# 操作

## 集群

1. 一个 Flink 集群总是包含**一个 JobManager** 以及**一个或多个 TaskManager**
2. **JobManager** 负责处理 **Job 提交**、 **Job 监控**以及**资源管理**
3. **TaskManager** 运行 **worker** 进程， 负责**实际任务** Tasks 的**执行**，而这些任务共同组成了一个 **Flink Job**

## 场景

![flink-docker-playground](/Users/zhongmingmao/data/typora/flink-docker-playground.svg)

![click-event-count-example](/Users/zhongmingmao/data/typora/click-event-count-example.svg)

1. 该 Job 负责从 **input topic** 消费点击事件 **ClickEvent**，每个点击事件都包含一个 **timestamp** 和一个 **page** 属性
2. 这些事件将按照 **page** 属性进行**分组**，然后按照每 **15s** 窗口 **windows** 进行统计， 最终结果输出到 **output topic** 中
3. 总共有 6 种不同的 page 属性，针对特定 page，我们会按照每 **15s** 产生 **1000** 个点击事件的速率**生成**数据
   - 因此，针对特定 page，该 Flink job 应该能在每个窗口中输出 1000 个该 page 的点击数据

![image-20241126175843742](/Users/zhongmingmao/data/typora/image-20241126175843742.png)

## 故障恢复

> 在 Job **部分失败**的情况下，Flink 对**事件处理**依然能够提供**精确一次**的保障

### 正常输出

> 事件以**特定速率**生成，刚好使得每个统计窗口都包含**确切**的 1000 条记录

![image-20241126191128856](/Users/zhongmingmao/data/typora/image-20241126191128856.png)

### 模拟失败

> kill 掉一个 **TaskManager** - TaskManager 进程挂掉、TaskManager 机器宕机、从框架或用户代码中抛出的一个临时异常

![image-20241126191524660](/Users/zhongmingmao/data/typora/image-20241126191524660.png)

> 几秒钟后，**JobManager** 就会**感知到 TaskManager 已失联**，接下来它会**取消 Job 运行**并且立即**重新提交该 Job** 以进行恢复

![image-20241126191819910](/Users/zhongmingmao/data/typora/image-20241126191819910.png)

1. 由于 **TaskManager** 提供的 **TaskSlots** 资源**不够用**，Job 的**所有任务**都不能成功转为 **RUNNING** 状态，直到有新的 **TaskManager** 可用
2. 在此之前，该 **Job** 将经历一个**取消**和**重新提交**不断循环的过程
3. 与此同时，**数据生成器**一直不断地往 **input topic** 中**生成 ClickEvent 事件**，在生产环境中也经常出现这种 **Job 挂掉**但**源头还在不断产生数据**的情况

### 故障恢复

> 一旦 **TaskManager** 重启成功，它将会**重新连接**到 **JobManager**

![image-20241126192200396](/Users/zhongmingmao/data/typora/image-20241126192200396.png)

1. 当 **TaskManager** 注册成功后，**JobManager** 就会将处于 **Restarting** 状态的**所有任务**调度到该 **TaskManager** 的**可用 TaskSlots** 中运行
2. 此时**所有的任务**将会从**失败前最近一次成功**的 **checkpoint** 进行**恢复**， 一旦**恢复成功**，它们的状态将转变为 **RUNNING**
3. 接下来该 **Job** 将**快速处理** Kafka input 事件的**全部积压**（在 Job 中断期间累积的数据）
   - 并以**更快的速度**产生输出，直到它**追上** kafka 的 **lag** 延迟为止
4. 在大部分生产环境中都需要一个资源管理器 (**Kubernetes**、Yarn)对失败的 Job 进行**自动重启**

![image-20241126192632758](/Users/zhongmingmao/data/typora/image-20241126192632758.png)

## 升级扩容

1. 使用 **Savepoint** 优雅地**停止 Flink Job**
   - **Savepoint** 是**整个应用程序状态**的一次**快照**（类似于 **checkpoint** ），该快照是在一个**明确定义**的、**全局一致**的**时间点**生成的
2. 从 Savepoint 恢复启动**待升级**的 Flink Job
   - **配置升级** - 修改 **Job 并行度**
   - **Job 拓扑升级** - 添加或者删除**算子**
   - Job 的**用户自定义函数**升级

### 停止 Job

> 要**优雅停止 Job**，需要使用 JobID 通过 **CLI** 或 **REST API** 调用 “**stop**” 命令

![image-20241126193544153](/Users/zhongmingmao/data/typora/image-20241126193544153.png)

![image-20241126193850654](/Users/zhongmingmao/data/typora/image-20241126193850654.png)

![image-20241126193612409](/Users/zhongmingmao/data/typora/image-20241126193612409.png)

### 重启 - 不做变更

> 从这个 **Savepoint** 重新启动待升级的 Job，为了简单起见，不对该 Job 作任何变更就

![image-20241126194215560](/Users/zhongmingmao/data/typora/image-20241126194215560.png)

![image-20241126194239764](/Users/zhongmingmao/data/typora/image-20241126194239764.png)

1. 刚启动的 Job 正在处理停止期间**积压**的大量数据
2. 在升级期间**没有产生任何数据丢失**

### 重启 - 修改并行度

> 在从 **Savepoint** 重启 **Job** 之前，你还可以通过**修改并行度**来达到**扩容 Job** 的目的

![image-20241126194633294](/Users/zhongmingmao/data/typora/image-20241126194633294.png)

> 现在 **Job** 已**重新提交**，但由于**提高了并行度**所以导致 **TaskSlots 不够用**（1 个 TaskSlot 可用，总共需要 3 个），最终 **Job** 会**重启失败**

![image-20241126194858410](/Users/zhongmingmao/data/typora/image-20241126194858410.png)

> 向 Flink 集群添加**第二个 TaskManager** - 为 Flink 集群提供 **2** 个 **TaskSlots** 资源
> **TaskManager** 会**自动向 JobManager 注册**，TaskManager 注册完成后，TaskManager 会再次处于 “**RUNNING**” 状态 - 在**扩容期间**数据依然**没有丢失**

![image-20241126195035745](/Users/zhongmingmao/data/typora/image-20241126195035745.png)

![image-20241126195054261](/Users/zhongmingmao/data/typora/image-20241126195054261.png)

## 查询指标

> 可以通过 **JobManager** 提供的 **REST API** 来获取**系统**和**用户**指标

```json
$ curl -s "localhost:8081/jobs/3f719b96075e76424d21bb71a80f99ea/metrics?get=lastCheckpointSize" | jq
[
  {
    "id": "lastCheckpointSize",
    "value": "5372"
  }
]
```

> **REST API** 不仅可以用于查询**指标**，还可以用于获取**正在运行中**的 **Job 详细信息**

![image-20241126195448032](/Users/zhongmingmao/data/typora/image-20241126195448032.png)

## 延伸扩展

1. `--checkpointing`
   - 开启了 **checkpoint** 配置，checkpoint 是 Flink **容错**机制的重要保证 - 可能会发生数据丢失
2. `--event-time`
   - 开启了 **Job** 的**事件时间**机制，使用 ClickEvent **自带的时间戳**进行统计
   - 如果不指定该参数，Flink 将结合**当前机器时间**使用**事件处理时间**进行统计
3. `--backpressure`
   - 将一个**额外算子**添加到 **Job** 中，该算子会在**偶数分钟**内**产生严重的反压**
   - **反压现象**可以通过多种**网络指标**观察到 - outputQueueLength / outPoolUsage
   - 通过 **WebUI** 上的**反压监控**也可以观察到

# 概念

## 流处理

1. 在自然环境中，数据的**产生**原本就是**流式**的
2. 在**分析**数据时，可以围绕有界流（**bounded**）或无界流（**unbounded**）两种模型来组织处理数据，当然，选择不同的模型，程序的执行和处理方式也都会不同

![bounded-unbounded](/Users/zhongmingmao/data/typora/bounded-unbounded-2600762.png)

1. **批处理**是**有界数据流**处理的范例
   - 在**批处理**模式下，可以选择在计算结果输出之前**输入整个数据集**，这也就意味着可以对**整个数据集**的数据进行**排序**、**统计**或**汇总**计算后再输出结果
2. 流处理涉及**无界数据流**
   - 在理论上，它的数据**输入永远不会结束**，因此程序必须**持续不断**地对到达的数据进行**处理**

> 在 Flink 中，应用程序由**用户自定义算子**转换而来的**流式 dataflows** 所组成
> 这些流式 dataflows 形成了**有向图**，以**一个或多个源（source）**开始，并以**一个或多个汇（sink）结束**

![program_dataflow](/Users/zhongmingmao/data/typora/program_dataflow.svg)

1. 通常，程序代码中的 **transformation** 和 dataflow 中的算子（**operator**）之间是**一一对应**的
2. 但有时也会出现**一个 transformation** 包含**多个 operator** 的情况

> 可以消费来自**消息队列**或**分布式日志**这类**流式数据源**（例如 **Apache Kafka** 或 Kinesis）的**实时数据**，也可以从各种的数据源中消费**有界的历史数据**
> 同样，Flink 应用程序**生成的结果流**也可以发送到各种**数据汇**中 - Sink

![flink-application-sources-sinks](/Users/zhongmingmao/data/typora/flink-application-sources-sinks.png)

## 并行 Dataflows

1. Flink 程序本质上是**分布式并行程序**
2. 在程序执行期间，一个**流**有一个或多个**流分区**（**Stream Partition**），每个**算子**有一个或**多个算子子任务**（**Operator Subtask**）
3. 每个**子任务**彼此**独立**，并在**不同的线程**中运行，或在**不同的计算机或容器**中运行
4. **算子子任务数**就是其对应**算子**的**并行度**
   - 在同一程序中，**不同算子**也可能具有**不同的并行度**

![parallel_dataflow](/Users/zhongmingmao/data/typora/parallel_dataflow.svg)

> Flink **算子之间**可以通过**一对一**（直传）模式或**重新分发**模式传输数据

1. **一对一**模式
   - 可以保留**元素**的**分区**和**顺序**信息
   - **同一分区的数据**只会进入到**下游算子**的**同一分区**
2. **重新分发**模式
   - 会**更改**数据所在的**流分区**
   - 选择使用**不同的 transformation**，每个算子**子任务**也会根据不同的 transformation 将数据发送到**不同的目标子任务**
   - 在重新分发数据的过程中，元素**只有**在**每对输出和输入子任务之间**才能**保留**其之间的**顺序**信息
     - 不同键（key）的聚合结果**到达 Sink 的顺序**是**不确定**的

| Transformation | Distribution       |
| -------------- | ------------------ |
| keyBy()        | 通过散列键重新分区 |
| broadcast()    | 广播               |
| rebalance()    | 随机重新分发       |

## 自定义时间流处理

1. 对于大多数流数据处理应用程序而言，能够使用处理**实时数据**的代码重新处理**历史数据**并产生**确定并一致的结果**非常有价值
2. 在处理**流式数据**时，我们通常更需要关注**事件本身发生的顺序**而不是**事件被传输以及处理的顺序**
   - 因为这能够帮助我们推理出一组事件（事件集合）是**何时发生以及结束**的
3. 为了满足上述这类的实时流处理场景，我们通常会使用记录在数据流中的**事件时间**的时间戳，而不是处理数据的**机器时钟**的时间戳

## 有状态流处理

1. Flink 中的**算子**可以是**有状态**的
   - 如何处理一个事件可能取决于该事件**之前所有事件数据**的**累积结果**
2. Flink 应用程序可以在**分布式群集**上**并行运行**，其中**每个算子**的**各个并行实例**会在**单独的线程**中独立运行，并且通常情况下是会在**不同的机器**上运行
3. **有状态算子**的**并行实例组**在**存储**其**对应状态**时通常是按照键（**key**）进行**分片**存储的
   - 每个**并行实例算子**负责处理一组**特定键**的**事件数据**，并且这组**键**对应的**状态**会**保存在本地**

![parallel-job](/Users/zhongmingmao/data/typora/parallel-job.png)

1. 前三个算子的并行度为 2，最后一个 sink 算子的并行度为 1，其中第三个算子是**有状态**的
2. 第二个算子和第三个算子之间是全互联的（**fully-connected**），它们之间通过**网络**进行**数据分发** - 模式为 **Push**
3. 通常情况下，实现这种类型的 Flink 程序是为了通过某些**键**对**数据流**进行**分区**，以便将**需要一起处理的事件**进行**汇合**，然后做**统一计算处理**

![local-state](/Users/zhongmingmao/data/typora/local-state-2603375.png)

1. Flink 应用程序的**状态访问**都在**本地**进行，因为这有助于其**提高吞吐量**和**降低延迟**
2. 通常情况下，Flink 应用程序都是将**状态**存储在 **JVM 堆**上，但如果**状态太大**，我们也可以选择将其以**结构化数据格式**存储在**高速磁盘**中

## 通过状态快照实现的容错

1. 通过**状态快照**和**流重放**两种方式的**组合**，Flink 能够提供**可容错**的，**精确一次计算**的语义

2. 这些**状态快照**在执行时会获取并存储**分布式 pipeline 中整体的状态**

   - 它会将**数据源中消费数据的偏移量**记录下来

   - 并将**整个 job graph 中算子**获取到该数据（记录的**偏移量**对应的数据）时的**状态**记录并存储下来

3. 当发生**故障**时，Flink 作业会**恢复上次存储的状态**，重置**数据源**从状态中记录的**上次消费的偏移量**开始**重新**进行**消费**处理

4. 而且**状态快照**在执行时会**异步**获取状态并存储，并**不会阻塞**正在进行的数据处理逻辑

# DataStream API

## 什么能被转化成流

1. Flink 的 Java DataStream API 可以将**任何可序列化的对象**转化为**流**
2. Flink **自带的序列化器**
   - 基本类型 - String、Long、Integer、Boolean、Array
   - 复合类型 - **Tuples**、**POJOs**、**Scala case classes**
3. Flink 会交给 **Kryo** 序列化**其他类型**
   - 可以将其他序列化器和 Flink 一起使用，特别是有良好支持的 **Avro**

### Tuples + POJOs

> Flink 的**原生序列化器**可以高效地操作 **Tuples** 和 **POJOs**

#### Tuples

> 对于 Java，Flink 自带有 **Tuple0** 到 **Tuple25** 类型

```java
Tuple2<String, Integer> person = Tuple2.of("Fred", 35);

// zero based index!  
String name = person.f0;
Integer age = person.f1;
```

#### POJOs

> 如果满足以下条件，Flink 将**数据类型**识别为 **POJO** 类型（并允许“**按名称**”字段**引用**）

1. 该类是**公有**且**独立**的（**没有非静态内部类**）
2. 该类有**公有**的**无参构造函数**
3. **类**（及**父类**）中**所有**的所有**不**被 **static**、**transient** 修饰的属性
   - 要么是**公有**的（且**不**被 **final** 修饰）
   - 要么是包含**公有**的 **getter** 和 **setter** 方法，这些方法遵循 **Java bean 命名规范**

```java
public class Person {
    public String name;  
    public Integer age;  
    public Person() {}
    public Person(String name, Integer age) {  
        . . .
    }
}  

Person person = new Person("Fred Flintstone", 35);
```

### Scala

> tuples + case classes

1. All **Flink Scala APIs** are **deprecated** and will be **removed** in a **future Flink version**. 
2. You can still **build** your application in Scala, but you should **move to the Java version** of either the DataStream and/or Table API.

![image-20241126162124727](/Users/zhongmingmao/data/typora/image-20241126162124727.png)

## Stream 执行环境

1. 每个 Flink 应用都需要有执行环境，**流式应用**需要用到 **StreamExecutionEnvironment**
2. **DataStream API** 将你的应用构建为一个 **job graph**，并附加到 **StreamExecutionEnvironment**
3. 当调用 **env.execute()** 时此 **job graph** 就被**打包**并发送到 **JobManager** 上，后者**对作业并行处理**并将其**子任务**分发给 **Task Manager** 来执行
   - 如果没有调用 execute()，应用就**不会运行**

> 此**分布式运行时**取决于你的应用是否是**可序列化**的，它还要求**所有依赖**对**集群**中的**每个节点**均可用

![distributed-runtime](/Users/zhongmingmao/data/typora/distributed-runtime.svg)

## Stream Source

1. 基本 - 原型或测试
   - fromElements
   - fromCollection
   - socketTextStream
   - readTextFile
2. 生产
   - 支持**低延迟**，**高吞吐并行读取**以及**重复**（高性能和容错能力为先决条件）的数据源，如 Apache **Kafka**
   - **REST API** 和**数据库**也经常用于**增强流处理的能力**（stream enrichment）

## Stream Sink

1. 基本 - 原型或测试
   - **print()** - 打印其结果到 task manager 的日志中（如果运行在 IDE 中时，将追加到你的 IDE 控制台）
2. 生产
   - 数据库
   - pub-sub 系统

# Pipelines + ETL

1. Apache Flink 的一种常见应用场景是 **ETL**（抽取、转换、加载）管道任务
2. 从**一个或多个数据源**获取数据，进行一些**转换操作**和**信息补充**，将结果**存储**起来

## 无状态转换

> map + flatmap

### map

![image-20241128153154792](/Users/zhongmingmao/data/typora/image-20241128153154792.png)



### flatmap

> **MapFunction** 只适用于**一对一**的转换 - 对每个进入**算子**的**流元素**，`map()` 将**仅输出一个转换后的元素**

![image-20241128153706024](/Users/zhongmingmao/data/typora/image-20241128153706024.png)

> **Collector** - 可以输出**任意数量**的元素，包括 0 个

## Keyed Streams

### keyBy

> 将一个流根据其中的一些**属性**来进行**分区**是十分有用的，这样可以使所有**具有相同属性的事件**分到**相同的组**里

![image-20241128154321017](/Users/zhongmingmao/data/typora/image-20241128154321017.png)

> 每个 **keyBy** 会通过 **shuffle** 来为**数据流**进行**重新分区** - 总体来说这个**开销**是**很大**的，它涉及**网络通信**、**序列化**和**反序列化**

![keyBy](/Users/zhongmingmao/data/typora/keyBy.png)

### 通过计算得到键

1. **KeySelector** 不仅限于**从事件中抽取键**
2. 可以按想要的方式计算得到键值，只要**最终结果**是**确定**的，并且实现了 **hashCode()** 和 **equals()**
   - 这些限制条件**不包括**产生**随机数**或者返回 **Arrays** 或 **Enums** 的 KeySelector
   - 可以用**元组**和 **POJO** 来组成**键**，只要他们的元素遵循上述条件 - **hashCode** + **equals**
3. **键**必须按**确定的方式**产生，因为它们会在**需要**的时候被**重新计算**，而不是一直被带在流记录中

```java
keyBy(enrichedRide -> enrichedRide.startCell)

// better
keyBy(ride -> GeoUtils.mapToGridCell(ride.startLon, ride.startLat))
```

### Keyed Stream 聚合

```java
minutesByStartCell
  .keyBy(value -> value.f0) // .keyBy(value -> value.startCell)
  .maxBy(1) // duration
  .print();
```

### 隐式状态

1. 尽管状态的**处理**是**透明**的，Flink 必须**跟踪每个不同的键**的最大时长
2. 只要**应用**中有**状态**，你就应该考虑**状态的大小**
   - 如果**键值的数量**是**无限**的，那 **Flink 的状态需要的空间**也同样是**无限**的
3. 在**流处理**场景中，考虑**有限窗口的聚合**往往比**整个流聚合**更有意义

### reduce

1. **maxBy** 只是 Flink 中 **KeyedStream** 上众多**聚合函数**中的一个
2. 还有一个**更通用**的 **reduce** 函数可以用来实现**自定义聚合**

## 有状态转换

### 状态管理

> 在 Flink 不参与管理状态的情况下，**应用**也可以**使用状态**，Flink 为其**管理状态**提供了一些引人注目的特性

1. **本地性**
   - Flink 状态是存储在使用它的**机器本地**的，并且可以以**内存**访问速度来获取
2. **持久性**
   - Flink 状态是**容错**的，例如，它可以自动按**一定的时间间隔**产生 **checkpoint**，并且在**任务失败**后进行**恢复**
3. **纵向可扩展性**
   - Flink 状态可以存储在集成的 **RocksDB** 实例中，这种方式下可以通过**增加本地磁盘**来扩展空间
4. **横向可扩展性**
   - Flink 状态可以**随着集群的扩缩容重新分布**

### Rich Functions

1. FilterFunction、MapFunction、FlatMapFunction - **单一抽象方法模式**
2. 对其中的每一个接口，Flink 同样提供了一个**rich** 变体 - RichFlatMapFunction

| Method                  | Desc                                                         |
| ----------------------- | ------------------------------------------------------------ |
| `open(Configuration c)` | 仅在**算子初始化**时调用一次 - 可以用来加载一些**静态数据**，或者建立**外部服务链接**等 |
| `close()`               |                                                              |
| `getRuntimeContext()`   | 提供了一个**访问途径**，最明显的，它是你创建和访问 Flink 状态的途径 |

### Keyed State

> 有一个要**去重**的事件数据流，对**每个键**只保留**第一个事件**

![image-20241128162701464](/Users/zhongmingmao/data/typora/image-20241128162701464.png)

```java
public static void main(String[] args) throws Exception {
    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
  
    env.addSource(new EventSource())
        .keyBy(e -> e.key)
        .flatMap(new Deduplicator())
        .print();
  
    env.execute();
}
```

1. Deduplicator 需要记录**每个键**是否已经有了相应的记录 -  **keyed state**
2. 当使用 **keyed stream** 时，Flink 会为每个状态中管理的条目维护一个**键值存储**
3. Flink 支持几种不同方式的 **keyed state**，最简单的是 **ValueState** - 对于**每个键** ，Flink 将存储一个**单一的对象**
4. open - 通过定义 `ValueStateDescriptor<Boolean>` 建立了**管理状态**的使用
   - 提供 - 状态的**名字** + 如何**序列化**
5. flatMap - keyHasBeenSeen.value()
   - Flink 会在**当前键的上下文**中**检索状态值**，只有当状态为 null 时，才会**输出**当前事件，同时也将**更新** keyHasBeenSeen 为 true
   - **键不是明确可见**
6. 当 **Flink 运行时**调用 **RichFlatMapFunction** 的 **open** 方法时， 是**没有事件**的，所以这个时候**上下文**中**不含有任何键**
   - 当调用 **flatMap** 方法，**被处理的事件的键**在**运行时**中就是**可用**的了，并且被用来确定操作哪个 Flink 状态后端的入口
7. 部署在**分布式集群**时，将会有**很多** Deduplicator 的**实例**，每一个实例将负责**整个键空间**的**互斥子集**中的一个
8. **ValueState** - 是一个**分布式**的**共享键值存储**
9. 当**键空间**是**无界**的时候，Flink 会对每个使用过的键都存储一个 Boolean 类型的实例，在**键无限增长**的应用中，**清除**再也不会使用的状态是很必要的
   - **定时器** / **TTL**

### Non-keyed State

1. 在**没有键**的**上下文**中我们也可以使用 Flink 管理的状态，称为 **OperatorState**
2. 它包含的接口是很不一样的，由于对**用户定义的函数**来说使用 **non-keyed state** 是**不太常见**的 - **source / sink**

## Connected Streams

> 预先定义的转换

![transformation](/Users/zhongmingmao/data/typora/transformation.svg)

> connected streams - 一个单独的算子有两个输入流 - **更灵活地调整转换的某些功能**

![connected-streams](/Users/zhongmingmao/data/typora/connected-streams.svg)

> 一个**控制流**是用来指定哪些词需要从 streamOfWords 里过滤掉的

```java
public class ControlFunction extends RichCoFlatMapFunction<String, String, String> {

  private ValueState<Boolean> blocked;

  @Override
  public void open(Configuration parameters) throws Exception {
    blocked = getRuntimeContext().getState(new ValueStateDescriptor<>("blocked", Boolean.class));
  }

  @Override
  public void flatMap1(String control_value, Collector<String> out) throws Exception {
    blocked.update(Boolean.TRUE);
  }

  @Override
  public void flatMap2(String data_value, Collector<String> out) throws Exception {
    if (blocked.value() == null) {
      out.collect(data_value);
    }
  }

  public static void main(String[] args) throws Exception {
    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

    DataStream<String> control = env.fromElements("DROP", "IGNORE").keyBy(x -> x);

    DataStream<String> streamOfWords =
        env.fromElements("Apache", "DROP", "Flink", "IGNORE").keyBy(x -> x);

    control.connect(streamOfWords).flatMap(new ControlFunction()).print();

    env.execute();
  }
}
```

1. 两个流只有**键一致**的时候才能连接
2. **keyBy** 的作用是**将流数据分区**，当 **keyed stream** 被连接时，他们必须按**相同的方式分区**
   - 保证了**两个流**中**所有键相同的事件**发到**同一个实例**上 - 使**按键关联两个流**成为可能
3. RichCoFlatMapFunction 在状态中存了一个布尔类型的变量，这个变量**被两个流共享**
4. **RichCoFlatMapFunction** 是一种可以被用于一对**连接流**的 **FlatMapFunction**，并且它可以调用 **rich function** 的接口 - **有状态的**
5. 布尔变量 **blocked** 被用于记录在数据流 **control** 中**出现过的键** - keyed state，**被两个流共享** - 两个流必须有**相同的键值空间**
6. 在 **Flink 运行时**中，**flatMap1** 和 **flatMap2** 在连接流有**新元素**到来时**被调用**
   - control 流中的元素会进入 flatMap1，streamOfWords 中的元素会进入 flatMap2 - control.connect(streamOfWords)
7. **没法控制** flatMap1 和 flatMap2 的**调用顺序**
   - 这**两个输入流**是**相互竞争**的关系，**Flink 运行时**将根据从一个流或另一个流中**消费**的事件
   - 对于需要保证**时间**和/或**顺序**的场景，你会发现在 Flink 的管理状态中**缓存事件**一直到它们能够被处理是必须的

```java
    // A stream of taxi ride START events, keyed by rideId.
    DataStream<TaxiRide> rides =
        env.addSource(rideSource).filter(ride -> ride.isStart).keyBy(ride -> ride.rideId);

    // A stream of taxi fare events, also keyed by rideId.
    DataStream<TaxiFare> fares = env.addSource(fareSource).keyBy(fare -> fare.rideId);

    // Create the pipeline.
    rides
        .connect(fares)
        .flatMap(new EnrichmentFunction())
        .uid("enrichment") // uid for this operator's state
        .name("enrichment") // name for this operator in the web UI
        .addSink(sink);
```

```java
  public static class EnrichmentFunction
      extends RichCoFlatMapFunction<TaxiRide, TaxiFare, RideAndFare> {

    private ValueState<TaxiRide> rideState;
    private ValueState<TaxiFare> fareState;

    @Override
    public void open(Configuration config) {
      rideState =
          getRuntimeContext().getState(new ValueStateDescriptor<>("saved ride", TaxiRide.class));
      fareState =
          getRuntimeContext().getState(new ValueStateDescriptor<>("saved fare", TaxiFare.class));
    }

    @Override
    public void flatMap1(TaxiRide ride, Collector<RideAndFare> out) throws Exception {
      TaxiFare fare = fareState.value();
      if (fare != null) {
        fareState.clear();
        out.collect(new RideAndFare(ride, fare));
      } else {
        rideState.update(ride);
      }
    }

    @Override
    public void flatMap2(TaxiFare fare, Collector<RideAndFare> out) throws Exception {
      TaxiRide ride = rideState.value();
      if (ride != null) {
        rideState.clear();
        out.collect(new RideAndFare(ride, fare));
      } else {
        fareState.update(fare);
      }
    }
  }
```

# Streaming Analytics

## Event Time + Watermarks

### 概要

> Flink 明确支持以下三种时间语义

| Time                           | Desc                                                     |
| ------------------------------ | -------------------------------------------------------- |
| 事件时间 - **event** time      | **事件产生**的时间，记录的是设备生产(或者存储)事件的时间 |
| 摄取时间 - **ingestion** time  | Flink **读取事件**时记录的时间                           |
| 处理时间 - **processing** time | Flink pipeline 中**具体算子处理事件**的时间              |

1. 为了获得**可重现的结果**，应该使用**事件时间** - 无论什么时间去计算都**不会影响输出结果**
2. 如果使用**处理时间**的话，实时应用程序的结果是由程序**运行的时间**所决定
   - 多次运行基于**处理时间**的实时程序，可能得到的**结果**都**不相同**

### Event Time

1. 如果想要使用**事件时间**，需要额外给 Flink 提供一个**时间戳提取器**和 **Watermark 生成器**
2. Flink 将使用它们来**跟踪事件时间的进度**

### Watermarks

> watermarks - 定义**何时停止等待较早的事件**

1. Flink 中**事件时间**的处理取决于 **watermark 生成器**，后者将**带有时间戳**的**特殊元素**插入**流**中形成 **watermarks**
2. **事件时间 t** 的 **watermark** 代表 **t 之前**（很可能）**都已经到达**

