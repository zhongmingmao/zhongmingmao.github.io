---
title: Observability - Prometheus Concepts
mathjax: true
date: 2025-01-23 00:06:25
cover: https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/prometheus-concepts.jpg
categories:
  - Cloud Native
  - Observability
tags:
  - Cloud Native
  - Observability
---

# Data model

1. Prometheus fundamentally stores **all data** as **time series**
   - **streams** of **timestamped values** belonging to the **same metric** and the **same set of labeled dimensions**.
2. Besides **stored time series**, Prometheus may generate **temporary derived time series** as the **result** of **queries**.

<!-- more -->

## Metric names and labels

Every **time series** is **uniquely identified** by its **metric name** and **optional key-value pairs** called **labels**.

### Metric names

1. Metric names **SHOULD** specify the **general feature** of a system that is measured
   - e.g. **http_requests_total** - the total number of HTTP requests received
2. Metric names **MAY** use any **UTF-8** characters.
3. Metric names **SHOULD** match the regex `[a-zA-Z_:][a-zA-Z0-9_:]*` for the **best experience and compatibility** (see the warning below).
   - Metric names **outside of that set** will require **quoting** e.g. when used in **PromQL**

> Colons ('**:**') are **reserved** for **user-defined recording rules**. They **SHOULD NOT** be used by **exporters** or **direct instrumentation**.

### Metric labels

1. Labels let you capture **different instances** of the **same metric name**.
   - For example: all HTTP requests that used the method POST to the **/api/tracks** handler.
2. We refer to this as Prometheus's "**dimensional data model**".
3. The **query language** allows **filtering** and **aggregation** based on these **dimensions**.
4. The **change** of **any label's value**, including **adding or removing labels**, will **create a new time series**.
   - Label names **MAY** use any **UTF-8** characters.
   - Label names **beginning** with `__` (two underscores) MUST be **reserved** for **internal Prometheus use**.
   - Label names **SHOULD** match the regex `[a-zA-Z_][a-zA-Z0-9_]*` for the **best experience and compatibility** (see the warning below).
     - Label names **outside of that regex** will require **quoting** e.g. when used in **PromQL**
   - Label values **MAY** contain any **UTF-8** characters.
   - Labels with an **empty label value** are considered **equivalent** to labels that **do not exist**.

> WARNING

1. The **UTF-8 support** for **metric and label names** was added relatively recently in **Prometheus v3.0.0**.
2. It might **take time** for the **wider ecosystem** to adopt **new quoting mechanisms**, <u>relaxed validation</u> etc.
   - downstream PromQL compatible projects and vendors, tooling, third-party instrumentation, collectors, etc.
3. For the **best compatibility** it's recommended to **stick** to the **recommended** ("**SHOULD**") character set.

```
  æŒ‡æ ‡åç§° (Metric Names)

  åŸºæœ¬è§„åˆ™

  - ç›®çš„: æŒ‡å®šç³»ç»Ÿæµ‹é‡çš„é€šç”¨ç‰¹å¾ï¼ˆå¦‚ http_requests_total - HTTPè¯·æ±‚æ€»æ•°ï¼‰
  - å­—ç¬¦: å¯ä½¿ç”¨ä»»ä½•UTF-8å­—ç¬¦
  - æ¨èæ ¼å¼: åº”åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼ [a-zA-Z_:][a-zA-Z0-9_:]*
  - âš ï¸ é‡è¦é™åˆ¶:
    - å†’å· (:) ä¿ç•™ç»™ç”¨æˆ·å®šä¹‰çš„è®°å½•è§„åˆ™
    - å¯¼å‡ºå™¨æˆ–ç›´æ¥ä»ªè¡¨åŒ–ä¸åº”ä½¿ç”¨å†’å·

  æ ‡ç­¾ (Labels)

  æ ‡ç­¾åç§°è§„åˆ™

  - ä½œç”¨: æ•è·åŒä¸€æŒ‡æ ‡åç§°çš„ä¸åŒå®ä¾‹ï¼ˆå¦‚POSTæ–¹æ³•ã€/api/trackså¤„ç†å™¨çš„HTTPè¯·æ±‚ï¼‰
  - å­—ç¬¦: å¯ä½¿ç”¨ä»»ä½•UTF-8å­—ç¬¦
  - å†…éƒ¨ä¿ç•™: ä»¥ __ å¼€å¤´çš„æ ‡ç­¾åç§°ä¿ç•™ç»™Prometheuså†…éƒ¨ä½¿ç”¨
  - æ¨èæ ¼å¼: åº”åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼ [a-zA-Z_][a-zA-Z0-9_]*

  æ ‡ç­¾å€¼è§„åˆ™

  - å­—ç¬¦: å¯åŒ…å«ä»»ä½•UTF-8å­—ç¬¦
  - ç©ºå€¼å¤„ç†: ç©ºæ ‡ç­¾å€¼ç­‰åŒäºæ ‡ç­¾ä¸å­˜åœ¨
  - æ—¶é—´åºåˆ—: ä»»ä½•æ ‡ç­¾å€¼çš„å˜æ›´ï¼ˆåŒ…æ‹¬æ·»åŠ /åˆ é™¤æ ‡ç­¾ï¼‰éƒ½ä¼šåˆ›å»ºæ–°çš„æ—¶é—´åºåˆ—

  ç»´åº¦æ•°æ®æ¨¡å‹

  Prometheusçš„"ç»´åº¦æ•°æ®æ¨¡å‹"å…è®¸æŸ¥è¯¢è¯­è¨€åŸºäºè¿™äº›ç»´åº¦è¿›è¡Œè¿‡æ»¤å’Œèšåˆã€‚

  å…¼å®¹æ€§è­¦å‘Š

  - UTF-8æ”¯æŒ: åœ¨Prometheus v3.0.0ä¸­æ–°å¢
  - ç”Ÿæ€å…¼å®¹: æ•´ä¸ªç”Ÿæ€ç³»ç»Ÿï¼ˆPromQLå…¼å®¹é¡¹ç›®ã€å·¥å…·ã€ç¬¬ä¸‰æ–¹ä»ªè¡¨åŒ–ç­‰ï¼‰é‡‡ç”¨æ–°å¼•ç”¨æœºåˆ¶éœ€è¦æ—¶é—´
  - æœ€ä½³å®è·µ: ä¸ºæœ€ä½³å…¼å®¹æ€§ï¼Œå»ºè®®éµå¾ªæ¨èçš„å­—ç¬¦é›†

  è¿™äº›è§„åˆ™ç¡®ä¿äº†PrometheusæŒ‡æ ‡çš„ä¸€è‡´æ€§å’Œå¯ç»´æŠ¤æ€§ï¼ŒåŒæ—¶æ”¯æŒå¤æ‚çš„ç›‘æ§éœ€æ±‚ã€‚
```

## Samples

> Samples form the **actual time series data**. Each sample consists of:

1. a **float64** or **native histogram** value
2. a **millisecond-precision timestamp**]

```
  Float64 vs Native Histogram

  Float64 æ ·æœ¬

  value: 123.45 (å•ä¸ªæ•°å€¼)
  timestamp: 1695912345678 (æ¯«ç§’æ—¶é—´æˆ³)

  Native Histogram æ ·æœ¬

  value: {
    count: 1000 (è§‚å¯Ÿæ¬¡æ•°)
    sum: 12345.67 (æ‰€æœ‰è§‚å¯Ÿå€¼çš„æ€»å’Œ)
    zero_threshold: 0.001 (é›¶å€¼é˜ˆå€¼)
    zero_count: 50 (é›¶å€¼æˆ–æ¥è¿‘é›¶å€¼çš„æ•°é‡)
    schema: 1 (å¢é•¿å› å­æ¨¡å¼)
    positive_buckets: [
      {upper_bound: 0.1, count: 100},
      {upper_bound: 1.0, count: 200},
      {upper_bound: 10.0, count: 300}
    ]
    negative_buckets: [...] (è´Ÿå€¼æ¡¶)
  }
  timestamp: 1695912345678

  ä¸ºä»€ä¹ˆå¼•å…¥ Native Histogramï¼Ÿ

  1. å­˜å‚¨æ•ˆç‡æå‡

  ä¼ ç»Ÿæ–¹æ¡ˆ (å¤šä¸ªæŒ‡æ ‡):
  http_request_duration_seconds_bucket{le="0.1"} 100
  http_request_duration_seconds_bucket{le="0.5"} 200
  http_request_duration_seconds_bucket{le="1.0"} 350
  http_request_duration_seconds_bucket{le="5.0"} 450
  http_request_duration_seconds_bucket{le="+Inf"} 500
  http_request_duration_seconds_sum 1234.56
  http_request_duration_seconds_count 500

  Native Histogram (å•ä¸ªæŒ‡æ ‡):
  http_request_duration_seconds{...} {åŒ…å«æ‰€æœ‰æ¡¶ä¿¡æ¯çš„ä¸€ä¸ªæ ·æœ¬}

  2. æ€§èƒ½ä¼˜åŠ¿

  | æ–¹é¢   | ä¼ ç»Ÿ Histogram | Native Histogram |
  |------|--------------|------------------|
  | å­˜å‚¨ç©ºé—´ | å¤šä¸ªæ—¶é—´åºåˆ—       | å•ä¸ªæ—¶é—´åºåˆ—           |
  | æŸ¥è¯¢æ€§èƒ½ | éœ€è¦å…³è”å¤šä¸ªæŒ‡æ ‡     | å•æ¬¡æŸ¥è¯¢è·å–æ‰€æœ‰ä¿¡æ¯       |
  | å‹ç¼©æ•ˆç‡ | è¾ƒä½           | æ›´é«˜               |
  | ç½‘ç»œä¼ è¾“ | å¤šä¸ªæ ·æœ¬         | å•ä¸ªæ ·æœ¬             |

  3. ç²¾åº¦å’Œçµæ´»æ€§

  åŠ¨æ€æ¡¶è¾¹ç•Œ:
  - Native histogram å¯ä»¥åŠ¨æ€è°ƒæ•´æ¡¶çš„è¾¹ç•Œ
  - åŸºäºè§‚å¯Ÿåˆ°çš„æ•°æ®åˆ†å¸ƒä¼˜åŒ–æ¡¶çš„è®¾ç½®
  - å‡å°‘é¢„å®šä¹‰æ¡¶è¾¹ç•Œçš„çŒœæµ‹å·¥ä½œ

  æ›´é«˜ç²¾åº¦:
  // ç¤ºä¾‹ï¼šè§‚å¯Ÿå»¶è¿Ÿåˆ†å¸ƒ
  histogram.Observe(0.123)  // è‡ªåŠ¨åˆ†é…åˆ°åˆé€‚çš„æ¡¶
  histogram.Observe(45.678) // æ ¹æ®æ•°æ®åˆ†å¸ƒåŠ¨æ€è°ƒæ•´

  ä½¿ç”¨åœºæ™¯å¯¹æ¯”

  Float64 é€‚ç”¨åœºæ™¯

  # ç®€å•çš„è®¡æ•°å™¨ã€ä»ªè¡¨ç›˜
  cpu_usage_percent 75.5
  memory_available_bytes 2147483648
  active_connections 150

  Native Histogram é€‚ç”¨åœºæ™¯

  # å»¶è¿Ÿåˆ†å¸ƒã€è¯·æ±‚å¤§å°ã€å“åº”æ—¶é—´ç­‰
  http_request_duration_seconds{quantile="0.95"} 2.5
  grpc_request_size_bytes{quantile="0.50"} 1024

  è¿ç§»ç¤ºä¾‹

  ä¹‹å‰ (ä¼ ç»Ÿæ–¹å¼):
  // Go å®¢æˆ·ç«¯ä¼ ç»Ÿ histogram
  hist := prometheus.NewHistogram(prometheus.HistogramOpts{
      Name:    "http_request_duration_seconds",
      Help:    "HTTP request latency.",
      Buckets: prometheus.DefBuckets, // [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]
  })

  ç°åœ¨ (Native Histogram):
  // Go å®¢æˆ·ç«¯ native histogram
  hist := prometheus.NewNativeHistogram(prometheus.NativeHistogramOpts{
      Name:    "http_request_duration_seconds",
      Help:    "HTTP request latency.",
      // æ— éœ€é¢„å®šä¹‰æ¡¶ï¼Œè‡ªåŠ¨ä¼˜åŒ–
  })

  æŸ¥è¯¢è¯­æ³•å˜åŒ–

  ä¼ ç»ŸæŸ¥è¯¢:
  # è®¡ç®— 95th ç™¾åˆ†ä½
  histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

  Native Histogram æŸ¥è¯¢:
  # ç›´æ¥æŸ¥è¯¢ç™¾åˆ†ä½æ•°
  histogram_quantile(0.95, rate(http_request_duration_seconds[5m]))

  æ€»ç»“

  å¼•å…¥ Native Histogram çš„ä¸»è¦åŠ¨æœºï¼š

  1. å­˜å‚¨æ•ˆç‡: å°†å¤šä¸ªç›¸å…³çš„æ—¶é—´åºåˆ—åˆå¹¶ä¸ºä¸€ä¸ª
  2. æ€§èƒ½æå‡: å‡å°‘æŸ¥è¯¢æ—¶çš„æ•°æ®å…³è”æ“ä½œ
  3. ç²¾åº¦æ”¹è¿›: åŠ¨æ€æ¡¶åˆ†é…æä¾›æ›´ç²¾ç¡®çš„æ•°æ®åˆ†å¸ƒ
  4. ç®€åŒ–é…ç½®: æ— éœ€é¢„å®šä¹‰æ¡¶è¾¹ç•Œ
  5. ç½‘ç»œä¼˜åŒ–: å‡å°‘ä¼ è¾“çš„æ•°æ®é‡

  è¿™æ˜¯ Prometheus åœ¨ v2.40 ç‰ˆæœ¬å¼•å…¥çš„é‡å¤§æ”¹è¿›ï¼Œä¸ºå¤§è§„æ¨¡ç›‘æ§æä¾›äº†æ›´å¥½çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚
```

## Notation

Given **a metric name** and **a set of labels**, time series are frequently identified using this notation:

```
<metric name>{<label name>="<label value>", ...}
```

For example, a time series with the metric name <u>api_http_requests_total</u> and the labels <u>method="POST"</u> and <u>handler="/messages"</u> could be written like this:

```
api_http_requests_total{method="POST", handler="/messages"}
```

This is the **same notation** that **OpenTSDB** uses.

Names with **UTF-8** characters **outside the recommended** set must be **quoted**, using this **notation**:

```
{"<metric name>", <label name>="<label value>", ...}
```

Since **metric name** are **internally represented** as a **label pair** with a **special label name** (`__name__="<metric name>"`) one could also use the following notation:

```
{__name__="<metric name>", <label name>="<label value>", ...}
```

# Metric types

1. The Prometheus **client libraries** offer **four** core metric types.
2. These are currently **only differentiated in the client libraries** (to enable **APIs tailored** to the **usage** of the **specific types**) and in the **wire protocol**.
3. The **Prometheus server** does **not yet** make use of the **type information** and **flattens all data** into **untyped time series**. This may change in the future.

```
  æ ¸å¿ƒå«ä¹‰

  ç›®å‰ï¼Œè¿™äº›æŒ‡æ ‡ç±»å‹ä»…åœ¨å®¢æˆ·ç«¯åº“å’Œä¼ è¾“åè®®ä¸­æœ‰åŒºåˆ†ï¼Œè€Œåœ¨ Prometheus æœåŠ¡å™¨å†…éƒ¨ï¼Œæ‰€æœ‰ç±»å‹éƒ½ä»¥ç›¸åŒçš„æ–¹å¼å­˜å‚¨å’Œå¤„ç†ã€‚

  å…·ä½“åˆ†æ

  1. å®¢æˆ·ç«¯åº“çš„å·®å¼‚åŒ–å¤„ç†

  // Go å®¢æˆ·ç«¯åº“ç¤ºä¾‹
  // Counter - è®¡æ•°å™¨
  counter := prometheus.NewCounter(prometheus.CounterOpts{
      Name: "http_requests_total",
      Help: "Total number of HTTP requests",
  })
  counter.Inc()  // åªèƒ½å¢åŠ ï¼Œä¸èƒ½å‡å°‘

  // Gauge - ä»ªè¡¨ç›˜
  gauge := prometheus.NewGauge(prometheus.GaugeOpts{
      Name: "memory_usage_bytes",
      Help: "Current memory usage",
  })
  gauge.Set(1024)  // å¯ä»¥ä»»æ„è®¾ç½®å€¼
  gauge.Dec()      // å¯ä»¥å‡å°‘

  // Histogram - ç›´æ–¹å›¾
  histogram := prometheus.NewHistogram(prometheus.HistogramOpts{
      Name: "request_duration_seconds",
      Help: "Request latency",
  })
  histogram.Observe(0.5)  // è§‚å¯Ÿå€¼

  2. ä¼ è¾“åè®®ä¸­çš„ç±»å‹æ ‡è¯†

  # Wire Protocol ç¤ºä¾‹
  # Counter ç±»å‹
  http_requests_total{method="GET"} 1234 1695912345678

  # Gauge ç±»å‹
  memory_usage_bytes{instance="host1"} 1073741824 1695912345678

  # Histogram ç±»å‹
  request_duration_seconds_bucket{le="1.0"} 100 1695912345678
  request_duration_seconds_sum 50.5 1695912345678
  request_duration_seconds_count 100 1695912345678

  3. æœåŠ¡å™¨å†…éƒ¨ç»Ÿä¸€å¤„ç†

  åœ¨ Prometheus æœåŠ¡å™¨å†…éƒ¨ï¼š
  // å†…éƒ¨æ•°æ®ç»“æ„ - æ‰€æœ‰ç±»å‹éƒ½æ˜¯æ—¶é—´åºåˆ—
  type Sample struct {
      Value     float64    // å­˜å‚¨æ•°å€¼
      Timestamp int64      // æ—¶é—´æˆ³
  }

  type TimeSeries struct {
      Labels  Labels       // æ ‡ç­¾
      Samples []Sample     // æ ·æœ¬åºåˆ—
  }

  4. API å±‚é¢çš„ç±»å‹åŒ–æ¥å£

  # Python å®¢æˆ·ç«¯åº“
  from prometheus_client import Counter, Gauge, Histogram

  # ä¸åŒç±»å‹æœ‰ä¸åŒçš„ API
  requests_total = Counter('http_requests_total', 'Total requests')
  memory_usage = Gauge('memory_usage_bytes', 'Memory usage')
  request_duration = Histogram('request_duration_seconds', 'Request duration')

  # ç±»å‹ç‰¹å®šçš„æ–¹æ³•
  requests_total.inc()              # Counter API
  memory_usage.set(1000)            # Gauge API
  request_duration.observe(0.5)     # Histogram API

  å®é™…å½±å“

  âœ… å®¢æˆ·ç«¯å±‚é¢çš„ä¼˜åŠ¿

  - ç±»å‹å®‰å…¨: é˜²æ­¢è¯¯ç”¨ï¼ˆå¦‚å¯¹ Counter è¿›è¡Œé€’å‡æ“ä½œï¼‰
  - è¯­ä¹‰æ¸…æ™°: API ä½“ç°æŒ‡æ ‡è¯­ä¹‰
  - ä½¿ç”¨ä¾¿åˆ©: æä¾›é’ˆå¯¹æ€§çš„æ–¹æ³•

  âš ï¸ æœåŠ¡å™¨å±‚é¢çš„é™åˆ¶

  - ç»Ÿä¸€å­˜å‚¨: æœåŠ¡å™¨ä¸åŒºåˆ†ç±»å‹ï¼Œéƒ½ä½œä¸ºæ—¶é—´åºåˆ—å­˜å‚¨
  - æŸ¥è¯¢æ—¶ä¾èµ–çº¦å®š: ç”¨æˆ·éœ€è¦çŸ¥é“æŒ‡æ ‡çš„è¯­ä¹‰æ¥æ­£ç¡®æŸ¥è¯¢
  - ç±»å‹æ£€æŸ¥ç¼ºå¤±: æœåŠ¡å™¨ç«¯ä¸ä¼šéªŒè¯æŒ‡æ ‡ä½¿ç”¨æ˜¯å¦ç¬¦åˆç±»å‹çº¦å®š

  è®¾è®¡å“²å­¦

  è¿™ç§è®¾è®¡ä½“ç°äº† Prometheus çš„å“²å­¦ï¼š
  1. ç®€åŒ–: æœåŠ¡å™¨ä¸“æ³¨äºå­˜å‚¨å’ŒæŸ¥è¯¢
  2. çµæ´»æ€§: å®¢æˆ·ç«¯å¯ä»¥è‡ªç”±é€‰æ‹©æœ€é€‚åˆçš„æŒ‡æ ‡ç±»å‹
  3. å¯æ‰©å±•æ€§: æ–°çš„æŒ‡æ ‡ç±»å‹å¯ä»¥åœ¨å®¢æˆ·ç«¯å®ç°ï¼Œæ— éœ€ä¿®æ”¹æœåŠ¡å™¨

  ç¤ºä¾‹å¯¹æ¯”

  // å®¢æˆ·ç«¯ï¼šæœ‰ç±»å‹åŒºåˆ†
  counter.Add(1)    // åªèƒ½å¢åŠ 
  gauge.Set(100)    // å¯è®¾ç½®ä»»æ„å€¼
  histogram.Observe(0.5) // è§‚å¯Ÿå€¼å¹¶åˆ†å¸ƒ

  // æœåŠ¡å™¨ï¼šç»Ÿä¸€å¤„ç†
  // æ‰€æœ‰æ•°æ®éƒ½æ˜¯: labelSet -> timestamp -> value çš„æ˜ å°„
  // ç±»å‹ä¿¡æ¯ä»…åœ¨å®¢æˆ·ç«¯ç»´æŠ¤

  è¿™ç§åˆ†ç¦»è®¾è®¡è®© Prometheus æ—¢ä¿æŒäº†æœåŠ¡å™¨çš„ç®€æ´æ€§ï¼Œåˆä¸ºå®¢æˆ·ç«¯æä¾›äº†ä¸°å¯Œçš„ç±»å‹åŒ–APIã€‚
```

## Counter

1. A counter is a **cumulative metric** that represents a **single monotonically increasing** counter
   - whose value can **only increase** or be **reset to zero** on **restart**.
2. For example, you can use a counter to represent the number of **requests served**, **tasks completed**, or **errors**.
3. Do not use a counter to expose a value that can **decrease**.
   - For example, do not use a counter for the number of currently running processes; instead use a **gauge**.
4. Client library usage documentation for counters: <u>Go Java Python Ruby .Net Rust</u>

## Gauge

1. A gauge is a metric that represents a **single numerical value** that can arbitrarily go **up** and **down**.
2. Gauges are typically used for measured values like **temperatures** or **current memory usage**
   - but also "counts" that can go up and down, like the number of concurrent requests.
3. Client library usage documentation for gauges: <u>Go Java Python Ruby .Net Rust</u>

## Histogram

1. A histogram samples **observations** (usually things like **request durations** or **response sizes**) and **counts** them in **configurable buckets**.
2. It also provides a **sum** of **all observed values**.
3. A histogram with a **base metric name** of `<basename>` exposes **multiple time series** during **a scrape**:
   - **cumulative counters** for the **observation buckets**, exposed as `<basename>_bucket{le="<upper inclusive bound>"}`
   - the total **sum** of **all observed values**, exposed as `<basename>_sum`
   - the **count** of **events** that have been observed, exposed as `<basename>_count` (identical to `<basename>_bucket{le="+Inf"`} above)
4. Use the **histogram_quantile()** function to **calculate quantiles** from **histograms** or even **aggregations** of **histograms**.
   - A histogram is also **suitable** to calculate an **Apdex score**
   - When operating on buckets, remember that the **histogram** is **cumulative**

> Apdex score

```
  Apdex åŸºç¡€æ¦‚å¿µ

  Apdex æ˜¯ä¸€ä¸ªè¡¡é‡åº”ç”¨æ€§èƒ½çš„æ ‡å‡†åŒ–æŒ‡æ ‡ï¼ŒèŒƒå›´ä» 0 åˆ° 1ï¼Œå…¶ä¸­ï¼š
  - 1.0 = æ‰€æœ‰ç”¨æˆ·éƒ½æ»¡æ„
  - 0.0 = æ‰€æœ‰ç”¨æˆ·éƒ½ä¸æ»¡æ„

  ä¸‰ä¸ªæ€§èƒ½åŒºåŸŸ

  æ»¡æ„åŒºåŸŸ (Satisfied)    [0, T]           ç”¨æˆ·æ»¡æ„çš„å“åº”æ—¶é—´
  å®¹å¿åŒºåŸŸ (Tolerated)    (T, 4T]         ç”¨æˆ·å¯å®¹å¿çš„å“åº”æ—¶é—´
  ä¸æ»¡æ„åŒºåŸŸ (Frustrated)  (4T, âˆ)         ç”¨æˆ·ä¸æ»¡æ„çš„å“åº”æ—¶é—´

  T = ç›®æ ‡å“åº”æ—¶é—´é˜ˆå€¼ï¼ˆå¦‚ 0.5 ç§’ï¼‰

  è¯¦ç»†è®¡ç®—å…¬å¼

  åŸºæœ¬å…¬å¼

  Apdex = (Satisfied + Tolerated/2) / Total

  å…¶ä¸­ï¼š
  - Satisfied: æ»¡æ„è¯·æ±‚æ•°é‡
  - Tolerated: å®¹å¿è¯·æ±‚æ•°é‡
  - Total: æ€»è¯·æ±‚æ•°é‡

  ä½¿ç”¨ Prometheus Histogram è®¡ç®—

  å‡è®¾æˆ‘ä»¬è®¾ç½®ï¼š
  - T = 0.5 ç§’ï¼ˆæ»¡æ„é˜ˆå€¼ï¼‰
  - 4T = 2.0 ç§’ï¼ˆä¸æ»¡æ„é˜ˆå€¼ï¼‰

  # æ­¥éª¤ 1: è®¡ç®—å„åŒºåŸŸçš„è¯·æ±‚ç‡
  # æ»¡æ„è¯·æ±‚ (â‰¤ 0.5s)
  satisfied_rate = sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m]))

  # æ€»è¯·æ±‚ (æ‰€æœ‰æ¡¶ï¼ŒåŒ…æ‹¬ +Inf)
  total_rate = sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m]))

  # å®¹å¿è¯·æ±‚ (> 0.5s ä¸” â‰¤ 2.0s)
  tolerated_rate = sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) - satisfied_rate

  # æ­¥éª¤ 2: è®¡ç®— Apdex åˆ†æ•°
  apdex_score = (satisfied_rate + tolerated_rate/2) / total_rate

  å®Œæ•´çš„ Apdex æŸ¥è¯¢

  # æ–¹æ³• 1: ç›´æ¥è®¡ç®—
  (
    sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) +
    (sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) -
     sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m]))) / 2
  ) /
  sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m]))

  # æ–¹æ³• 2: ä½¿ç”¨å­æŸ¥è¯¢æ›´æ¸…æ™°
  (
    sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m]))
    + (sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) -
       sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) * 0.5
  )
  /
  sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m]))

  # æ–¹æ³• 3: å¤šç»´åº¦ Apdexï¼ˆæŒ‰æœåŠ¡åˆ†ç»„ï¼‰
  (
    sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) by (service) +
    (sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) by (service) -
     sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) by (service)) * 0.5
  ) /
  sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m])) by (service)

  å®é™…æ•°å€¼ç¤ºä¾‹

  å‡è®¾æŸæœåŠ¡ 5 åˆ†é’Ÿå†…çš„è¯·æ±‚åˆ†å¸ƒï¼š
  - â‰¤0.5s: 800 ä¸ªè¯·æ±‚
  - â‰¤2.0s: 150 ä¸ªè¯·æ±‚ï¼ˆæ–°å¢ï¼‰
  2.0s: 50 ä¸ªè¯·æ±‚

  è®¡ç®—è¿‡ç¨‹ï¼š

  # æŸ¥è¯¢ç»“æœç¤ºä¾‹
  # æ»¡æ„è¯·æ±‚ç‡
  sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m]))
  # ç»“æœ: 800/300 = 2.67 requests/second

  # å®¹å¿è¯·æ±‚ç‡
  sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) - sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m]))
  # ç»“æœ: 150/300 = 0.5 requests/second

  # æ€»è¯·æ±‚ç‡
  sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m]))
  # ç»“æœ: 1000/300 = 3.33 requests/second

  # Apdex åˆ†æ•°
  apdex_score = (800 + 150/2) / 1000 = (800 + 75) / 1000 = 0.875

  Apdex ç­‰çº§æ ‡å‡†

  | Apdex åˆ†æ•°  | æ€§èƒ½ç­‰çº§ | æè¿°     |
  |-----------|------|--------|
  | 0.94-1.00 | ä¼˜ç§€   | ç”¨æˆ·éå¸¸æ»¡æ„ |
  | 0.85-0.93 | è‰¯å¥½   | ç”¨æˆ·æ»¡æ„   |
  | 0.70-0.84 | ä¸€èˆ¬   | åŸºæœ¬å¯æ¥å—  |
  | 0.50-0.69 | è¾ƒå·®   | ç”¨æˆ·å¼€å§‹ä¸æ»¡ |
  | 0.00-0.49 | å¾ˆå·®   | ç”¨æˆ·ä½“éªŒå·®  |

  ä¸åŒåº”ç”¨åœºæ™¯çš„é˜ˆå€¼å»ºè®®

  # Web åº”ç”¨ - T = 0.5s
  web_apdex = (
    sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) +
    (sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) -
     sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) * 0.5
  ) / sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m]))

  # API æœåŠ¡ - T = 0.2s
  api_apdex = (
    sum(rate(http_request_duration_seconds_bucket{le="0.2"}[5m])) +
    (sum(rate(http_request_duration_seconds_bucket{le="0.8"}[5m])) -
     sum(rate(http_request_duration_seconds_bucket{le="0.2"}[5m])) * 0.5
  ) / sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m]))

  # æ•°æ®åº“æŸ¥è¯¢ - T = 0.1s
  db_apdex = (
    sum(rate(db_query_duration_seconds_bucket{le="0.1"}[5m])) +
    (sum(rate(db_query_duration_seconds_bucket{le="0.4"}[5m])) -
     sum(rate(db_query_duration_seconds_bucket{le="0.1"}[5m])) * 0.5
  ) / sum(rate(db_query_duration_seconds_bucket{le="+Inf"}[5m]))

  ä»ªè¡¨ç›˜å±•ç¤º

  # å•ä¸ªæœåŠ¡ Apdex è¶‹åŠ¿
  label_replace(
    (
      sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) +
      (sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) -
       sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) * 0.5
    ) / sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m])),
    "service", "web-api", "job", ".*"
  )

  # å¤šæœåŠ¡ Apdex å¯¹æ¯”
  (
    sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) by (service) +
    (sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) by (service) -
     sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) by (service)) * 0.5
  ) / sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m])) by (service)

  SLO åŸºäºApdex

  # SLO: 95% çš„æ—¶é—´å†… Apdex â‰¥ 0.85
  avg_over_time(
    (
      sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) +
      (sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) -
       sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) * 0.5
    ) / sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m]))
    [30d:1d]
  ) >= 0.85

  é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒApdex å°†å¤æ‚çš„æ€§èƒ½æ•°æ®ç®€åŒ–ä¸ºå•ä¸€ã€ç›´è§‚çš„åˆ†æ•°ï¼Œä¾¿äºä¸šåŠ¡å›¢é˜Ÿç†è§£å’Œå†³ç­–ã€‚
```

```
  1. histogram_quantile() å‡½æ•°ä½¿ç”¨

  åŸºæœ¬ç”¨æ³•

  # è®¡ç®— 95% è¯·æ±‚çš„åˆ†ä½æ•°
  histogram_quantile(0.95, http_request_duration_seconds_bucket)

  # è®¡ç®— 50% (ä¸­ä½æ•°)
  histogram_quantile(0.50, http_request_duration_seconds_bucket)

  # è®¡ç®— 99%
  histogram_quantile(0.99, http_request_duration_seconds_bucket)

  èšåˆåˆ†ä½æ•°è®¡ç®—

  # è·¨å¤šä¸ªå®ä¾‹èšåˆåè®¡ç®—åˆ†ä½æ•°
  histogram_quantile(0.95,
      sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
  )

  # å¤šæœåŠ¡ç»Ÿä¸€çš„åˆ†ä½æ•°è®¡ç®—
  histogram_quantile(0.99,
      sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
  )

  2. Apdex åˆ†æ•°è®¡ç®—

  Apdex (Application Performance Index) æ˜¯åº”ç”¨æ€§èƒ½æŒ‡æ ‡ï¼ŒåŸºäºç”¨æˆ·æ»¡æ„åº¦ã€‚

  Apdex è®¡ç®—ç¤ºä¾‹

  # è®¾å®šé˜ˆå€¼ï¼šT=0.5s (æ»¡æ„), 4T=2.0s (ä¸æ»¡æ„è¾¹ç•Œ)

  # è®¡ç®— Apdex åˆ†æ•°
  (
    # æ»¡æ„è¯·æ±‚ (â‰¤0.5s)
    sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) +
    # å®¹å¿è¯·æ±‚ (>0.5s ä½† â‰¤2.0s) çš„ä¸€åŠæƒé‡
    (sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) -
     sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) * 0.5
  ) /
  # æ€»è¯·æ±‚æ•°
  sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m]))

  Apdex åˆ†æ•°å«ä¹‰

  - 1.0 = æ‰€æœ‰ç”¨æˆ·éƒ½æ»¡æ„
  - 0.875 = 87.5% çš„ç”¨æˆ·æ»¡æ„ï¼Œå…¶ä½™éƒ¨åˆ†æ»¡æ„
  - 0.0 = æ‰€æœ‰ç”¨æˆ·éƒ½ä¸æ»¡æ„

  3. ç´¯ç§¯æ€§ (Cumulative) ç‰¹æ€§

  è¿™æ˜¯ Histogram æœ€é‡è¦çš„ç‰¹æ€§ï¼

  ç´¯ç§¯æ€§è§£é‡Š

  ç¤ºä¾‹ï¼šå“åº”æ—¶é—´åˆ†å¸ƒ
  le="0.1"  : 10 ä¸ªè¯·æ±‚   (â‰¤ 0.1s çš„è¯·æ±‚)
  le="0.5"  : 30 ä¸ªè¯·æ±‚   (â‰¤ 0.5s çš„è¯·æ±‚ï¼ŒåŒ…å«å‰é¢çš„10ä¸ª)
  le="1.0"  : 80 ä¸ªè¯·æ±‚   (â‰¤ 1.0s çš„è¯·æ±‚ï¼ŒåŒ…å«å‰é¢çš„30ä¸ª)
  le="2.0"  : 95 ä¸ªè¯·æ±‚   (â‰¤ 2.0s çš„è¯·æ±‚ï¼ŒåŒ…å«å‰é¢çš„80ä¸ª)
  le="+Inf" : 100 ä¸ªè¯·æ±‚ (æ‰€æœ‰è¯·æ±‚)

  å®é™…æ•°æ®ç»“æ„

  http_request_duration_seconds_bucket{le="0.1"} 10
  http_request_duration_seconds_bucket{le="0.5"} 30  # ç´¯ç§¯å€¼ï¼Œä¸æ˜¯å¢é‡
  http_request_duration_seconds_bucket{le="1.0"} 80
  http_request_duration_seconds_bucket{le="2.0"} 95
  http_request_duration_seconds_bucket{le="+Inf"} 100

  4. ç´¯ç§¯æ€§çš„é‡è¦æ€§

  æ­£ç¡®çš„ç†è§£æ–¹å¼

  # è®¡ç®—åœ¨ 0.1s-0.5s èŒƒå›´å†…çš„è¯·æ±‚æ•°
  range_0_1_to_0_5 = sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) -
                     sum(rate(http_request_duration_seconds_bucket{le="0.1"}[5m]))
  # ç»“æœ: 30 - 10 = 20 ä¸ªè¯·æ±‚

  å¸¸è§é”™è¯¯ç†è§£

  # âŒ é”™è¯¯ï¼šè®¤ä¸º le="0.5" åªåŒ…å« 0.5s çš„è¯·æ±‚
  # âœ… æ­£ç¡®ï¼šle="0.5" åŒ…å«æ‰€æœ‰ â‰¤0.5s çš„è¯·æ±‚

  5. å®é™…åº”ç”¨ç¤ºä¾‹

  æ€§èƒ½ç›‘æ§ä»ªè¡¨ç›˜

  # 1. åˆ†ä½æ•°ç›‘æ§
  P50 = histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))
  P95 = histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
  P99 = histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))

  # 2. Apdex åˆ†æ•°ç›‘æ§
  Apdex = (
    sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) +
    (sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) -
     sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) * 0.5
  ) / sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m]))

  # 3. å¹³å‡å“åº”æ—¶é—´
  avg_duration = rate(http_request_duration_seconds_sum[5m]) /
                 rate(http_request_duration_seconds_count[5m])

  6. Histogram vs Summary çš„å¯¹æ¯”

  | ç‰¹æ€§    | Histogram                 | Summary  |
  |-------|---------------------------|----------|
  | åˆ†ä½æ•°è®¡ç®— | æœåŠ¡å™¨ç«¯ histogram_quantile() | å®¢æˆ·ç«¯é¢„è®¡ç®—   |
  | èšåˆèƒ½åŠ›  | âœ… å¯è·¨å®ä¾‹èšåˆ                  | âŒ æ— æ³•èšåˆ   |
  | çµæ´»æ€§   | æŸ¥è¯¢æ—¶è®¡ç®—ä»»æ„åˆ†ä½æ•°                | é¢„å®šä¹‰å›ºå®šåˆ†ä½æ•° |
  | å­˜å‚¨å¼€é”€  | å¤šä¸ªæ¡¶ + count + sum         | è¾ƒå°‘æ—¶é—´åºåˆ—   |
  | ä½¿ç”¨åœºæ™¯  | å¤§è§„æ¨¡åˆ†å¸ƒå¼ç³»ç»Ÿ                  | ç®€å•ä½“åº”ç”¨    |

  7. æœ€ä½³å®è·µ

  # 1. æ€»æ˜¯ä½¿ç”¨ rate() å¤„ç†ç›´æ–¹å›¾æ•°æ®
  histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

  # 2. èšåˆæ—¶ä¿ç•™æ¡¶æ ‡ç­¾
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service, instance)

  # 3. ç»“åˆ count å’Œ sum è®¡ç®—å…¶ä»–æŒ‡æ ‡
  request_rate = rate(http_request_duration_seconds_count[5m])
  avg_response = rate(http_request_duration_seconds_sum[5m]) / request_rate

  æ€»ç»“

  è¿™æ®µè¯çš„æ ¸å¿ƒè¦ç‚¹ï¼š

  1. histogram_quantile() æ˜¯è®¡ç®—åˆ†ä½æ•°çš„ä¸»è¦æ–¹æ³•
  2. Apdex å¯ä»¥åŸºäº Histogram è®¡ç®—ç”¨æˆ·æ»¡æ„åº¦
  3. ç´¯ç§¯æ€§ æ˜¯ Histogram çš„å…³é”®ç‰¹æ€§ï¼Œç†è§£è¿™ä¸€ç‚¹å¯¹äºæ­£ç¡®è®¡ç®—è‡³å…³é‡è¦
  4. èšåˆä¼˜åŠ¿ ä½¿å¾— Histogram é€‚åˆåˆ†å¸ƒå¼ç³»ç»Ÿçš„æ€§èƒ½ç›‘æ§

  ç†è§£è¿™äº›æ¦‚å¿µå¯¹äºæœ‰æ•ˆä½¿ç”¨ Prometheus è¿›è¡Œæ€§èƒ½ç›‘æ§å’Œ SLO è·Ÿè¸ªè‡³å…³é‡è¦ã€‚
```

> æ€»æ˜¯ä½¿ç”¨ **rate()** å¤„ç†ç›´æ–¹å›¾æ•°æ®

```
  æ ¸å¿ƒåŸå› 

  1. Counter ç±»å‹çš„æœ¬è´¨

  Histogram çš„æ¡¶æ•°æ®æœ¬è´¨ä¸Šæ˜¯ Counter ç±»å‹ï¼Œå®ƒä»¬åªä¼šé€’å¢ï¼Œä¸ä¼šå‡å°‘ã€‚

  æ—¶é—´æˆ³1: http_request_duration_seconds_bucket{le="1.0"}  100
  æ—¶é—´æˆ³2: http_request_duration_seconds_bucket{le="1.0"}  150  (å¢åŠ äº†50)
  æ—¶é—´æˆ³3: http_request_duration_seconds_bucket{le="1.0"}  200  (å¢åŠ äº†50)

  2. é¿å…ç´¯ç§¯å€¼è¯¯ç”¨

  å¦‚æœç›´æ¥ä½¿ç”¨ç´¯ç§¯å€¼ï¼Œä¼šäº§ç”Ÿè¯¯å¯¼æ€§çš„ç»“æœï¼š

  # âŒ é”™è¯¯ï¼šç›´æ¥ä½¿ç”¨ç´¯ç§¯å€¼
  sum(http_request_duration_seconds_bucket{le="1.0"})
  # ç»“æœï¼š200 (è¿™æ˜¯ä»å¼€å§‹åˆ°ç°åœ¨çš„æ€»ç´¯ç§¯å€¼)

  # âœ… æ­£ç¡®ï¼šä½¿ç”¨ rate() è®¡ç®—å˜åŒ–ç‡
  sum(rate(http_request_duration_seconds_bucket{le="1.0"}[5m]))
  # ç»“æœï¼šçº¦0.167 requests/second (æ¯ç§’æ–°å¢çš„è¯·æ±‚æ•°)

  è¯¦ç»†åˆ†æ

  3. æ—¶é—´çª—å£çš„é‡è¦æ€§

  rate() å‡½æ•°è®¡ç®—çš„æ˜¯æŒ‡å®šæ—¶é—´çª—å£å†…çš„å¹³å‡å˜åŒ–ç‡ï¼š

  rate(metric[5m])  # è®¡ç®—è¿‡å»5åˆ†é’Ÿå†…çš„å¹³å‡æ¯ç§’å¢é•¿ç‡

  4. å®é™…æ•°å€¼å¯¹æ¯”

  å‡è®¾ä¸€ä¸ª Web æœåŠ¡çš„å“åº”æ—¶é—´åˆ†å¸ƒï¼š

  æ—¶é—´ç‚¹1 (10:00): http_request_duration_seconds_bucket{le="0.5"}  1000
  æ—¶é—´ç‚¹2 (10:01): http_request_duration_seconds_bucket{le="0.5"}  1200  (æ–°å¢200)
  æ—¶é—´ç‚¹3 (10:02): http_request_duration_seconds_bucket{le="0.5"}  1400  (æ–°å¢200)
  æ—¶é—´ç‚¹4 (10:03): http_request_duration_seconds_bucket{le="0.5"}  1600  (æ–°å¢200)

  ä¸ä½¿ç”¨ rate() çš„é—®é¢˜ï¼š

  # âŒ ç›´æ¥æŸ¥è¯¢ç´¯ç§¯å€¼
  sum(http_request_duration_seconds_bucket{le="0.5"})
  # ç»“æœï¼š1600 (è¿™ä¸ªæ•°å­—æœ¬èº«æ²¡æœ‰å®é™…æ„ä¹‰)

  # è®¡ç®—åˆ†ä½æ•°ä¼šå¾—åˆ°é”™è¯¯ç»“æœ
  histogram_quantile(0.95, http_request_duration_seconds_bucket)
  # åŸºäºç´¯ç§¯å€¼è®¡ç®—ï¼Œæ— æ³•åæ˜ å½“å‰æ€§èƒ½çŠ¶å†µ

  ä½¿ç”¨ rate() çš„æ­£ç¡®æ–¹å¼ï¼š

  # âœ… è®¡ç®—è¿‡å»5åˆ†é’Ÿå†…çš„è¯·æ±‚ç‡
  sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m]))
  # ç»“æœï¼šçº¦3.33 requests/second (200/60ç§’)

  # æ­£ç¡®è®¡ç®—åˆ†ä½æ•°
  histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
  # åŸºäºå˜åŒ–ç‡è®¡ç®—ï¼Œåæ˜ å½“å‰çœŸå®çš„æ€§èƒ½åˆ†å¸ƒ

  å…·ä½“ç¤ºä¾‹

  5. åˆ†ä½æ•°è®¡ç®—çš„å·®å¼‚

  # æ•°æ®ï¼šå“åº”æ—¶é—´æ¡¶çš„ç´¯ç§¯å€¼
  le="0.1": 1000
  le="0.5": 1500
  le="1.0": 1800
  le="2.0": 1950
  le="+Inf": 2000

  # âŒ ä¸ä½¿ç”¨ rate() - é”™è¯¯çš„åˆ†ä½æ•°è®¡ç®—
  histogram_quantile(0.95, http_request_duration_seconds_bucket)
  # ç»“æœï¼šåŸºäºç´¯ç§¯å€¼è®¡ç®—ï¼Œå¯èƒ½å¾—åˆ° 1.8s çš„é”™è¯¯åˆ†ä½æ•°

  # âœ… ä½¿ç”¨ rate() - æ­£ç¡®çš„åˆ†ä½æ•°è®¡ç®—
  histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
  # ç»“æœï¼šåŸºäºå®é™…è¯·æ±‚åˆ†å¸ƒè®¡ç®—ï¼Œå¾—åˆ°çœŸå®çš„ 95% åˆ†ä½æ•°

  6. ä»ªè¡¨ç›˜å¯¹æ¯”

  # é”™è¯¯çš„ä»ªè¡¨ç›˜é…ç½®ï¼ˆæ˜¾ç¤ºç´¯ç§¯å€¼ï¼‰
  - title: "æ»¡æ„è¯·æ±‚æ•°"
    expr: sum(http_request_duration_seconds_bucket{le="0.5"})
    # æ˜¾ç¤ºï¼šä»å¼€å§‹ç´¯ç§¯çš„æ€»æ•°ï¼Œæ•°å€¼åªä¼šå¢é•¿

  # æ­£ç¡®çš„ä»ªè¡¨ç›˜é…ç½®ï¼ˆæ˜¾ç¤ºå®æ—¶æ€§èƒ½ï¼‰
  - title: "æ»¡æ„è¯·æ±‚ç‡"
    expr: sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m]))
    # æ˜¾ç¤ºï¼šæ¯ç§’æ»¡æ„çš„è¯·æ±‚æ•°ï¼Œåæ˜ å½“å‰æ€§èƒ½çŠ¶å†µ

  - title: "95% å“åº”æ—¶é—´"
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
    # æ˜¾ç¤ºï¼šå½“å‰95%è¯·æ±‚çš„å“åº”æ—¶é—´

  ç‰¹æ®Šæƒ…å†µ

  7. ä»€ä¹ˆæ—¶å€™ä¸ä½¿ç”¨ rate()ï¼Ÿ

  # 1. æŸ¥è¯¢å½“å‰ç´¯ç§¯æ€»æ•°ï¼ˆå¦‚æ€»è¯·æ±‚æ•°ï¼‰
  sum(http_request_duration_seconds_count)

  # 2. è®¡ç®—å¹³å‡å€¼æ—¶ï¼Œrate() å¯ä»¥æŠµæ¶ˆ
  # avg = sum / count
  rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])
  # ä¸¤ä¸ª rate() å¯ä»¥æŠµæ¶ˆï¼Œç®€åŒ–ä¸ºï¼š
  http_request_duration_seconds_sum / http_request_duration_seconds_count

  # 3. å®æ—¶çŠ¶æ€ç›‘æ§ï¼ˆéè¶‹åŠ¿åˆ†æï¼‰
  # ä½†è¿™ç§æƒ…å†µè¾ƒå°‘ï¼Œé€šå¸¸è¿˜æ˜¯ç”¨ rate() æ›´æœ‰æ„ä¹‰

  8. increase() æ›¿ä»£æ–¹æ¡ˆ

  # ä¹Ÿå¯ä»¥ä½¿ç”¨ increase() è®¡ç®—æ—¶é—´çª—å£å†…çš„æ€»å¢é‡
  increase(http_request_duration_seconds_bucket{le="0.5"}[5m])
  # ç»“æœï¼šè¿‡å»5åˆ†é’Ÿå†…çš„æ€»å¢é‡

  # ç­‰ä»·äºï¼š
  rate(http_request_duration_seconds_bucket{le="0.5"}[5m]) * 300 (5åˆ†é’Ÿ*60ç§’)

  æœ€ä½³å®è·µæ€»ç»“

  # âœ… æ¨èçš„æŸ¥è¯¢æ¨¡å¼

  # 1. åˆ†ä½æ•°ç›‘æ§
  histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

  # 2. Apdex åˆ†æ•°
  (
    sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) +
    (sum(rate(http_request_duration_seconds_bucket{le="2.0"}[5m])) -
     sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m])) * 0.5
  ) / sum(rate(http_request_duration_seconds_bucket{le="+Inf"}[5m]))

  # 3. è¯·æ±‚é€Ÿç‡ç›‘æ§
  sum(rate(http_request_duration_seconds_count[5m]))

  # 4. å¹³å‡å“åº”æ—¶é—´
  rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])

  æ€»ç»“

  ä½¿ç”¨ rate() çš„æ ¸å¿ƒåŸå› ï¼š

  1. é¿å…ç´¯ç§¯å€¼è¯¯å¯¼ - Counter ç±»å‹çš„æ•°æ®æ˜¯ç´¯ç§¯çš„ï¼Œç›´æ¥ä½¿ç”¨æ²¡æœ‰æ„ä¹‰
  2. åæ˜ å®æ—¶æ€§èƒ½ - rate() æ˜¾ç¤ºå½“å‰çš„æ€§èƒ½è¶‹åŠ¿ï¼Œè€Œä¸æ˜¯å†å²ç´¯ç§¯
  3. æ­£ç¡®çš„åˆ†ä½æ•°è®¡ç®— - histogram_quantile() éœ€è¦åŸºäºå®é™…è¯·æ±‚åˆ†å¸ƒï¼Œä¸æ˜¯ç´¯ç§¯å€¼
  4. æœ‰æ„ä¹‰çš„ç›‘æ§ - åªæœ‰å˜åŒ–ç‡æ‰èƒ½åæ˜ ç³»ç»Ÿçš„å®æ—¶è¿è¡ŒçŠ¶å†µ

  è¿™æ˜¯ Prometheus ç›‘æ§æœ€ä½³å®è·µçš„æ ¸å¿ƒåŸåˆ™ä¹‹ä¸€ï¼
```

> NOTE

1. Beginning with **Prometheus v2.40**, there is **experimental support** for **native histograms**.
2. A **native histogram** requires **only one time series**, which includes a **dynamic number of buckets** in addition to the **sum** and **count** of observations.
3. Native histograms allow **much higher resolution** at a **fraction** of the **cost**.
4. **Detailed documentation** will follow once native histograms are **closer** to becoming a **stable feature**.

```
  Native Histograms çš„ç¨³å®šçŠ¶æ€

  ğŸ¯ æ­£å¼ç¨³å®šç‰ˆæœ¬

  - Prometheus v3.8.0 åŠä»¥ä¸Šç‰ˆæœ¬ä¸­ï¼ŒNative Histograms å·²æˆä¸º stable feature
  - ä¸å†éœ€è¦å¯ç”¨ --enable-feature=native-histograms æ ‡å¿—

  ğŸ“… å‘å±•æ—¶é—´çº¿

  - v2.40.0 (2022å¹´): é¦–æ¬¡å¼•å…¥å®éªŒæ€§æ”¯æŒï¼Œéœ€è¦å¯ç”¨ç‰¹æ€§æ ‡å¿—
  - v3.0.0 (2024å¹´): æ”¹è¿›å®éªŒæ€§æ”¯æŒï¼Œä½†ä»éœ€æ ‡å¿—
  - v3.8.0 (2025å¹´): æ­£å¼æˆä¸ºç¨³å®šåŠŸèƒ½

  ğŸ” å…³é”®ä¿¡æ¯æ¥æº

  æ ¹æ® Prometheus å®˜æ–¹æ–‡æ¡£ï¼š
  "Starting with v3.8.0, native histograms are supported as a stable feature."

  Grafana Labs åšå®¢ä¹Ÿç¡®è®¤ï¼š
  "Last week, during PromCon EU 2025, the Prometheus developers announced that native histograms are now stable, after three years of intense testing and improvements."

  ç”Ÿæ€ç³»ç»Ÿçš„æ”¯æŒæƒ…å†µ

  âœ… å·²æ”¯æŒ Native Histograms çš„ç»„ä»¶

  1. Prometheus Server - v3.8.0+ ç¨³å®šæ”¯æŒ
  2. Grafana Mimir - å·²æ”¯æŒï¼ˆä½œä¸º Prometheus ä¸‹æ¸¸é¡¹ç›®ï¼‰
  3. Grafana Cloud - å·²é›†æˆï¼Œæä¾›ä¸“é—¨çš„å¯è§†åŒ–æ”¯æŒ
  4. OpenTelemetry - å…¼å®¹æ€§æ”¯æŒ
  5. å®¢æˆ·ç«¯åº“ - Goã€Java ç­‰å®˜æ–¹å®¢æˆ·ç«¯å·²æ”¯æŒ

  ğŸ”„ å‘åå…¼å®¹æ€§

  - ç°æœ‰çš„ç»å…¸ç›´æ–¹å›¾ç»§ç»­å·¥ä½œ
  - ä¸¤ç§æ ¼å¼å¯ä»¥å¹¶å­˜
  - æ¸è¿›å¼è¿ç§»è·¯å¾„

  ä½¿ç”¨å»ºè®®

  ğŸš€ ç°åœ¨å¯ä»¥å®‰å…¨ä½¿ç”¨

  # åœ¨ Prometheus v3.8.0+ ä¸­ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨
  # æ— éœ€ç‰¹æ®Šé…ç½®æˆ–ç‰¹æ€§æ ‡å¿—

  # æŸ¥è¯¢ç¤ºä¾‹
  histogram_quantile(0.95, rate(http_request_duration_seconds[5m]))

  ğŸ“Š è¿ç§»è€ƒè™‘

  - æ–°é¡¹ç›®å¯ä»¥ç›´æ¥ä½¿ç”¨ Native Histograms
  - ç°æœ‰é¡¹ç›®å¯ä»¥é€æ­¥è¿ç§»
  - è€ƒè™‘å®¢æˆ·ç«¯åº“çš„å…¼å®¹æ€§

  ğŸ’¡ ä¼˜åŠ¿ç¡®è®¤

  ç»è¿‡3å¹´æµ‹è¯•ï¼ŒNative Histograms çš„ä¼˜åŠ¿å¾—åˆ°éªŒè¯ï¼š
  - å­˜å‚¨æ•ˆç‡: å•ä¸€æ—¶é—´åºåˆ—æ›¿ä»£å¤šä¸ªæ¡¶
  - ç²¾åº¦æå‡: åŠ¨æ€æ¡¶è¾¹ç•Œ
  - æ€§èƒ½ä¼˜åŒ–: å‡å°‘ç½‘ç»œä¼ è¾“å’Œå­˜å‚¨å¼€é”€
  - ç®€åŒ–é…ç½®: æ— éœ€é¢„å®šä¹‰æ¡¶è¾¹ç•Œ

  æ€»ç»“

  æ˜¯çš„ï¼ŒNative Histograms ç°åœ¨æ˜¯ Prometheus çš„ç¨³å®šåŠŸèƒ½ï¼Œå¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å®‰å…¨ä½¿ç”¨ã€‚è¿™æ˜¯ä¸€ä¸ªé‡å¤§çš„é‡Œç¨‹ç¢‘ï¼Œæ ‡å¿—ç€ Prometheus ç›‘æ§æŠ€æœ¯çš„é‡å¤§è¿›æ­¥ã€‚
```

> NOTE

Beginning with **Prometheus v3.0**, the **values** of the **le label** of **classic histograms** are **normalized** during **ingestion** to follow the **format** of **OpenMetrics Canonical Numbers**

```
  ä»€ä¹ˆæ˜¯ OpenMetrics Canonical Numbersï¼Ÿ

  Canonical Numbers æ ¼å¼

  OpenMetrics è§„èŒƒè¦æ±‚æ•°å€¼æ ‡ç­¾éµå¾ªç‰¹å®šçš„è§„èŒƒæ ¼å¼ï¼š
  - æ•´æ•°: ç›´æ¥ä½¿ç”¨ï¼Œå¦‚ le="1"
  - å°æ•°: ä½¿ç”¨æœ€ç²¾ç¡®çš„è¡¨ç¤ºï¼Œå¦‚ le="0.1" è€Œä¸æ˜¯ le="0.10"
  - ç§‘å­¦è®¡æ•°æ³•: å¯¹äºæå¤§æˆ–æå°çš„æ•°ï¼Œå¦‚ le="1e-6"

  Prometheus v3.0 çš„å˜æ›´

  ğŸ”„ è§„èŒƒåŒ–å¤„ç† (Normalization)

  å½“ Prometheus é‡‡é›†ç»å…¸ç›´æ–¹å›¾æ—¶ï¼Œä¼šå¯¹ le æ ‡ç­¾çš„å€¼è¿›è¡Œè§„èŒƒåŒ–ï¼š

  # é‡‡é›†å‰çš„åŸå§‹å€¼
  http_request_duration_seconds_bucket{le="0.100"} 100
  http_request_duration_seconds_bucket{le="0.500"} 200
  http_request_duration_seconds_bucket{le="1.000"} 350

  # è§„èŒƒåŒ–åçš„å­˜å‚¨å€¼
  http_request_duration_seconds_bucket{le="0.1"} 100
  http_request_duration_seconds_bucket{le="0.5"} 200
  http_request_duration_seconds_bucket{le="1"} 350

  ğŸ“ å…·ä½“è§„èŒƒåŒ–è§„åˆ™

  // è§„èŒƒåŒ–ç¤ºä¾‹
  "0.100"   â†’ "0.1"     // ç§»é™¤å°¾éšé›¶
  "1.0"     â†’ "1"       // æ•´æ•°å½¢å¼
  "0.010"   â†’ "0.01"    // ç§»é™¤ä¸å¿…è¦çš„é›¶
  "1000.0"  â†’ "1000"    // æ•´æ•°å½¢å¼
  "1e-3"    â†’ "0.001"   // è½¬æ¢ä¸ºå°æ•°å½¢å¼ï¼ˆåœ¨æŸäº›æƒ…å†µä¸‹ï¼‰

  ä¸ºä»€ä¹ˆè¦è¿›è¡Œè§„èŒƒåŒ–ï¼Ÿ

  1. æ ‡å‡†åŒ–å…¼å®¹æ€§

  # ä¸åŒå®¢æˆ·ç«¯å¯èƒ½å‘é€ç›¸åŒå€¼çš„ä¸åŒè¡¨ç¤º
  å®¢æˆ·ç«¯A: le="0.500"
  å®¢æˆ·ç«¯B: le="0.5"
  å®¢æˆ·ç«¯C: le="5e-1"

  # è§„èŒƒåŒ–åç»Ÿä¸€ä¸º
  le="0.5"

  2. æŸ¥è¯¢ä¸€è‡´æ€§

  # è§„èŒƒåŒ–å‰ï¼Œå¯èƒ½éœ€è¦æŸ¥è¯¢å¤šä¸ªå˜ä½“
  sum(rate(http_request_duration_seconds_bucket{le=~"0.5|0.500|0.50"}[5m]))

  # è§„èŒƒåŒ–åï¼ŒæŸ¥è¯¢æ›´ç®€å•
  sum(rate(http_request_duration_seconds_bucket{le="0.5"}[5m]))

  3. OpenMetrics åˆè§„æ€§

  # ç¬¦åˆ OpenMetrics 1.0 è§„èŒƒ
  # ç¡®ä¿ä¸å…¶ä»–ç›‘æ§ç³»ç»Ÿçš„äº’æ“ä½œæ€§

  å®é™…å½±å“ç¤ºä¾‹

  ğŸ“Š ç›‘æ§é…ç½®å½±å“

  ä¹‹å‰ (v2.x):
  # å¯èƒ½éœ€è¦å¤„ç†å¤šç§æ ¼å¼
  - record: http_request_duration_95th
    expr: histogram_quantile(0.95,
      rate(http_request_duration_seconds_bucket{le=~"0\\.5|0\\.500"}[5m]))

  ç°åœ¨ (v3.0+):
  # æ ¼å¼æ ‡å‡†åŒ–ï¼ŒæŸ¥è¯¢æ›´ç®€å•
  - record: http_request_duration_95th
    expr: histogram_quantile(0.95,
      rate(http_request_duration_seconds_bucket{le="0.5"}[5m]))

  ğŸ”§ å®¢æˆ·ç«¯åº“å½±å“

  // Go å®¢æˆ·ç«¯ç¤ºä¾‹
  hist := prometheus.NewHistogram(prometheus.HistogramOpts{
      Name:    "http_request_duration_seconds",
      Help:    "HTTP request latency",
      Buckets: []float64{0.1, 0.5, 1.0, 5.0},  // è¿™äº›å€¼åœ¨å­˜å‚¨æ—¶ä¼šè¢«è§„èŒƒåŒ–
  })

  âš ï¸ æ³¨æ„äº‹é¡¹

  1. æŸ¥è¯¢å…¼å®¹æ€§: ç°æœ‰çš„æŸ¥è¯¢å¯èƒ½éœ€è¦æ›´æ–°
  2. ä»ªè¡¨ç›˜: Grafana ä»ªè¡¨ç›˜ä¸­çš„æŸ¥è¯¢å¯èƒ½éœ€è¦è°ƒæ•´
  3. å‘Šè­¦è§„åˆ™: åŸºäº le æ ‡ç­¾çš„å‘Šè­¦è§„åˆ™å¯èƒ½éœ€è¦ä¿®æ”¹

  è¿ç§»æŒ‡å—

  ğŸ”„ æŸ¥è¯¢æ›´æ–°ç¤ºä¾‹

  # æ—§æŸ¥è¯¢ï¼ˆå¯èƒ½ä¸å…¼å®¹ï¼‰
  histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{le="0.500"}[5m]))

  # æ–°æŸ¥è¯¢ï¼ˆæ¨èï¼‰
  histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{le="0.5"}[5m]))

  ğŸ“ˆ å‘åå…¼å®¹æ€§

  Prometheus v3.0 åœ¨å¤„ç†æ—¶ä¼šè‡ªåŠ¨è§„èŒƒåŒ–ï¼Œä½†å»ºè®®ï¼š
  1. æ£€æŸ¥ç°æœ‰çš„æŸ¥è¯¢å’Œå‘Šè­¦è§„åˆ™
  2. æ›´æ–°ç¡¬ç¼–ç çš„ le å€¼
  3. æµ‹è¯•ä»ªè¡¨ç›˜çš„å…¼å®¹æ€§

  æ€»ç»“

  è¿™ä¸ªå˜æ›´çš„ä¸»è¦ç›®çš„æ˜¯ï¼š

  1. æ ‡å‡†åŒ–: ç»Ÿä¸€æ•°å€¼è¡¨ç¤ºæ ¼å¼
  2. å…¼å®¹æ€§: ä¸ OpenMetrics æ ‡å‡†å¯¹é½
  3. ç®€åŒ–: è®©æŸ¥è¯¢å’Œé…ç½®æ›´åŠ ä¸€è‡´
  4. äº’æ“ä½œæ€§: æå‡ä¸å…¶ä»–ç›‘æ§ç³»ç»Ÿçš„é›†æˆèƒ½åŠ›

  è¿™æ˜¯ Prometheus å‘ OpenMetrics æ ‡å‡†é æ‹¢çš„é‡è¦ä¸€æ­¥ï¼Œä¸ºæ•´ä¸ªç›‘æ§ç”Ÿæ€çš„æ ‡å‡†åŒ–åšå‡ºäº†è´¡çŒ®ã€‚
```

Client library usage documentation for histograms: <u>Go Java Python Ruby .Net Rust</u>

## Summary

1. Similar to a histogram, a summary **samples observations** (usually things like **request durations** and **response sizes**).
2. While it also provides a total **count** of **observations** and a **sum** of all **observed values**, it calculates **configurable quantiles** over a **sliding** time window.
3. A summary with a **base metric name** of `<basename>` exposes **multiple time series** during a **scrape**:
   - streaming **Ï†-quantiles** (0 â‰¤ Ï† â‰¤ 1) of observed events, exposed as `<basename>{quantile="<Ï†>"}`
   - the **total sum** of all observed values, exposed as `<basename>_sum`
   - the **count** of events that have been observed, exposed as `<basename>_count`

> NOTE

Beginning with **Prometheus v3.0**, the **values** of the **quantile label** are **normalized** during **ingestion** to follow the format of **OpenMetrics Canonical Numbers**

Client library usage documentation for summaries: <u>Go Java Python Ruby .Net</u>

# Jobs and instances

1. In Prometheus terms, an **endpoint** you can **scrape** is called an **instance**, usually corresponding to **a single process**.
2. A **collection** of **instances** with the **same purpose**, a process **replicated** for **scalability** or **reliability** for example, is called a **job**.
3. For example, an API server job with four replicated instances:
   - job: `api-server`
     - instance 1: `1.2.3.4:5670`
     - instance 2: `1.2.3.4:5671`
     - instance 3: `5.6.7.8:5670`
     - instance 4: `5.6.7.8:5671`

## Automatically generated labels and time series

1. When Prometheus **scrapes** a **target**, it **attaches some labels automatically** to the **scraped time series** which serve to **identify** the scraped **target**:
   - **job**: The **configured job name** that the target belongs to.
   - **instance**: The `<host>:<port>` part of the **target's URL** that was **scraped**.
2. If either of these labels are already present in the scraped data, the behavior depends on the **honor_labels** configuration option.

>   honor_labels é…ç½®è§£å†³äº† Prometheus é‡‡é›†è¿‡ç¨‹ä¸­çš„**æ ‡ç­¾å†²çª**é—®é¢˜ï¼š
>
>   - false (é»˜è®¤): **Prometheus æ ‡ç­¾ä¼˜å…ˆ**ï¼Œé€‚åˆæ ‡å‡†åŒ–ç¯å¢ƒ
>   - true: ç›®æ ‡æ ‡ç­¾ä¼˜å…ˆï¼Œé€‚åˆè‡ªå®šä¹‰æ ‡ç­¾ä½“ç³»

```
  æ­£ç¡®çš„è¡Œä¸ºæ¨¡å¼

  1. honor_labels: false (é»˜è®¤å€¼)

  è¡Œä¸º: Prometheus çš„æ ‡ç­¾ä¼˜å…ˆï¼Œç›®æ ‡æ•°æ®ä¸­çš„å†²çªæ ‡ç­¾ä¼šè¢«é‡å‘½åï¼Œè€Œä¸æ˜¯å¿½ç•¥

  # Prometheus é…ç½®
  scrape_configs:
    - job_name: 'myapp'  # è¿™ä¸ª job åç§°æ˜¯ Prometheus ä½¿ç”¨çš„
      static_configs:
        - targets: ['localhost:8080']
      honor_labels: false

  æ­£ç¡®çš„å¤„ç†è¿‡ç¨‹:

  # ç›®æ ‡æ•°æ®è¿”å›
  http_requests_total{job="myapp", instance="localhost:8080"} 1000

  # Prometheus å­˜å‚¨ç»“æœ
  # Prometheus çš„æ ‡ç­¾ä¼˜å…ˆï¼Œç›®æ ‡æ•°æ®çš„å†²çªæ ‡ç­¾è¢«é‡å‘½å
  http_requests_total{job="myapp", instance="localhost:8080", exported_job="myapp", exported_instance="localhost:8080"} 1000

  2. honor_labels: true

  è¡Œä¸º: ç›®æ ‡æ•°æ®çš„æ ‡ç­¾ä¼˜å…ˆï¼ŒPrometheus çš„å†²çªæ ‡ç­¾ä¼šè¢«ä¸¢å¼ƒ

  # ç›®æ ‡æ•°æ®è¿”å›
  http_requests_total{job="myapp", instance="localhost:8080"} 1000

  # Prometheus å­˜å‚¨ç»“æœ
  # ç›®æ ‡æ ‡ç­¾ä¼˜å…ˆï¼Œä¿æŒåŸæ ·
  http_requests_total{job="myapp", instance="localhost:8080"} 1000

  æ›´è¯¦ç»†çš„æ­£ç¡®ç¤ºä¾‹

  honor_labels: false çš„è¯¦ç»†è¡Œä¸º

  # Prometheus é…ç½®
  scrape_configs:
    - job_name: 'prometheus-job'
      static_configs:
        - targets: ['target.example.com:8080']
      honor_labels: false

  å¤„ç†è¿‡ç¨‹:
  # 1. Prometheus ä¼šè‡ªåŠ¨æ·»åŠ æ ‡ç­¾
  # job="prometheus-job" (æ¥è‡ªé…ç½®)
  # instance="target.example.com:8080" (æ¥è‡ªç›®æ ‡åœ°å€)

  # 2. ç›®æ ‡è¿”å›æ•°æ®
  http_requests_total{job="target-job", instance="target-instance"} 1000

  # 3. å­˜å‚¨ç»“æœï¼ˆå†²çªæ ‡ç­¾è¢«é‡å‘½åï¼‰
  http_requests_total{
    job="prometheus-job",           # Prometheus çš„æ ‡ç­¾
    instance="target.example.com:8080",  # Prometheus çš„æ ‡ç­¾
    exported_job="target-job",      # é‡å‘½ååçš„ç›®æ ‡æ ‡ç­¾
    exported_instance="target-instance"   # é‡å‘½ååçš„ç›®æ ‡æ ‡ç­¾
  } 1000

  honor_labels: true çš„è¯¦ç»†è¡Œä¸º

  # Prometheus é…ç½®
  scrape_configs:
    - job_name: 'prometheus-job'
      static_configs:
        - targets: ['target.example.com:8080']
      honor_labels: true

  å¤„ç†è¿‡ç¨‹:
  # 1. ç›®æ ‡è¿”å›æ•°æ®
  http_requests_total{job="target-job", instance="target-instance"} 1000

  # 2. å­˜å‚¨ç»“æœï¼ˆä¿æŒç›®æ ‡æ ‡ç­¾ï¼Œä¸¢å¼ƒ Prometheus çš„è‡ªåŠ¨æ ‡ç­¾ï¼‰
  http_requests_total{
    job="target-job",        # ç›®æ ‡çš„æ ‡ç­¾
    instance="target-instance"  # ç›®æ ‡çš„æ ‡ç­¾
  } 1000

  å®é™…éªŒè¯

  æŸ¥è¯¢éªŒè¯

  # å½“ honor_labels: false æ—¶ï¼Œå¯ä»¥çœ‹åˆ°é‡å‘½åçš„æ ‡ç­¾
  http_requests_total{exported_job="target-job"}

  # å½“ honor_labels: true æ—¶ï¼Œç›´æ¥æŸ¥è¯¢åŸå§‹æ ‡ç­¾
  http_requests_total{job="target-job"}

  æ€»ç»“ä¿®æ­£

  æ„Ÿè°¢æŒ‡å‡ºé”™è¯¯ï¼æ­£ç¡®çš„è¡Œä¸ºæ˜¯ï¼š

  - honor_labels: false: Prometheus æ ‡ç­¾ä¼˜å…ˆï¼Œå†²çªçš„ç›®æ ‡æ ‡ç­¾ä¼šè¢«é‡å‘½åï¼ˆæ·»åŠ  exported_ å‰ç¼€ï¼‰
  - honor_labels: true: ç›®æ ‡æ ‡ç­¾ä¼˜å…ˆï¼ŒPrometheus çš„å†²çªæ ‡ç­¾ä¼šè¢«ä¸¢å¼ƒ

  å…³é”®æ˜¯è¦ç†è§£ä¸¤ä¸ªæ ‡ç­¾ä½“ç³»ä¼šåŒæ—¶å­˜åœ¨ï¼Œè€Œä¸æ˜¯ç®€å•åœ°"å¿½ç•¥"æŸä¸€æ–¹çš„æ ‡ç­¾ã€‚
```

> For each **instance** scrape, Prometheus stores a **sample** in the following time series:

1. `up{job="<job-name>", instance="<instance-id>"}`
   - **1** if the instance is **healthy**, i.e. **reachable** or **0** if the **scrape failed**.
2. `scrape_duration_seconds{job="<job-name>", instance="<instance-id>"}`
   - **duration** of the scrape.
3. `scrape_samples_post_metric_relabeling{job="<job-name>", instance="<instance-id>"}`
   - the number of **samples remaining** after **metric relabeling** was applied.
4. `scrape_samples_scraped{job="<job-name>", instance="<instance-id>"}`
   - the number of **samples** the target **exposed**.
5. `scrape_series_added{job="<job-name>", instance="<instance-id>"}`
   - the **approximate** number of **new series** in this scrape. New in **v2.10**

> scrape_samples_post_metric_relabeling

```
  æŒ‡æ ‡å«ä¹‰

  ğŸ“Š scrape_samples_post_metric_relabeling æŒ‡æ ‡

  scrape_samples_post_metric_relabeling{job="myapp", instance="localhost:8080"} 1500

  å«ä¹‰: åœ¨å¯¹ "myapp" ä»»åŠ¡çš„ "localhost:8080" å®ä¾‹è¿›è¡ŒæŠ“å–åï¼Œç»è¿‡ metric relabeling å¤„ç†ï¼Œæœ€ç»ˆä¿ç•™äº† 1500 ä¸ªæ ·æœ¬ã€‚

  Metric Relabeling æµç¨‹

  ğŸ”„ å®Œæ•´çš„æŠ“å–æµç¨‹

  1. [ç›®æ ‡ç«¯ç‚¹] â†’ åŸå§‹æŒ‡æ ‡æ•°æ®
     â†“
  2. [æŠ“å–] â†’ è·å–æ‰€æœ‰åŸå§‹æ ·æœ¬
     â†“
  3. [Metric Relabeling] â†’ è¿‡æ»¤ã€ä¿®æ”¹ã€æ·»åŠ æ ‡ç­¾
     â†“
  4. [å­˜å‚¨] â†’ æœ€ç»ˆå­˜å‚¨çš„æ ·æœ¬

  scrape_samples_post_metric_relabeling æµ‹é‡çš„æ˜¯ç¬¬3æ­¥ä¹‹åå‰©ä½™çš„æ ·æœ¬æ•°

  é…ç½®ç¤ºä¾‹

  ğŸ“ Metric Relabeling é…ç½®

  scrape_configs:
    - job_name: 'myapp'
      static_configs:
        - targets: ['localhost:8080']
      metric_relabel_configs:
        # 1. è¿‡æ»¤æ‰ä¸éœ€è¦çš„æŒ‡æ ‡
        - source_labels: [__name__]
          regex: 'go_.*'
          action: drop

        # 2. åªä¿ç•™ç‰¹å®šçš„æŒ‡æ ‡
        - source_labels: [__name__]
          regex: 'http_.*|process_.*'
          action: keep

        # 3. ä¿®æ”¹æ ‡ç­¾
        - source_labels: [service]
          target_label: application
          regex: '(.*)'
          replacement: 'myapp-${1}'

        # 4. æ·»åŠ æ–°æ ‡ç­¾
        - target_label: environment
          replacement: 'production'

        # 5. åˆ é™¤æ ‡ç­¾
        - regex: 'temp_.*'
          action: labeldrop

  å®é™…åº”ç”¨ç¤ºä¾‹

  ğŸ¯ åœºæ™¯1: è¿‡æ»¤é«˜åŸºæ•°æŒ‡æ ‡

  # é…ç½®ï¼šè¿‡æ»¤æ‰ go_* æŒ‡æ ‡ä»¥å‡å°‘å­˜å‚¨
  metric_relabel_configs:
    - source_labels: [__name__]
      regex: 'go_.*'
      action: drop

  # ç»“æœï¼š
  # åŸå§‹æŠ“å–: 5000 ä¸ªæ ·æœ¬
  # è¿‡æ»¤å: 3000 ä¸ªæ ·æœ¬
  # æŒ‡æ ‡æ˜¾ç¤º: scrape_samples_post_metric_relabeling{job="myapp"} 3000

  ğŸ¯ åœºæ™¯2: ç¯å¢ƒæ ‡ç­¾æ ‡å‡†åŒ–

  # é…ç½®ï¼šä¸ºæ‰€æœ‰æŒ‡æ ‡æ·»åŠ ç¯å¢ƒæ ‡ç­¾
  metric_relabel_configs:
    - target_label: env
      replacement: 'prod'

  # ç»“æœï¼š
  # æ‰€æœ‰æ ·æœ¬éƒ½è·å¾—äº† env="prod" æ ‡ç­¾
  # æ ·æœ¬æ•°é‡ä¸å˜ï¼Œä½†æ ‡ç­¾ç»“æ„æ”¹å˜
  scrape_samples_post_metric_relabeling{job="myapp"} 3000

  ğŸ¯ åœºæ™¯3: é«˜çº§è¿‡æ»¤é€»è¾‘

  # é…ç½®ï¼šå¤æ‚çš„è¿‡æ»¤å’Œè½¬æ¢é€»è¾‘
  metric_relabel_configs:
    # åªä¿ç•™ HTTP ç›¸å…³æŒ‡æ ‡
    - source_labels: [__name__]
      regex: 'http_.*'
      action: keep

    # æ·»åŠ æœåŠ¡æ ‡ç­¾
    - source_labels: [__meta_kubernetes_pod_label_app]
      target_label: service
      regex: '(.*)'
      replacement: '${1}'

    # åˆ é™¤ä¸´æ—¶æ ‡ç­¾
    - regex: '__meta_kubernetes_.*'
      action: labeldrop

  ç›¸å…³æŒ‡æ ‡å¯¹æ¯”

  ğŸ“ˆ å®Œæ•´çš„æŠ“å–æŒ‡æ ‡ä½“ç³»

  # 1. æŠ“å–çš„åŸå§‹æ ·æœ¬æ•°
  scrape_samples_scraped{job="myapp", instance="localhost:8080"}

  # 2. Metric relabeling åçš„æ ·æœ¬æ•°
  scrape_samples_post_metric_relabeling{job="myapp", instance="localhost:8080"}

  # 3. å®é™…å­˜å‚¨çš„æ ·æœ¬æ•°ï¼ˆå¯èƒ½å› å…¶ä»–åŸå› è¢«ä¸¢å¼ƒï¼‰
  prometheus_tsdb_head_samples_appended{job="myapp", instance="localhost:8080"}

  ğŸ“Š è¿‡æ»¤æ•ˆç‡è®¡ç®—

  # è®¡ç®— metric relabeling çš„è¿‡æ»¤æ•ˆç‡
  (
    scrape_samples_scraped - scrape_samples_post_metric_relabeling
  ) / scrape_samples_scraped * 100

  # ç¤ºä¾‹ï¼šè®¡ç®—è¿‡æ»¤æ‰çš„æ ·æœ¬ç™¾åˆ†æ¯”
  (5000 - 3000) / 5000 * 100 = 40%  # è¿‡æ»¤æ‰äº† 40% çš„æ ·æœ¬

  ç›‘æ§å’Œå‘Šè­¦

  ğŸš¨ åŸºäºæ­¤æŒ‡æ ‡çš„å‘Šè­¦

  # å‘Šè­¦ï¼šmetric relabeling åæ ·æœ¬æ•°ä¸º 0
  - alert: ScrapeNoSamplesAfterRelabeling
    expr: scrape_samples_post_metric_relabeling == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "No samples after metric relabeling for {{ $labels.job }}/{{ $labels.instance }}"
      description: "Target {{ $labels.instance }} in job {{ $labels.job }} has no samples after metric relabeling."

  # å‘Šè­¦ï¼šæ ·æœ¬æ•°å¼‚å¸¸ä½
  - alert: ScrapeLowSamplesAfterRelabeling
    expr: scrape_samples_post_metric_relabeling < 10
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Low sample count after metric relabeling"
      description: "Only {{ $value }} samples remaining after relabeling for {{ $labels.job }}/{{ $labels.instance }}"

  ğŸ“ˆ ä»ªè¡¨ç›˜æŸ¥è¯¢

  # 1. å„ä»»åŠ¡çš„æ ·æœ¬æ•°è¶‹åŠ¿
  sum(scrape_samples_post_metric_relabeling) by (job)

  # 2. å„å®ä¾‹çš„æ ·æœ¬æ•°åˆ†å¸ƒ
  sum(scrape_samples_post_metric_relabeling) by (instance, job)

  # 3. è¿‡æ»¤æ•ˆç‡åˆ†æ
  (sum(scrape_samples_scraped) - sum(scrape_samples_post_metric_relabeling)) / sum(scrape_samples_scraped) * 100

  # 4. æ ·æœ¬æ•°å˜åŒ–ç‡
  rate(scrape_samples_post_metric_relabeling[5m])

  æ•…éšœæ’æŸ¥

  ğŸ” é—®é¢˜è¯Šæ–­æµç¨‹

  # 1. æ£€æŸ¥åŸå§‹æŠ“å–æ•°æ®
  curl http://localhost:8080/metrics | wc -l

  # 2. æ£€æŸ¥ Prometheus ä¸­çš„æŒ‡æ ‡
  curl "http://prometheus:9090/api/v1/query?query=scrape_samples_post_metric_relabeling"

  # 3. æ£€æŸ¥ relabeling é…ç½®
  curl "http://prometheus:9090/api/v1/targets" | jq '.data.activeTargets[] | {job, instance, scrapeUrl, lastError}'

  ğŸ› ï¸ å¸¸è§é—®é¢˜è§£å†³

  # é—®é¢˜ï¼šè¿‡æ»¤è§„åˆ™è¿‡äºä¸¥æ ¼ï¼Œå¯¼è‡´æ ·æœ¬æ•°ä¸º 0
  # è§£å†³ï¼šæ£€æŸ¥ relabeling è§„åˆ™
  metric_relabel_configs:
    - source_labels: [__name__]
      regex: 'too_strict_pattern'  # å¯èƒ½è¿‡äºä¸¥æ ¼
      action: drop  # è€ƒè™‘æ”¾å®½è§„åˆ™

  æ€»ç»“

  scrape_samples_post_metric_relabeling æŒ‡æ ‡æ˜¯ Prometheus ç›‘æ§ä½“ç³»ä¸­çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå®ƒï¼š

  1. è·Ÿè¸ªè¿‡æ»¤æ•ˆæœ: ç›‘æ§ metric relabeling è§„åˆ™çš„å®é™…æ•ˆæœ
  2. ä¼˜åŒ–å­˜å‚¨ä½¿ç”¨: å¸®åŠ©ä¼˜åŒ–æŒ‡æ ‡å­˜å‚¨å’ŒæŸ¥è¯¢æ€§èƒ½
  3. æ•…éšœæ’æŸ¥: ç”¨äºè¯Šæ–­æ•°æ®ä¸¢å¤±å’Œé…ç½®é—®é¢˜
  4. å®¹é‡è§„åˆ’: è¯„ä¼°å­˜å‚¨éœ€æ±‚å’Œæ€§èƒ½å½±å“

  ç†è§£è¿™ä¸ªæŒ‡æ ‡å¯¹äºæœ‰æ•ˆç®¡ç† Prometheus çš„æŒ‡æ ‡æ”¶é›†å’Œå­˜å‚¨ç­–ç•¥è‡³å…³é‡è¦ã€‚
```

The **up** time series is useful for **instance availability monitoring**.

With the **extra-scrape-metrics** feature flag several **additional metrics** are available:

1. `scrape_timeout_seconds{job="<job-name>", instance="<instance-id>"}`
   - The **configured scrape_timeout** for a target. **10**
2. `scrape_sample_limit{job="<job-name>", instance="<instance-id>"}`
   - The **configured sample_limit** for a target. Returns **zero** if there is **no limit configured**. **0**
3. `scrape_body_size_bytes{job="<job-name>", instance="<instance-id>"}`
   - The **uncompressed size** of the **most recent scrape response**, if successful.
   - **Scrapes failing** because **body_size_limit** is **exceeded** report **-1**, <u>other scrape failures</u> report **0**.



