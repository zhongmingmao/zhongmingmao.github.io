---
title: LLM - API
mathjax: false
date: 2024-07-01 00:06:25
cover: https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240817181521113.png
categories:
  - AI
  - LLM
tags:
  - AI
  - LLM
  - NLP
  - Python
  - FastAPI
  - Uvicorn
---

# èƒŒæ™¯

1. LLM æ˜¯æ²¡æœ‰ **Web API** çš„ï¼Œéœ€è¦è¿›è¡Œä¸€æ¬¡**å°è£…**
2. å°† LLM çš„æ ¸å¿ƒæ¥å£å°è£…æˆ Web API æ¥ä¸ºç”¨æˆ·æä¾›æœåŠ¡ - **å¿…ç»ä¹‹è·¯**

<!-- more -->

# æ¥å£å°è£…

## FastAPI

### æ¥å£å°è£…

> Uvicorn + FastAPI

1. **Uvicorn** ç±»ä¼¼äº Tomcatï¼Œä½†æ¯” Tomcat è½»é‡å¾ˆå¤šï¼Œä½œä¸º **Web æœåŠ¡å™¨**
   - å…è®¸**å¼‚æ­¥å¤„ç†** HTTP è¯·æ±‚ï¼Œéå¸¸é€‚åˆå¤„ç†**å¹¶å‘è¯·æ±‚**
   - åŸºäº **uvloop** å’Œ **httptools**ï¼Œå…·å¤‡éå¸¸é«˜çš„æ€§èƒ½
2. **FastAPI** ç±»ä¼¼äº SpringBootï¼ŒåŒæ ·æ¯” SpringBoot è½»é‡å¾ˆå¤šï¼Œä½œä¸º **API æ¡†æ¶**
3. ç»“åˆ Uvicorn å’Œ FastAPI
   - å¯ä»¥æ„å»ºä¸€ä¸ª**é«˜æ€§èƒ½**çš„ã€**æ˜“äºæ‰©å±•**çš„**å¼‚æ­¥** Web åº”ç”¨ç¨‹åº
   - Uvicorn ä½œä¸º**æœåŠ¡å™¨**è¿è¡Œ FastAPI åº”ç”¨ï¼Œå¯ä»¥æä¾›ä¼˜å¼‚çš„**å¹¶å‘**å¤„ç†èƒ½åŠ›

### å®‰è£…ä¾èµ–

```
$ pip install fastapi
$ pip install uvicorn
```

### ä»£ç åˆ†å±‚

```python
import uvicorn
from fastapi import FastAPI

# åˆ›å»ºAPIåº”ç”¨
app = FastAPI()


@app.get("/")
async def root():
    return {"message": "Hello World"}


if __name__ == '__main__':
    uvicorn.run(app, host='0.0.0.0', port=8888, log_level="info", workers=1)
```

```json
$ curl -s 127.0.0.1:8888 | jq
{
  "message": "Hello World"
}
```

### æ¨¡å‹å®šä¹‰

> åœ¨ Python ä¸­ä½¿ç”¨ **Pydantic** æ¨¡å‹æ¥å®šä¹‰æ•°æ®ç»“æ„
> Pydantic - **æ•°æ®éªŒè¯ + æ•°æ®ç®¡ç†** - ç±»ä¼¼äº **Java Validation**

```python
import uvicorn
from fastapi import FastAPI
from pydantic import BaseModel, Field
from typing import List

app = FastAPI()


class Message(BaseModel):
    role: str
    content: str


class ChatMessage(BaseModel):
    history: List[Message]
    prompt: str
    max_tokens: int
    temperature: float
    top_p: float = Field(default=1.0)


@app.post("/v1/chat/completions")
async def create_chat_response(message: ChatMessage):
    return {"message": "Hello World"}


if __name__ == '__main__':
    uvicorn.run(app, host='0.0.0.0', port=8888, log_level="info", workers=1)
```

1. BaseModel ä¸ºäº†**æ•°æ®éªŒè¯å’Œç®¡ç†**è€Œè®¾è®¡çš„
2. å½“**ç»§æ‰¿** BaseModel åï¼Œå°†è‡ªåŠ¨è·å¾—**æ•°æ®éªŒè¯**ã€**åºåˆ—åŒ–**å’Œ**ååºåˆ—åŒ–**çš„åŠŸèƒ½

### é¡¹ç›®ç»“æ„

```
project_name/
â”‚
â”œâ”€â”€ app/                         # ä¸»åº”ç”¨ç›®å½•
â”‚   â”œâ”€â”€ main.py                  # FastAPI åº”ç”¨å…¥å£
â”‚   â””â”€â”€ controller/              # API ç‰¹å®šé€»è¾‘
â”‚       â””â”€â”€ chat_controller.py
â”‚   â””â”€â”€ common/                  # é€šç”¨APIç»„ä»¶
â”‚       â””â”€â”€ errors.py            # é”™è¯¯å¤„ç†å’Œè‡ªå®šä¹‰å¼‚å¸¸
â”‚
â”œâ”€â”€ services/                    # æœåŠ¡å±‚ç›®å½•
â”‚   â”œâ”€â”€ chat_service.py          # èŠå¤©æœåŠ¡ç›¸å…³é€»è¾‘
â”‚
â”œâ”€â”€ schemas/                     # Pydantic æ¨¡å‹ï¼ˆè¯·æ±‚å’Œå“åº”æ¨¡å¼ï¼‰
â”‚   â”œâ”€â”€ chat_schema.py           # èŠå¤©æ•°æ®æ¨¡å¼
â”‚
â”œâ”€â”€ database/                    # æ•°æ®åº“è¿æ¥å’Œä¼šè¯ç®¡ç†
â”‚   â”œâ”€â”€ session.py               # æ•°æ®åº“ä¼šè¯é…ç½®
â”‚   â””â”€â”€ engine.py                # æ•°æ®åº“å¼•æ“é…ç½®
â”‚
â”œâ”€â”€ tools/                       # å·¥å…·å’Œå®ç”¨ç¨‹åºç›®å½•
â”‚   â”œâ”€â”€ data_migration.py        # æ•°æ®è¿ç§»å·¥å…·
â”‚
â”œâ”€â”€ tests/                       # æµ‹è¯•ç›®å½•
â”‚   â”œâ”€â”€ conftest.py              # æµ‹è¯•é…ç½®å’Œå¤¹å…·
â”‚   â”œâ”€â”€ test_services/           # æœåŠ¡å±‚æµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ test_chat_service.py
â”‚   â””â”€â”€ test_controller/                
â”‚       â”œâ”€â”€ test_chat_controller.py
â”‚
â”œâ”€â”€ requirements.txt             # é¡¹ç›®ä¾èµ–æ–‡ä»¶
â””â”€â”€ setup.py                     # å®‰è£…ã€æ‰“åŒ…ã€åˆ†å‘é…ç½®æ–‡ä»¶
```

### è·¯ç”±é›†æˆ

> FastAPI é€šè¿‡ **include_router** å°†ä¸åŒçš„è·¯ç”±**é›†æˆ**åˆ°ä¸»åº”ç”¨ä¸­

```
â”œâ”€â”€ app
â”‚Â Â  â”œâ”€â”€ controller
â”‚Â Â  â”‚Â Â  â””â”€â”€ chat_controller.py
â”‚Â Â  â””â”€â”€ main.py
â”œâ”€â”€ schemas
â”‚Â Â  â””â”€â”€ chat_schema.py
â”œâ”€â”€ services
â”‚Â Â  â””â”€â”€ chat_service.py
â””â”€â”€ tests
    â””â”€â”€ test_controller
        â””â”€â”€ test_chat_controller.py
```

#### chat_schema.py

```python
from pydantic import BaseModel, Field


class Message(BaseModel):
    role: str
    content: str


class ChatMessage(BaseModel):
    prompt: str
    max_tokens: int
    temperature: float = Field(default=1.0)
    top_p: float = Field(default=1.0)
```

#### chat_service.py

```python
from schemas.chat_schema import ChatMessage


class ChatService:
    def post_message(self, message: ChatMessage):
        print(message.prompt)
        return {"message": "post message"}

    def get_messages(self):
        return {"message": "get message"}
```

#### chat_controller.py

```python
from fastapi import APIRouter

from schemas.chat_schema import ChatMessage
from services.chat_service import ChatService

chat_router = APIRouter()
chat_service = ChatService()


@chat_router.post("/new/message/")
def post_message(message: ChatMessage):
    return chat_service.post_message(message)


@chat_router.get("/get/messages/")
def get_messages():
    return chat_service.get_messages()
```

#### main.py

```python
import uvicorn as uvicorn
from fastapi import FastAPI
from controller.chat_controller import chat_router as chat_router

app = FastAPI()
app.include_router(chat_router, prefix="/chat", tags=["chat"])

if __name__ == '__main__':
    uvicorn.run(app, host='0.0.0.0', port=8888, log_level="info", workers=1)
```

#### test_chat_controller.py

```python
import json
import requests

data = {
    'prompt': 'hello',
    'max_tokens': 1000
}

url1 = 'http://localhost:8888/chat/new/message/'
response = requests.post(url1, data=json.dumps(data))
print(response.text)

url2 = 'http://localhost:8888/chat/get/messages/'
response = requests.get(url2)
print(response.text)
```

## LLM

> ä¸åŒçš„ LLM å¯¹åº”çš„**å¯¹è¯æ¥å£**ä¸ä¸€æ ·

### æ‡’åŠ è½½

```python
from transformers import AutoTokenizer, AutoModelForCausalLM


class ModelManager:
    _model = None
    _tokenizer = None

    @classmethod
    def get_model(cls):
        if cls._model is None:
            _model = AutoModelForCausalLM.from_pretrained("chatglm3-6b", trust_remote_code=True).half().cuda().eval()
        return _model

    @classmethod
    def get_tokenizer(cls):
        if cls._tokenizer is None:
            _tokenizer = AutoTokenizer.from_pretrained("chatglm3-6b", trust_remote_code=True)
        return _tokenizer
```

### Chat

> **ä¸€æ¬¡æ€§**è¾“å‡º LLM è¿”å›çš„å†…å®¹

```python
from datetime import datetime

from schemas.chat_schema import ChatMessage
from services.model_service import ModelManager


class ChatService:
    def post_message(self, message: ChatMessage):
        print(message.prompt)
        model = ModelManager.get_model()
        tokenizer = ModelManager.get_tokenizer()
        # model.chat() æ˜¯ 6B æš´éœ²çš„å¯¹è¯æ¥å£
        response, history = model.chat(
            tokenizer,
            message.prompt,
            history=message.histroy,
            max_length=message.max_tokens,
            top_p=message.top_p,
            temperature=message.temperature
        )
        now = datetime.datetime.now()  # è·å–å½“å‰æ—¶é—´
        time = now.strftime("%Y-%m-%d %H:%M:%S")  # æ ¼å¼åŒ–æ—¶é—´ä¸ºå­—ç¬¦ä¸²
        answer = {
            "response": response,
            "history": history,
            "status": 200,
            "time": time
        }
        log = "[" + time + "] " + '", prompt:"' + message.prompt + '", response:"' + repr(response) + '"'
        print(log)
        return answer

    def get_messages(self):
        return {"message": "get message"}
```

### Stream Chat

> model.stream_chat()

```
æˆ‘
æ˜¯
ä¸­
å›½
äºº
```

```
æˆ‘
æˆ‘æ˜¯
æˆ‘æ˜¯ä¸­
æˆ‘æ˜¯ä¸­å›½
æˆ‘æ˜¯ä¸­å›½äºº
```

> é€šè¿‡ stream å˜é‡æ§åˆ¶æ˜¯å¦æµå¼è¾“å‡º

```python
if stream:
    async for token in callback.aiter():
        # Use server-sent-events to stream the response
        yield json.dumps(
            {"text": token, "message_id": message_id},
            ensure_ascii=False)
else:
    answer = ""
    async for token in callback.aiter():
        answer += token
    yield json.dumps(
        {"text": answer, "message_id": message_id},
        ensure_ascii=False)
await task
```

> stream=true

```json
data: {"text": "ä½ ", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "å¥½", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "ğŸ‘‹", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "ï¼", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "æˆ‘æ˜¯", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "äººå·¥æ™ºèƒ½", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "åŠ©æ‰‹", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": " Chat", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "GL", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "M", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "3", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "-", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "6", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "B", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "ï¼Œ", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "å¾ˆé«˜å…´", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "è§åˆ°", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "ä½ ", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "ï¼Œ", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "æ¬¢è¿", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "é—®æˆ‘", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "ä»»ä½•", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "é—®é¢˜", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
data: {"text": "ã€‚", "message_id": "80b2af55c5b7440eaca6b9d510677a75"}
```

> stream=false

```json
data: {"text": "ä½ å¥½ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆé—®é¢˜æˆ‘å¯ä»¥å¸®æ‚¨è§£ç­”å—ï¼Ÿ", "message_id": "741a630ac3d64fd5b1832cc0bae6bb68"}
```

# æ¥å£è°ƒç”¨

1. åœ¨å·¥ç¨‹åŒ–å®è·µä¸­ï¼Œä¸€èˆ¬ä¼šå°†ä¸ **AI** ç›¸å…³çš„é€»è¾‘**å°è£…**åœ¨ **Python** åº”ç”¨ä¸­
2. **ä¸Šå±‚åº”ç”¨**ä¸€èˆ¬é€šè¿‡å…¶å®ƒè¯­è¨€å®ç° - **Java / Go**

## Java

> Java -> Pythonï¼ŒåŸºäº **OkHttp** å®ç° **Server-Sent Events**

![image-20240817215939927](https://llm-1253868755.cos.ap-guangzhou.myqcloud.com/image-20240817215939927.png)

## JavaScript

> JavaScript -> Javaï¼ŒåŸºäº **EventSource** å®ç° **Server-Sent Events**

```javascript
<script>
  let eventData = '';
  const eventSource = new EventSource('http://localhost:9999/sendMessage');
  eventSource.onmessage = function(event) {
    // ç´¯åŠ æ¥æ”¶åˆ°çš„äº‹ä»¶æ•°æ®
    eventData += event.data;
  };
</script>
```

