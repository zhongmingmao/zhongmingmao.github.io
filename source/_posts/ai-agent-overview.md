---
title: AI Agent - Overview
mathjax: true
date: 2025-01-18 00:06:25
cover: https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/ai-agent.webp
categories:
  - AI Agent
  - MCP
  - A2A
tags:
  - MCP
  - A2A
---

# 技术更迭

![image-20250912095241722](https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/image-20250912095241722.png)

<!-- more -->

# LLM 应用工程化难题

1. **模型**与**外部世界**割裂
   - LLM 是基于**概率计算**的新范式，虽然很强大，但仍需要与传统的**结构化**计算范式相结合，即通过**工具调用**来完成**精确任务**
   - 目前传统结构化工具与 LLM 之间是割裂的，LLM 难以直接动态地接入**实时数据**、**数据库**或**企业工具**
   - 传统的 API 调用方式**零散且不标准**，导致开发效率低下
2. **Agent 协作**的孤岛效应
   - 不同 Agent 框架（LangGraph、AutoGen、CrewAI）各自为政，**缺乏统一的通信标准**，跨平台协作很难实现
3. **复杂场景**的工程化瓶颈
   - 从搜索助手到企业知识中台、RAG 与多 Agent 系统需要处理**多源数据**、**多模态交互**和**长时任务**，现有**工具链**难以提供**统一的解决方案**

# MCP + A2A

> **标准化** + **可扩展**

![image-20250912101054787](https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/image-20250912101054787.png)

## MCP 

> **模型主控** + **客户端驱动**

1. MCP 是一个为 **LLM** 更方便地利用**外部资源**（主要是**工具**）而设计的**标准化接口**，旨在打破 LLM 与外部数据、工具之间的壁垒
2. 传统上，将 AI 系统连接到外部工具需要**集成多个 API** - <u>代码冗余 + 难以维护 + 扩展性差</u>

![image-20250912101826989](https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/image-20250912101826989.png)

> MCP 将**繁琐细节**都隐藏到服务器端 - 开发者只需关心 **LLM 想用哪个工具做什么** - 不再需要为每个服务编写样板代码 - **即插即用**

1. 服务端**注册**好**工具能力**
2. 然后 **Agent** 发起同一套 **JSON-RPC** 调用
3. **MCP 服务器**负责底层的 **HTTP 请求**、**鉴权**、**连接管理**和**结果解析**，最后把结果一并返回给 LLM

> JSON-RPC 调用

```json
{
  "method": "callTool",
  "params": {
    "tool": "Translate",
    "input": "Hello, world!",
    "target_lang": "zh"
  }
}
```

> 核心理念 - **模型主控、客户端驱动服务器调用**

| Role       | Effect                     |
| ---------- | -------------------------- |
| LLM        | 推理 + 决策                |
| 客户端     | 动态提供上下文、工具和资源 |
| 外部服务器 | 提供工具和资源             |

![image-20250912103117569](https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/image-20250912103117569.png)

1. 基于 **MCP** 的标准化协议，可以将 **AI Agent** 轻松地连接到各种**外部工具**和**数据源**
2. **MCP** 相当于专门为 **AI 应用**提供的 **USB-C 端口**
   - **即插即用**，所有**繁琐**的事情，都由 **MCP Server** 根据协议来提供

> <u>OpenAI Function Calling</u> vs <u>LangChain Tools</u> vs <u>JSON-RPC</u>

1. OpenAI Function Calling 和 LangChain Tools 让 LLM 能够实现**工具调用**，但并没有真正解决 **LLM 应用开发**的**高墙**
2. OpenAI Function Calling 只绑在 **GPT** 系列上
   - 其调用规范、参数定义和返回格式都**深度耦合**在 OpenAI 的 API 流程中，**无法扩展**到其它开源或私有模型
3. LangChain Tools 支持多种模型和工具，但所有能力都要写在 **LangChain 框架**里面 - Spring AI
4. **JSON-RPC** 作为**通用远程调用协议**，轻量却太过**底层** - 只关心**发送请求**和**接收响应**
   - 不包括 - LLM 的**上下文管理**、**并发会话**、**流式返回**、**能力发现**等
   - 并没有形成**面向 LLM** + **Agent 协作**的**统一**、**可插拔**、**开箱即用**的**接口规范**

> **MCP** 在 **JSON-RPC** 之上，为 **LLM** 量身定制

| Key              | Value                                                        |
| ---------------- | ------------------------------------------------------------ |
| **统一工具描述** | 所有能力用同一份 **tool.json** 注册，LLM 只按**名字** call 即可 |
| **会话与权限**   | 自动管理**多轮对话状态**、**工具访问权限**和**鉴权流程**，**LLM 无需关心鉴权细节** |
| **流式与事件**   | 内建**流式数据返回**、**异步回调**和**事件订阅**，让**长任务**、**实时监控**、**异步通知**都能自然融入**推理过程** |
| **多层传输**     | 即可跑 **HTTP/REST**、也可以挂 **WebSocket**、**RPC** 或 **MQ**，灵活适配不同的部署场景 |

> MCP - 模型想用什么工具干啥 - **LLM** 专注于**决策**，**开发者**专注于**业务逻辑**

![image-20250913001255456](https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/image-20250913001255456.png)

> MCP 的统一接口让开发者无需为每个场景**定制协议**，显著降低了**工程化成本** - 只需要保留**核心决策**和**业务流程**

## A2A

1. Agent-to-Agent - 智能代理之间的协议，本质上，是让不同的 Agent 能够**无障碍沟通和协作**的标准语言
2. 不同的 Agent 会有不同的能力，为了共同完成一项任务，必须不断地交换信息、共享知识、甚至协同合作
3. 不同的开发者、公司和团队可能会创造出各种各样的 Agent，它们之间基本无法按**标准语言**来**统一沟通**
4. A2A 协议应运而生，它定义了一套**清晰**、**标准**的沟通方式，让所有 Agent 可以**顺畅地交流**彼此的**需求**、**能力**、**决策**和**状态**

![image-20250913002756303](https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/image-20250913002756303.png)

> A2A 协议的职责

| Key          | Value                                                        |
| ------------ | ------------------------------------------------------------ |
| **统一协议** | 所有 Agent 均使用**同一个消息 schema** 进行**能力发现**与**调用** |
| **异步协作** | 支持**流式**与**异步返回**，可**并发处理**多任务             |
| **灵活扩展** | 新 Agent **即插即用**，无需额外适配器                        |
| **解耦实现** | Agent 专注业务，**底层传输**、**鉴权**、**错误处理**由协议层统一管理 |

1. A2A 协议是一种**开放标准**，用于让**不同平台和框架**下的 AI 智能代理能够实现无障碍地**信息交换和协作**
2. 技术上说
   - A2A 通过**标准化**的组件（如 **Agent Cards** ）为 Agent 间的相互**发现**与**握手**提供了**通用语言**
   - A2A 在 **JSON-RPC**、**HTTP/SSE** 等底层传输之上，定义了**能力发现**、**会话管理**、**任务生命周期管理**、**消息与内容单元**、**权限认证**、**流式**与**事件**等语义
   - 使得多 Agent 能够**灵活拼接**、**异步协作**，并且具备**企业安全**与**可扩展性**
3. A2A 支持**长时任务**、**多模态协作**（文本、图像、音视频），并强调**企业安全性**
4. 与 **MCP** 的**资源管理**结合，A2A 使 Agent 能够**动态协商任务分配**，实时共享数据洞察
   - 一个基于 **CrewAI** 的客服 Agent 可以通过 A2A 的 **LlamaIndex** 驱动的知识检索 Agent 协作，共同完成客户问题的精准解答

# MCP vs A2A

> 都是**标准化协议**，都在 LLM 应用场景中实现**信息交换和协作**，形成**互补**关系，形成一个完整的 AI 时代的**通信协议方案**

![image-20250913005507158](https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/image-20250913005507158.png)

> MCP 与 A2A 结合，将单一 AI 应用推向**分布式**、**模块化**的智能生态

1. MCP 提供了统一的**上下文管理**与**工具调用**接口，整合了 **LLM** 驱动的**概率计算**与**传统工具**驱动的**结构化计算**
2. A2A 则为**多 Agent 协同**注入了**开放标准**

> 未来的 AI 系统将不再是孤立的模型，而是由无数 **Agent** 和**知识模块**组成的动态网络

## 相同点

![image-20250913004742619](https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/image-20250913004742619.png)

## 差异点

![image-20250913005135465](https://ai-agent-1253868755.cos.ap-guangzhou.myqcloud.com/image-20250913005135465.png)
