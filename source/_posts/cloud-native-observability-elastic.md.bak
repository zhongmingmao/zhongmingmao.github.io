---
title: Observability - Elastic
mathjax: true
date: 2025-01-02 00:06:25
cover: https://observability-1253868755.cos.ap-guangzhou.myqcloud.com/elastic-observability.jpeg
categories:
  - Cloud Native
  - Observability
tags:
  - Cloud Native
  - Observability
---

# 参考

| Subject                                                | Uri                                                          | Status |
| ------------------------------------------------------ | ------------------------------------------------------------ | ------ |
| Overview                                               | https://www.elastic.co/cn/observability/                     | Done   |
| Elastic Observability                                  | https://www.elastic.co/guide/en/observability/current/index.html |        |
| OpenTelemetry                                          | https://www.elastic.co/cn/observability/opentelemetry        |        |
| Cloud Native                                           | https://www.elastic.co/cn/observability/cloud-native         |        |
| Tool Consolidation                                     | https://www.elastic.co/cn/observability/tool-consolidation   |        |
| Cloud Monitoring                                       | https://www.elastic.co/cn/observability/cloud-monitoring     |        |
| Cloud Migration                                        | https://www.elastic.co/cn/observability/cloud-migration      |        |
| Digital Experience Monitoring                          | https://www.elastic.co/cn/observability/digital-experience-monitoring |        |
| DevOps                                                 | https://www.elastic.co/cn/observability/devops               |        |
| AIOps                                                  | https://www.elastic.co/cn/observability/aiops                |        |
| Log Monitoring                                         | https://www.elastic.co/cn/observability/log-monitoring       |        |
| Application Performance Monitoring                     | https://www.elastic.co/cn/observability/application-performance-monitoring |        |
| AI Assistant                                           | https://www.elastic.co/cn/elasticsearch/ai-assistant         |        |
| Infrastructure Monitoring                              | https://www.elastic.co/cn/observability/infrastructure-monitoring |        |
| Synthetic Monitoring                                   | https://www.elastic.co/cn/observability/synthetic-monitoring |        |
| Real User Monitoring                                   | https://www.elastic.co/cn/observability/real-user-monitoring |        |
| Universal Profiling                                    | https://www.elastic.co/cn/observability/universal-profiling  |        |
| What is Observability                                  | https://www.elastic.co/cn/what-is/observability              | Done   |
| Application Performance Monitoring                     | https://www.elastic.co/cn/what-is/application-performance-monitoring | Done   |
| Root Cause Analysis                                    | https://www.elastic.co/cn/what-is/root-cause-analysis        |        |
| Anomaly Detection                                      | https://www.elastic.co/cn/what-is/anomaly-detection          |        |
| What is                                                | https://www.elastic.co/cn/what-is                            |        |
| Building data foundation modern observability          | https://www.elastic.co/cn/observability/building-data-foundation-modern-observability |        |
| Building Software Reliability With Distributed Tracing | https://www.elastic.co/cn/blog/building-software-reliability-with-distributed-tracing |        |
| Abnormal detection                                     | https://www.elastic.co/cn/blog/using-elastic-machine-learning-rare-analysis-to-hunt-for-the-unusual |        |
| Devops Observability                                   | https://www.elastic.co/cn/explore/devops-observability       |        |
| Kubernetes Monitoring                                  | https://www.elastic.co/cn/observability/kubernetes-monitoring |        |
| Serverless                                             | https://www.elastic.co/cn/what-is/serverless-computing       |        |
| Opentelemetry                                          | https://www.elastic.co/cn/what-is/opentelemetry              |        |
| ROI                                                    | https://www.elastic.co/cn/blog/total-economic-impact-study-elastic-delivers-10x-performance-with-up-to-75-percent-cost-savings |        |
| Log Management                                         | https://www.elastic.co/cn/virtual-events/best-practices-for-log-management |        |
| eBook                                                  | https://www.elastic.co/cn/explore/devops-observability/leveraging-observability-to-build-better-applications-at-scale |        |
| Elasticon global Observability                         | https://www.elastic.co/cn/blog/elasticon-global-observability |        |
| Elastic APM                                            | https://www.elastic.co/cn/blog/distributed-tracing-opentracing-and-elastic-apm |        |
| APM NET Agent                                          | https://www.elastic.co/cn/blog/auto-instrumentation-elastic-apm-net-agent |        |
| Correlations                                           | https://www.elastic.co/cn/blog/apm-correlations-elastic-observability-root-cause-transactions |        |
| AIOps                                                  | https://www.elastic.co/cn/what-is/aiops                      |        |
| Integrations                                           | https://www.elastic.co/cn/integrations                       |        |
| Opentelemetry Observability                            | https://www.elastic.co/observability-labs/blog/opentelemetry-observability |        |
| Gartner Magic Quadrant                                 | https://www.elastic.co/cn/resources/observability/analyst-report/gartner-magic-quadrant-observability-platforms |        |
| RUM                                                    | https://www.elastic.co/cn/blog/performing-real-user-monitoring-rum-with-elastic-apm |        |
| Synthetic Monitoring                                   | https://www.elastic.co/observability-labs/blog/new-synthetic-monitoring-observability |        |
| APM                                                    | https://www.elastic.co/cn/virtual-events/getting-started-with-apm |        |
| Tracing                                                | https://www.elastic.co/cn/webinars/distributed-tracing-opentracing-and-elastic-apm |        |
| Total Economic Impact                                  | https://www.elastic.co/cn/explore/devops-observability/forrester-total-economic-impact-observability |        |
| Observability Predictions                              | https://www.elastic.co/cn/blog/observability-predictions-trends-2023 |        |
| Practice                                               | https://www.elastic.co/cn/virtual-events/addressing-the-gaps-in-your-observability-practice |        |
| Search AI Lake                                         | https://www.elastic.co/cn/cloud/serverless/search-ai-lake    |        |
| Virtual Events                                         | https://www.elastic.co/cn/virtual-events                     |        |
| AIOps                                                  | https://www.elastic.co/cn/explore/devops-observability/understanding-aiops-for-observability |        |
| Elastic Observability Serverless                       | https://www.elastic.co/guide/en/serverless/current/what-is-observability-serverless.html |        |
| Elastic integrations                                   | https://www.elastic.co/guide/en/integrations/current/introduction.html |        |
| RUM Agent                                              | https://www.elastic.co/guide/en/apm/agent/rum-js/current/intro.html |        |
| RUM Agent Framework                                    | https://www.elastic.co/guide/en/apm/agent/rum-js/current/framework-integrations.html |        |
| ECS logging                                            | https://www.elastic.co/guide/en/ecs-logging/overview/master/intro.html |        |
| Root cause analysis with logs                          | https://www.elastic.co/observability-labs/blog/reduce-mttd-ml-machine-learning-observability |        |
| APM Correlations                                       | https://www.elastic.co/blog/apm-correlations-elastic-observability-root-cause-transactions |        |
| Fleet and Elastic Agent                                | https://www.elastic.co/guide/en/fleet/8.17/fleet-overview.html |        |
| Elastic Common Schema                                  | https://www.elastic.co/guide/en/ecs/8.17/ecs-reference.html  |        |
| Log Rate Analysis                                      | https://www.elastic.co/guide/en/kibana/8.17/xpack-ml-aiops.html#log-rate-analysis |        |
| Change Point Detection                                 | https://www.elastic.co/guide/en/kibana/8.17/xpack-ml-aiops.html#change-point-detection |        |
| Installation Verification                              | https://github.com/elastic/opentelemetry/tree/main/docs/kubernetes/operator#installation-verification |        |
| Instrumenting Applications                             | https://github.com/elastic/opentelemetry/blob/main/docs/kubernetes/operator/instrumenting-applications.md |        |
| Subscriptions                                          | https://www.elastic.co/subscriptions                         |        |
| Elastic Opentelemetry                                  | https://github.com/elastic/opentelemetry                     |        |

<!-- more -->

# 概述

> 基于 **Search AI** 提供支持的可观测性

1. 通过基于 Elastic **Search AI** Platform 构建的可观测性，一体化地管理**指标**、**日志**、**痕迹**和**性能分析**。
2. 探索部署最为广泛的可观测性解决方案，即使处理 **PB** 量级的数据，也能够在**数分钟**提供**深入见解**。

> **开放**、**可扩展**的**全堆栈**可观测性

![diagram-opentelemetry](/Users/zhongmingmao/data/typora/diagram-opentelemetry.png)

## **OpenTelemetry**

> 借助**开放标准**保护您的投资

1. 凭借在开源领域的深厚积淀，Elastic 将 **OpenTelemetry** 原生集成到我们的**开放**且**可扩展**的平台中，以实现大规模的无死角可见性
2. 从贡献 **Elastic ECS** 到 Elastic 的 **Universal Profiling** 代理，Elastic 一直支持 **OpenTelemetry** 作为可观测性的标准。

## 云原生

> 信心满满地采用**云原生**架构

1. 监测您的云原生生态系统，从 **Kubernetes** 到**无服务器**
2. 通过无缝的**上下文工作流**关联**依赖关系**和调查问题。

## 工具整合

> 减少工具杂乱，更快解决问题

1. 通过 **350** 多个 Elastic 集成整合可观测性
2. 包括对**云服务**和 **OpenTelemetry** 等开源项目的本地支持。

## 云监测

> 在**混合云**和**多云**环境中**统一可见性**

1. 无论您的应用程序和基础架构托管在何处，都可从中**无缝采集遥测数据**，以便深入了解最复杂的环境。

## 云迁移

> 快速迁移到云

1. 借助我们的**零配置无服务器产品**，加速云迁移进程，实现环境端到端的全面可见性。

## 数字化体验

> 全天候监测数字化体验

1. 全天候主动监测**用户**旅程，在用户受到影响之前发现并解决问题
2. 跟踪所有区域所有**设备**上的**性能**

## DevOps

> 以更快的发布速度加速创新

1. 全面了解整个**软件交付生命周期**
2. 通过 **CI/CD** 可观测性，消除孤岛并识别任何**性能回归**

## AIOps

> 借助 **ML** 和 **AI** 提供具有**上下文感知能力**的可操作见解

1. **自动**完成**异常检测**并**更快**地完成**根本原因分析**
2. 从**手动追踪数据**转向使用**生成式 AI** 进行**交互式探索**。

## Universal Profiling

1. 了解 Elastic 对 **OpenTelemetry** 的**最新贡献** — Universal Profiling 代理

## 端到端

> 通过**端到端**的可观测性解决方案**统一可见性**

1. 从**任何来源**收集、存储和可视化数据
2. 利用 **Machine Learning** 和 **AI** 加快问题解决速度
3. 在**任何云**中实现大规模部署，只需按**使用量**付费
4. 通过**开源**且**可扩展**的平台获得最大的灵活性

## 日志监测和分析

1. 基于 **PB** 量级的日志获得**可感知上下文**的见解
2. 与**日志监测和分析**领域的领导者携手，利用 **GenAI** 在**几秒钟内**获得见解
3. **大规模**分析**结构化**和**非结构化**日志

## 应用程序性能监测

> 快速发现并解决应用程序问题

1. 深入了解**云原生**和**分布式**应用程序，快速识别出现性能问题的根本原因并加以解决。

## AI Assistant

> 使用**生成式 AI** 为 **SRE** 赋能

1. 将**生成式 AI** 与**异常检测**和**可观测性**相结合，基于您的专有数据打造**交互式聊天体验**。

## 基础架构监测

> 对**混合云**和**多云**环境进行**一体化监测**

1. 通过 **350** 多个 Elastic 集成监测**动态分布式基础架构**，包括对**云服务提供商服务**和 **Kubernetes** 的支持。

## 合成监测

> 主动监测用户旅程

1. 全面了解**用户体验**，并在客户之前发现问题
2. 通过集成的 **GitOps** 工作流简化测试

## 真实用户监测

> 全面了解用户交互和性能

1. 收集反映**实际用户体验**的**性能数据**
2. 了解应用程序在最终用户系统上的性能，帮助优化性能

## Universal Profiling

> 从**内核**到**高级代码**进行**观测**和**优化**

1. 覆盖**全环境**的**性能分析**。**不分地点**，即刻完成
2. 利用 Elastic 无缝集成、**持续在线**的性能分析功能，轻松获得复杂**云原生环境**的**全系统可见性**

## 全堆栈可观测性

1. 全堆栈可观测性是指一个可观测性解决方案监测**整个应用程序堆栈**（从**最终用户**到**应用程序代码**和**基础架构**）的能力
2. 全堆栈可观测性解决方案通常由多种功能组成，例如：**日志监测和分析**、**云和基础架构监测**、**应用程序性能监测**、**数字体验监测**、**持续性能分析**和 **AIOps**
3. 优势
   - 全堆栈可观察性使企业能够实现**业务**和**运营**的**卓越性**
   - 通过实施全栈可观察性，**SRE** 团队打破了**各自为政**的局面，可以利用**上下文警报**和**有效的跨职能协作**，更快地**主动发现和解决问题**
   - 企业可以按照服务水平协议（**SLA**）提供服务，缩短**上市时间**，提高**运营效率**和**客户满意度**

## Splunk -> Elastic

1. 各地的企业都面临着一个充满挑战的环境：**成本压力**增加，加上**复杂**、**分布式**、**云原生**环境产生的**大量数据**
   - 因此，团队需要更智能的分析、数据访问和所有数据的保留（即时和随时随地），以便解决问题、做出决策和确保弹性
2. 许多已采用 **Splunk Enterprise** 的公司需要做出选择，因为 Splunk 提供的 Splunk Enterprise、Splunk Cloud 和 Splunk Observability 具有**不同的定价模式**
   - 相比之下，Elastic 提供了一种**快速、简单**的解决方案，使公司能够**面向未来**

## 可观测性 + 监控

1. **可观察性**可以看作是**现代应用监控**的发展
2. 从根本上说，它是**应用程序**和**基础设施**通过可操作的**日志**、发布的**指标**和**分布式跟踪**来**暴露其内部状态**的能力
3. 作为一种方法，可观察性比传统监控更适合通过**收集**、**转换**、**关联**、**分析**和**可视化**这些**信号**来管理**云原生环境**的**复杂性**和**规模**
4. 可观察性随着**新趋势**和**新技术**的出现而**不断发展**

## 实现路径

1. 在实施可观察性时，应从**技术**和**操作准备**的角度考虑
2. 确保**人员和流程到位**，以支持可观察性功能
3. 确定最初要收集的数据
   - 如果您刚刚起步，我们建议您先从**单个应用程序**开始试点，重点关注**一种类型的信号**（如日志），然后再转向度量和跟踪
4. 选择能与您**共同成长**的可观测性解决方案，为**未来**做好规划

## Search AI Lake

1. Elastic 的 Search AI Lake 为**实时的低延迟应用程序**进行了优化，成为您 AI 驱动未来的理想架构
2. Search AI Lake 通过结合**数据湖的巨大存储容量**、**Elasticsearch 的低延迟查询**，以及**强大的搜索**和 **AI 相关性**功能，为数据湖领域带来革新力量
3. Search AI Lake 为 Elastic Cloud 提供了一种全新的**无服务器部署**方式，消除了所有**运维开销**，可让您的团队更专注于创新

# 可观测性

## 定义

> 可观测性是指如何通过**检查系统的外部输出**（尤其是系统的数据）来**了解系统的内部状态**。

1. 在现代应用程序开发的背景下，可观测性是指从**各种来源**收集和分析数据（例如**日志**、**指标**和**痕迹**），以针对环境中运行的应用程序的行为提供详细见解
   - 它可以应用于任何您构建的并希望进行监测的系统
2. 可观测性对于当今的**动态架构**和**多云计算环境**来说，都是至关重要的
   - 借助**可观测性**，可让**软件工程师**、**IT**、**DevOps** 和网站可靠性工程 (**SRE**) 团队解读**遥测数据**
   - 这可以借助**仪表板**、**服务依赖关系图**和**分布式跟踪**等可视化功能，以及 **AIOps** 和 **Machine Learning** 方法，轻松完成
   - 有了合适的**可观测性解决方案**，您便可以了解**应用程序**、**服务**和**基础架构**在跟踪和响应问题方面的表现

## 重要性

1. 可观测性很重要的原因在于，它能够让团队**评估**、**监测**和**改进**分布式 IT 系统的**性能**
   - 相比传统的监测方法，它要**有效得多**
   - **端到端可观测性平台**可以帮助**打破孤岛**并**促进协作**
   - 可以**主动诊断**、**分析问题**，并**追溯问题根源**
2. 可观测性使 IT 组织能够真正了解**云原生环境**中的**许多数据源**
   - 可观测性的三大支柱是**日志**、**指标**和**痕迹**
   - 通过**全堆栈可观测性**，您既可以**实时跟踪**多云生态系统的**性能**，也可以查看它过去的运行数据
   - 您可以综合源自**各种终端和服务**（包括**硬件**、**软件**、**云基础架构组件**、**容器**、**开放数据源**、**微服务**等）生成的数据
3. 可观测性有助于组织
   - 发现和分析**性能事件**对业务的重要性
   - 提高**软件开发生命周期**的**效率**
   - 加速**问题解决**和**根本原因分析**
   - 改进**最终用户体验**
   - 增强**应用程序安全性**
4. 可观测性解决方案对企业的 **IT 运营**至关重要，对**企业利润**的影响也不可小觑
   - 可观测性能够让应用程序**交付**的速度更快，**品质**更高，这也意味着为您的团队**节省成本**和**优化资源**
   - **性能更好**的应用程序最终会带来**更多收入**

## 可观测性 + APM + 监测

### 监测

> 简单问题 + 难以预测

1. 监测是团队**观测**和**评估**各个**系统状态**的方式
2. 它经常会结合使用**日志**和一组**预定义的指标**来**跟踪**错误和使用模式
3. 这些指标可以帮助回答有关**服务器利用率**、**响应时间**和**吞吐量**方面的**简单问题**
4. 专门的监测工具有助于**发现**团队**可以预见**的**孤岛式问题**
   - 但是，在更为复杂的**云原生**应用程序上，**很难**对问题做出**预测**，因为这些应用程序存在许多**依赖关系**
   - 团队需要有一个工具来帮助管理这种程度的复杂性

### APM

1. 应用程序性能监测 (**APM**)（通常被认为是**可观测性**的一个**子集**）是一种用于**深入了解应用程序代码和依赖关系**的监测方案
2. APM 的一个**关键功能**是**分布式跟踪** - 这项功能可用于跟踪应用程序中的
3. APM 可以帮助支持和优化应用程序**性能**，识别瓶颈，并改进**用户体验**

### 可观测性

1. 可观测性结合了 **APM** 和**传统监测工具**，但并**不能取代**它
   - 它提供了一个专为当今**复杂软件系统**构建的**更全面的工具集**，可以针对**整个基础架构**的总体运行状况和性能提供**精细见解**
2. 可观测性会利用从环境中的所有**应用程序**、**微服务**、**服务器**和**数据库**中收集和聚合的**日志**、**痕迹**和**指标**。
3. 这有助于团队通过查看**整个 IT 生态系统**中的**数据**和**依赖关系**来确定问题的**根本原因**

## 关键概念

1. 可观测性的运作方式是，通过**不断收集性能数据**，为每个用户的**请求**和**事务**创建完整、相关的**记录**
2. 系统的**可观测性越高**，就越能**快速准确**地**识别**和**跟踪**性能问题的根源
3. 可观测性平台会**实时关联大量的遥测数据**，可为 **DevOps**、**SRE** 和 **IT** 团队提供任何事件或问题的**完整背景信息**。

![ElasticONBlog-OBS-Image1](/Users/zhongmingmao/data/typora/ElasticONBlog-OBS-Image1.png)

### 日志数据

1. 日志可提供**应用程序事件**的**带时间戳**的**记录**。一个大型组织一天可以产生数十亿个日志！

### 指标

1. 指标是**时序数据**，用于衡量**应用程序**和**系统**在**一段时间内**的运行状况和**性能**。

### 分布式跟踪

1. 分布式跟踪通过**整个分布式架构**提供每个用户请求的**端到端代码级记录**。

### 依赖关系映射

1. 依赖关系图显示了**应用程序**、**服务**和**基础架构组件**是如何关联的。

### 异常检测

1. 异常检测会使用**基线**、**统计分析**或 **Machine Learning** 对系统中的**异常行为**发出早期警告。

## 用例

1. 借助可观测性工具，团队能够处理大量数据，而无需进行繁琐的手动工作或运行效率低下的系统
2. 可观测性平台可在问题影响客户体验和收入**之前**解决问题并确定根本原因

> 监测系统**性能**并做出响应

1. **故障排查**和**监测应用程序性能**是可观测性的主要用例
2. 它可以帮助您了解有关服务和系统整体运行状况的问题
3. DevOps 中的可观测性可以监测给定操作的**平均响应时间**，并发现是何因素导致某些用户的加载时间变长
4. 此外，它还可以告知您哪些服务需要**微调**，或者某项更改可能造成了延迟或影响了应用程序性能
5. 它还能为您提供有关**用户体验**的基本情况报告，以及 **SLO** 的衡量方式

> 实现数字化和云转型

1. 随着公司向**应用程序现代化**和**云基础架构**的迁移，可观测性能够让他们**总体了解**所有移动部分的运行情况
   - 在**迁移过程**中，**保持系统正常运行**是**非常复杂**的
   - **全堆栈可观测性**对于确保系统在云迁移过程中和之后可靠运行也是非常有必要的
2. **微服务架构**让复杂性又更添一筹
   - 因为它们可以**跨不同的主机**独立部署，以便提高应用程序的**可扩展性**且**易维护性**
   - 但是，在微服务架构中跟踪更新、错误和故障是至关重要的
   - 可观测性可以让您完全了解**动态系统**中的**依赖关系**

## 优势

> 可观测性有利于解决 **IT** 团队、**DevOps**、**SRE** 乃至整个组织在**业务**和**运营**方面所面临的挑战

### 进行性能监测，加快问题解决速度

1. 可观测性能够发现您可能**从未想过**要寻找的条件
2. 这使您能够在**庞大的分布式系统**中**识别**特定应用程序**性能问题**的**根本原因**
3. 内置的 **Machine Learning** 可以自动**将异常与下游数据和依赖关系关联起来**，从而提供可操作的结果

### 完整且即时的可视性

1. 清晰观测**整个云原生和混合环境**，包括 **Kubernetes**
2. 您可以很轻松地从**应用程序**和**基础架构**中采集**指标**、**日志**和**痕迹**
3. 您的**所有数据**都会在**一个地方**进行**一体化处理**和**可视化**

### 消除工具孤岛

1. 借助可观测性，可让您**整合多个工具**并**全面收集遥测数据**。

### 更好的用户体验

1. **先于用户**主动发现问题
2. 确认主机、服务和 API 的**运行状况**，并使用页面加载、请求和延迟等指标跟踪所有区域和设备上的**性能**和**可用性**
3. 关联**运营**和**业务关键绩效指标**

## 挑战

1. 可观测性挑战与**复杂架构**的**爆炸式增长**有关
2. 如果没有合适的可观测性解决方案，原始数据的庞大数量、产生的速度及多样性可能会使**提取答案**变得**十分困难**，并增加**成本**
   - 这在 AWS、Azure 和 GCP 等**云平台**以及 **Kubernetes** 和**容器**等云原生技术中尤为如此
3. 没有采用有效可观测性策略的组织还会面临**端到端分布式跟踪**的挑战
   - **动态架构**需要**实时查看**容器内运行的**工作负载**
   - 对于团队来说，**手动**将**多个仪表板**中的信息**拼接**在一起是**不可行**的
4. **迁移基础架构**和添加更多的云可能会造成各种障碍
   - 例如，干扰数据、不连贯的监测策略和杂乱无序的工具，这些都是潜在的障碍
   - 而且，由于团队各自为政，获得的信号和经验可能会丢失
5. 在整个组织中培育一种**可观测性的文化**本身就是一个挑战
   - 对于 **IT** 和**开发**团队的许多人来说，向那些可能**不完全理解可观测性影响**的人介绍可观测性业务案例是很**棘手**的
   - 与**长期节省成本**和**提高效率**相比，实施**全面可观测性**计划的**短期成本和妥协**，有时只有**工程师**才能明白
6. 一个很好的开始方式是，解释可观测性可以带来的全方位**重大性能改进**和**成本节省**

## 关键功能

1. 可观测性平台的关键功能包括**实时洞察**和**具有交互式可视化的多信号数据聚合**
   - 当然，合适的可观测性工具应**易于使用和实施**
   - 至少，它应在**混合**和**多云**软件系统中提供可见性，改进**故障排查**方法，提供**更好的分析**，并提高**运营效率**
2. 使用**单个堆栈**来统一**日志**、**指标**、**数据**、**痕迹**和**合成数据**，可以帮助**打破数据孤岛**
3. 团队可以轻松地将**遥测数据**采集到一个**开放**且**可扩展**的平台中
4. 此外，**上下文数据模型**可以灵活地从**任何来源**收集、存储和可视化各种数据
5. 合适的可观测性工具还可让您在事件发生时**搜索、监测和应用分析**
   - 您可以分析特定事务的日志，监测运行该事务的主机或容器的性能指标，跟踪事务，检查整体服务可用性，等等 - **关联分析**

## Elastic

1. **Elastic Observability** 构建于 **Elastic Stack** 基础之上，有助于组织利用**搜索功能**将无限量遥测数据**关联**起来，以将数据转化为结果
2. 在单个**统一**的体验中，Elastic 可观测性可为 AWS、Microsoft Azure 和 Google Cloud 等**云环境**提供可见性，并为**无缝数据采集**构建提供了集成
3. 事实证明，Elastic 可观测性可将企业性能提升 10 倍，并节省 75% 的成本

# APM

## 含义

> APM（应用程序性能监测）是组织快速**识别和解决应用程序和代码中任何性能问题**的过程。

1. APM 解决方案可**收集**和**监测**来自各种网站、软件应用程序和服务的**遥测数据**，并对数据进行**分析**
2. 团队借此能够获得对应用程序的**端到端可见性**，进而理解应用程序和服务的**依赖关系**，并解决任何错误或速度变慢的问题
3. 此外，APM 解决方案还会存储并利用**历史数据**来揭示**趋势**，并对照**关键性能指标**（如延迟和吞吐量以及各项业务 KPI）检测**离群值**

## 作用

1. 应用程序性能监测能够对**应用程序的执行情况**提供**连续不断**的**详细见解**
2. 团队可以利用这些见解，更加**积极主动**地**解决问题**，而不是等到客户投诉了才有所行动
3. APM 有多种用途
   - 例如，团队可以针对**用户体验过程**中的**性能下降**设置**告警**，衡量最新版本的影响，并就哪些地方需要改进做出明智的决策
   - 此外，它还可以协助进行**根本原因分析**，以及**缩短**平均检测时间 (**MTTD**) 和平均解决时间 (**MTTR**)

## 重要性

1. 应用程序是现代组织的命脉，也是人们每天所用产品、服务和工具的门户，而且都变得越来越复杂
2. 随着**分布式**应用程序（**云原生技术**和**微服务**）的兴起，团队根本无法跟上**大量遥测数据**涌入的速度
3. 他们需要找到一种方法来**监测所有信息**，从而提供**卓越的用户体验**
4. APM 可确保应用程序按预期运行
   - 为了保持客户的信心，APM 工具可以提醒团队注意**潜在问题**，以便**快速解决**问题

## 发展历程

1. 自 **1990** 年代问世以来，APM 便为 IT 团队提供了全方位了解应用程序的能力
   - 这些年来，也有多家公司尝试过**分布式跟踪**
2. 但直到 **2010** 年代，市场上才出现功能更加强大的 **APM 解决方案**
   - 这些**平台解决方案**提供的**跟踪**和**端到端监测**功能的水平更高

## APM + 可观测性

1. 从表面上看，可观测性和 APM 有相似之处
   - 两者都使用**遥测技术**来收集数据，以及提供**性能**方面的**见解**
2. 尽管如此，**APM** 会更侧重于**应用程序（跟踪和监测事务）**，而**可观测性**则兼顾了**应用程序**和**基础架构**性能
   - **APM** - **应用程序**
   - **Observability** - **应用程序** + **基础架构**
3. 通过**可观测性**，可**深入挖掘技术细节**，从而**提高对系统的了解**
   - 它可以帮助团队通过**关联日志、指标和痕迹**，了解**性能问题**背后的**背景信息**和**根本原因**

## 工作原理

1. APM 会使用一套**工具**和**方法**来监测和管理软件应用程序的**性能**
2. APM 工具一般包括对**关键指标**（如响应时间、吞吐量和错误率）的监测，以此来**识别**和**诊断**性能瓶颈和问题
3. 此外，APM 工具还可以提供**详细**的**跟踪**和**故障排查信息**，协助开发人员了解和修复代码中的问题
4. 这通常包括**告警**和**报告**功能，以让**利益相关方**始终了解应用程序的**性能**

## Agent

1. 代理是指通常**装载于应用程序的软件**
2. 它负责**监测痕迹和遥测数据**，并将数据传输到 **APM 服务器**和/或其他监测工具
3. 代理可用来监测各种系统和应用程序
4. 您可以对代理进行配置，以收集有关**性能特定方面**的数据

## Instrumentation

1. Instrumentation 是向应用程序**添加监测代码**以**收集性能数据**的过程
2. 它可用于收集**响应时间**、**错误率**、**资源利用率**、**日志**等**指标**，以及应用程序在**运行状况**和**性能方面**的**其他关键指标**
3. Instrumentation 可以使用**供应商专用**的 **APM SDK** 或按照 **OpenTelemetry** 这类公开的标准**手动执行**，其中会使用**跨度**来设置**痕迹**的开始和停止时间
4. 另外，也可以使用**自动装载代码**的代理来实现
   - 安装代理后，团队可以对应用程序或事务的特定部分进行分析，然后将数据发送到终端（通常是 APM 平台）
5. 一般情况下，Instrumentation 是在工具的 **UI** 中或通过 **API** 进行设置的
   - 配置示例包括**环境名称**、**采样率**和**其他指标**

## 分析 + 告警

1. 在收集到**性能数据**后，便可进行分析了
2. 在选择工具时，请务必确保工具包含各种**仪表板**和**视图**，以便轻松跟踪用户体验，并快速发现错误和问题
3. 大多数团队都会围绕报告的**问题**开始调查，然后再努力确定**根本原因**
4. 使用平台来执行 APM 可避免中途更换工具的情况，您还可以设置告警，以避免将来出现问题

## 可衡量指标

| Metrics        | Desc                                                         |
| -------------- | ------------------------------------------------------------ |
| 服务器运行状况 | 监测服务器 CPU 使用情况、内存需求和读写速度                  |
| 错误率         | 跟踪性能下降情况并发现问题                                   |
| 响应时间       | 确定应用性能是否受到影响                                     |
| 实例           | 了解正在运行的服务器或应用实例的数量，以便有效进行扩展和管理总体成本 - 基于云的应用程序 |
| 请求率         | 评估用户流量，以了解出现峰值或用户不活跃的原因               |
| 可用性         | 跟踪应用程序的运行时间                                       |

## 优势

> 当应用程序停止工作时，最好能做到提前了解情况，以免给用户带来负面体验
> 借助 APM，可让团队快速识别和解决问题，甚至防止将来出现问题

1. 提高**稳定性**和增加**运行时间**
2. 减少**事件发生**
3. 更快地**解决问题**
4. 发布**高质量软件**
5. 发现**基础架构**需要改进的地方
6. 提高**工作效率**
7. 打造更好的**用户体验**
8. 增加**收入**

## 挑战

1. APM 工具并非没有挑战
   - 各团队需要处理的**实时数据流规模庞大**
   - 复杂的**分布式**应用程序（尤其是使用**云原生**技术的应用程序）可能会使 **APM Instrumentation** 成为一个挑战
   - 如果环境中存在问题或根本原因分析用例很复杂，则许多工具可能会难以应对
2. APM 解决方案需要**监测端到端事务**、**应用程序和代码级别的性能**，以帮助组织实现**全方位覆盖**
   - 只需**一个平台**就能做到**全面监测**，并能**简化工作流**和**加快问题解决速度**
   - 选择合适的 APM 解决方案非常重要，以便使用多种监测方法来实现业务目标

## 关键功能

1. 尽管有多种不同的 APM 解决方案能够监测端到端事务、应用程序和代码级别的性能，但重要的是，要选择一个符合您**当前和未来技术需求**的解决方案

## 技术能力

1. 跟踪**网站**和/或**应用程序**的性能
2. 映射和管理应用程序和服务**依赖关系**
3. 收集**分布式痕迹**以实现**端到端可见性**
4. 提供**实时用户监测**（**客户端**和**服务器**）
5. 将**应用性能**与**业务目标**联系起来
6. 运用 **Machine Learning** 和基于 **AI** 的分析技术
7. 支持多种**数据类型**、**数据源**和**语言**

## 端到端可见性

1. APM 数据能够让组织了解应用程序中**实际发生**的情况
   - 但是，您需要能够**有效地监测所有内容**，才能清楚地了解应用程序的工作方式
2. 由于**痕迹**展示的只是这个过程的一部分，因此 APM 工具应该更进一步，实现对**事务整个过程**的监测
   - 然后，再将痕迹联系起来，即可从**鸟瞰图**转入**代码级别**的问题
3. 端到端可见性也是 AIOps 的一个关键要素

## 集成

1. 通过与**第三方**服务和应用程序集成，可让您的 APM 工具**无缝融入**组织更大的生态系统中
2. 从**身份验证**到 **CI/CD 框架**，事先对这些集成进行**调查**是非常重要的

## 简单易用

1. 您的组织中会有许多人需要使用 APM 功能
2. 请提供**直观的用户界面**来满足他们的各项需求
   - 此外，还要验证部署、管理和扩展 APM 解决方案的**容易程度**

## 部署选项

1. 如果您希望降低**运营和管理成本**，则可以考虑基于云的 **SaaS** 选项
2. 但是，还有其他部署选项需要考虑
   - 虽然有些 APM 工具支持**多云**或**混合云**部署策略，但有些工具可能会因您**偏好的云提供商**而存在局限性

## 开放标准

1. 可观测性空间在不断发展，随着众多新工具和标准进入市场，您需要的是一个能够**灵活适应**的平台
2. 使用 **OpenTelemetry** 等开放标准和技术也有助于确保您的工具集适应未来的发展

## 安全性

1. 在评估工具时，请考虑供应商在**安全性**方面的承诺
2. APM 工具的构建和交付方式可能会**增强或削弱**您现有的**安全框架**
   - 各**组件之间**的**流量**应该**加密**
   - **第三方扩展**也可能带来**安全问题**
3. 另外，还要确保 APM 工具支持现有的具有**精细权限**的**身份访问管理**解决方案

## Elastic

1. 2023 年，Elastic 连续第三年在 **Gartner® APM** 和**可观测性 Magic Quadrant™** 中被评为有**远见者**
2. Elastic 通过**内置 APM 监测功能**，为公司打造**全堆栈可观测性**
   - 团队不需要使用多种工具，即可全方位查看自己负责的产品
3. 在**混合云**和**多云**环境中实现可见性
   - 通过提供对**云原生**技术（如 **Kubernetes** 和**无服务器**技术）的可观测性，加快数字化转型的步伐
   - Elastic 还提供对 **OpenTelemetry** 的**原生支持**
4. 加大**故障排查力度**并提高**效率**
   - 打破整个组织中的**孤岛**，并将**指标**、**日志**和**痕迹**信息整合在**一个视图**中，以便了解环境内部的情况
5. 强大的 **Machine Learning** 和**分析**
   - 使用创新的 **AIOps** 功能（例如 **APM 关联**和**异常检测**），为团队**自动执行根本原因分析**
6. **用户体验监测**
   - 通过真实用户监测 (**RUM**)，详细了解**用户**与**网站**的互动情况
   - 秉持**主动原则**，利用**合成监测**，先于客户发现网络性能问题

## 术语

### 分布式跟踪

1. 分布式跟踪是一种**跟踪**和**分析**从**应用程序前端**流经**后端服务**的请求和响应的方法
2. 它可以帮助团队了解应用程序不同部分的交互情况，并识别潜在的**瓶颈**或**问题**

![screenshot-what-is-apm-trace-sample](/Users/zhongmingmao/data/typora/screenshot-what-is-apm-trace-sample.png)

### 跨度

1. 跨度是**工作流**的一个个**组成部分**
2. 它们衡量的是从**活动开始到结束**的**全过程**，并包含**相关执行信息**
3. 常见的**跨度属性**包括 - 开始和完成时间 + 名称 + 类型

![screenshot-what-is-apm-http-request](/Users/zhongmingmao/data/typora/screenshot-what-is-apm-http-request.png)

### 事务

1. **事务**是与**逻辑工作单元**相对应的**事件**
2. 它们通常与**传入的请求**或**受监测服务的类似任务**相**关联**
3. 事务可以包含**多个跨度**以及其他**属性**，如有关记录事件的**环境**的数据
4. 事务的一些示例包括 - 对服务器的请求 + 批量作业 + 后台作业
5. 在 **APM 解决方案**中，事务通常是指 **Web 事务**
   - 包括从**提交请求**到**收到响应**的**所有活动**

### 痕迹

> **Traces**

1. **痕迹**是对应用程序所执行操作的**详细代码级的记录**
2. 它衡量的是与**应用程序请求**相关的**方法**或**函数调用**的**状态**和**持续时间**

### 服务

1. 服务是**独立软件**，用于执行特定任务或一组任务
2. 它们都会被设计为**松散耦合**和**高度可重用**，经常被用于**微服务架构**中
3. 服务通常使用**容器技术**部署，例如 **Docker** 和 **Kubernetes**

### OpenTelemetry

1. OpenTelemetry 是一个开源框架，用于从**应用程序**、**服务**和**库**中收集和导出**遥测数据**
2. 它提供了**装载代码**和**收集数据**所需的**库**和 **API**，以及用于**分析**、**可视化**和**存储数据**的工具和集成
3. OpenTelemetry 是一个对**供应商中立**的框架，并且**可扩展**。它被认为是**收集和导出遥测数据**的**标准**

# Elastic Observability

1. Rely on the **most widely deployed** observability solution
   - powered by **machine learning** and **analytics**, to converge **metrics**, **logs**, and **traces** that deliver **unified visibility** and **actionable insights**.
2. **Eliminate tool silos** and **efficiently store data**
3. Get **visibility** across **hybrid** and **multi-cloud** environments
4. Monitor your **digital experience** — 24/7

## APM

1. Monitor your **application performance**
   - Learn how to **collect** and **visualize** Application Performance Monitoring (**APM**) data with the **Elastic Stack**.
2. Monitor your **application logs**
   - **Correlate** your **application logs and traces** for **increased visibility** into your services.
3. Integrate with **OpenTelemetry**
   - Reuse your **existing OTel instrumentation** to easily send **observability data** to the **Elastic Stack**.

## Infrastructure

1. Get started
   - Learn how to monitor **logs** and **infrastructure metrics** from **systems** and **services** across your organization.
2. Integrations
   - Stream in and visualize **logs**, **metrics**, **traces**, **content**, and more from all the sources in your ecosystem.

## RUM

1. User experience
   - **Quantify** and **analyze** the **perceived performance** of your **web application**.
2. Monitor your users
   - Deploy the Elastic APM Real User Monitoring (RUM) **JavaScript Agent**
   - to add **detailed performance metrics** and **error tracking** of your **web applications**.
3. Integrate with your favorite framework
   - Easily integrate the RUM agent with **React**, **Angular**, and **Vue** applications.

## Logs

1. Get started
   - Learn how to monitor **logs** and **metrics** from systems and services across your organization.
2. Integrations
   - Stream in and visualize **logs**, **metrics**, **traces**, **content**, and more from all the sources in your ecosystem.

## Synthetic

1. Get started
   - Choose a method and create your first **synthetic monitor**.
2. Write a **synthetic test**
   - Write a synthetic test to check **critical actions** that an **end-user** might make on your site.
3. **Analyze data** from synthetic monitors
   - See a **high-level overview** of your **service's availability**, and **dig into details** to **diagnose** what caused downtime.

## Universal Profiling

1. Universal Profiling
   - Inspect, filter, and compare your data to gain **visibility** and **optimize performance**.
2. Get started
   - Set up Universal Profiling in Elastic Cloud and install your **host-agent**.

# Use cases

1. Cloud monitoring
   - **Cross-platform** and **multi-cloud** visibility and analytics.
2. **DevOps**
   - Observe your **entire software lifecycle** — from **development** to **production**.
   - CI/CD
     - Get **better visibility** into your **CI/CD pipelines**.
   - **ECS logging**
     - Leverage the **Elastic Common Schema logging libraries** to automatically link **application traces** to their **corresponding logs**.
3. **AIOps**
   - **Automate anomaly detection** and **accelerate root cause analysis**.
   - **Root cause analysis** with **logs**
     - Learn about Elastic’s **artificial intelligence for IT operations** and **machine learning capabilities for root cause analysis**.
   - **APM Correlations**
     - **Automatically identify** the **probable causes** of **slow** or **failed** transactions.
4. **User experience**
   - **Measure**, **gauge**, and **improve** your end users’ experience.
   - Scripting browser monitors
     - **Simulate critical user workflows** on a **regular interval** to **catch bugs** before your users report them.
   - User experience
     - Learn how to **track Core Web Vitals** and how to use them to **quantify** the **real-world user experience**.

# Get started

## Get started with your use case

> Learn how to **spin up** a **deployment** of our **hosted Elasticsearch Service** and use **Elastic Observability** to gain **deeper insight** into the **behavior** of your applications and systems.

![get-started](/Users/zhongmingmao/data/typora/get-started.svg)

1. Choose your source
   - Elastic integrates with **hundreds of data sources** for **unified visibility** across all your applications and systems.
2. Ingest your data
   - **Turn-key integrations** provide a **repeatable workflow** to **ingest data** from all your sources
   - you install an integration, configure it, and deploy an **agent** to **collect** your data
3. View your data
   - **Navigate seamlessly** between **Observabilty UIs and dashboards** to **identify and resolve problems** quickly
4. Customize
   - Expand your deployment and add features like **alerting** and **anomaly detection**

## Quickstarts

1. Our quickstarts **dramatically reduce** your **time-to-value** by offering a **fast path** to **ingest** and **visualize** your **Observability data**
2. Each quickstart provides
   - A highly opinionated, **fast path** to **data ingestion**
   - **Sensible configuration defaults** with **minimal configuration required**
   - **Auto-detection** of **logs** and **metrics** for **monitoring hosts**
   - Quick access to related **dashboards** and **visualizations**

## What is Elastic Observability?

1. Observability provides **granular insights and context** into the **behavior** of **applications** running in your environments.
   - It’s an **important part** of any system that you build and want to **monitor**.
   - Being able to **detect and fix root cause events quickly** within an **observable system** is a **minimum requirement** for any analyst.
2. Elastic Observability provides
   - a **single stack** to unify your **logs**, **infrastructure metrics**, **application traces**, **user experience data**, **synthetics**, and **universal profiling**.
   - **Ingest** your data **directly** to **Elasticsearch**, where you can further **process** and **enhance** the data, before **visualizing** it and adding **alerts** in Kibana.

![what-is-observability](/Users/zhongmingmao/data/typora/what-is-observability.svg)

### APM

1. **Instrument** your **code** and **collect performance data** and **errors** at runtime by installing **APM agents** like **Java**, **Go**, **.NET**, and many more.
2. On the Observability **Overview** page, the **Services** chart shows
   - the total number of **services** running within your environment
   - and the total number of **transactions per minute** that were captured by the **Elastic APM agent** instrumenting those services.
3. You can then **drill down** into the **Applications UI** by clicking **Show service inventory** to quickly find the **APM traces** for underlying services.

![apm](/Users/zhongmingmao/data/typora/apm.png)

### Infrastructure monitoring

1. Monitor **system and service metrics** from your **servers**, **Docker**, **Kubernetes**, **Prometheus**, and **other services and applications**.
2. On the Observability **Overview** page, the **Hosts** table shows your **top hosts** with the **most significant resource footprints**.
3. These **metrics** help you **evaluate host efficiency** and determine if **resource consumption** is **impacting end users**.
4. You can then **drill down into** the **Infrastructure app** by clicking **Show inventory**.
   - Here you can **monitor** and **filter** your data by **hosts**, **pods**, **containers**,or **EC2 instances**
   - and create **custom groupings** such as **availability zones** or **namespaces**.

![metrics-summary](/Users/zhongmingmao/data/typora/metrics-summary.png)

### RUM

1. **Quantify** and **analyze** the **perceived performance** of your **web application** with **User Experience data**, powered by the **APM RUM agent**.
2. On the Observability **Overview** page, the **User Experience** chart provides a **snapshot** of **core web vitals** for the service with the **most traffic**.
   - **drill down into** the **User Experience dashboard** by clicking **Show dashboard** too see data by **URL**, **operating system**, **browser**, and **location**.

![obs-overview-ue](/Users/zhongmingmao/data/typora/obs-overview-ue.png)

### Log monitoring

1. Analyze log data from your **hosts**, **services**, **Kubernetes**, **Apache**, and many more.
2. On the Observability **Overview** page, the **Log Events** chart helps you **detect** and **inspect** possible **log anomalies**
   - across each of your **ingested log sources** to determine if the **log rate** is **outside** of your **expected bounds**.
3. **drill down into** the **Logs app** by clicking **Show log stream** to view a **live stream** of your **logs**, and the filter, pin, or highlight the data you need.

![log-rate](/Users/zhongmingmao/data/typora/log-rate.png)

### Synthetic monitoring

1. **Simulate actions and requests** that an **end user** would **perform** on your site at **predefined intervals** and in a controlled environment. 
2. The end result is **rich**, **consistent**, and **repeatable** data that you can **trend** and **alert** on.

### Universal Profiling

1. Build **stack traces** to get **visibility** into your system without **application source code changes or instrumentation**.
2. Use **flamegraphs** to explore **system performance** and **identify** the **most expensive lines of code**
   - increase CPU resource efficiency, debug performance regressions, and reduce cloud spend.

### Alerting

1. **Stay aware** of **potential issues** in your environments with **Kibana’s alerting and actions feature**
   - that integrates with the **Logs app**, **Infrastructure app**, and **Applications UI**.
   - It provides a set of **built-in actions** and **specific threshold rules** and enables **central management** of **all rules** from Kibana Management.
2. On the Observability **Overview** page, the **Alerts** table provides a **snapshot** of **alerts occurring** within the **specified time frame**.
   - The table includes the **alert status**, when it was **last updated**, the **reason** for the alert, and more.
3. You can then see more **details** on these alerts by clicking **Show alerts**.

![alerts-overview](/Users/zhongmingmao/data/typora/alerts-overview.png)

## Hosts + Elastic Agent

1. In this quickstart guide, you’ll learn how to scan your **host** to detect and collect **logs** and **metrics**
   - then navigate to **dashboards** to **further analyze** and **explore** your **observability data**.
   - You’ll also learn how to get **value** out of your **observability data**.
2. To scan your host, you’ll run an auto-detection script that downloads and installs **Elastic Agent**
   - which is used to collect **observability data** from the **host** and send it to **Elastic**.
3. The script also **generates** an Elastic Agent **configuration** file that you can use with your existing **Infrastructure-as-Code** tooling.

### Prerequisites

1. An **Elasticsearch cluster** for **storing** and **searching** your data, and **Kibana** for **visualizing** and **managing** your data.
   - This quickstart is available for **all Elastic deployment models**.
2. To get started quickly, try out our hosted Elasticsearch Service on **Elastic Cloud**.
3. A user with the **superuser** built-in role or the **privileges** required to onboard data.
4. **Root privileges** on the host—required to run the **auto-detection script** used in this quickstart.

| Privileges | Desc                                                         |
| ---------- | ------------------------------------------------------------ |
| Cluster    | ['monitor', 'manage_own_api_key']                            |
| Index      | { names: ['logs-*-*', 'metrics-*-*'], privileges: ['auto_configure', 'create_doc'] } |
| Kibana     | { spaces: ['*'], feature: { fleet: ['all'], fleetv2: ['all'] } } |

### Limitations

1. The **auto-detection script** works on **Linux** and **MacOS** only. 
   - Support for the **lsof** command is also required if you want to **detect custom log files**.
2. If you’ve installed **Apache** or **Nginx** in a **non-standard location**
   - you’ll need to **specify log file paths manually** when you run the scan.
3. Because **Docker Desktop** runs in a **VM**, its **logs** are **not auto-detected**.

### Collect your data

1. In **Kibana**, go to the **Observability UI** and click **Add Data**.
2. Under **What do you want to monitor**? select **Host**, and then select **Elastic Agent: Logs & Metrics**.
3. Copy the install command.
   - download the **auto-detection script**, scan your system for **observability data**, and **install Elastic Agent**.
4. Open a terminal on the host you want to scan, and run the command.
5. Review the list of log files:
   - Enter **Y** to **ingest** all the log files listed.
   - Enter **n** to either **exclude log files** or **specify additional log paths**. Enter Y to confirm your selections.

![quickstart-monitor-hosts-entry-point](/Users/zhongmingmao/data/typora/quickstart-monitor-hosts-entry-point.png)

![image-20250303184753624](/Users/zhongmingmao/data/typora/image-20250303184753624.png)

> When the script is done, you’ll see a message like "Elastic Agent is configured and running."

![image-20250303191051592](/Users/zhongmingmao/data/typora/image-20250303191051592.png)

> Need to scan your host again?

1. The **auto-detection script** (auto_detect.sh) is downloaded to the **directory** where you ran the installation command.
2. You can **re-run** the script on the **same host** to detect additional logs.
3. The script will scan the host and **reconfigure Elastic Agent** with any additional logs that are found.
4. If the script **misses** any **custom logs**, you can **add** them **manually** by entering n after the script has finished scanning the host.

### Visualize your data

1. After installation is complete and all **relevant data** is flowing into Elastic
   - the Visualize your data section will show links to assets you can use to analyze your data.
2. Depending on what **type** of **observability data** was collected, the page may link to the following integration assets:

| Integration asset         | Description                                                  |
| ------------------------- | ------------------------------------------------------------ |
| Apache                    | **Prebuilt dashboard** for monitoring **Apache HTTP server health** using **error** and **access** log data. |
| Custom .log files         | **Logs Explorer** for analyzing custom logs.                 |
| Docker                    | **Prebuilt dashboard** for monitoring the **status** and **health** of **Docker containers**. |
| MySQL                     | **Prebuilt dashboard** for monitoring **MySQl server health** using **error** and **access** log data. |
| Nginx                     | **Prebuilt dashboard** for monitoring **Nginx server health** using **error** and **access** log data. |
| System                    | **Prebuilt dashboard** for monitoring **host status and health** using **system metrics**. |
| Other prebuilt dashboards | **Prebuilt dashboards** are also available for systems and services not described here<br />including **PostgreSQL**, **Redis**, **HAProxy**, **Kafka**, **RabbitMQ**, **Prometheus**, **Apache Tomcat**, and **MongoDB**. |

> For example, you can navigate the **Host overview** dashboard to explore **detailed metrics** about **system usage** and **throughput**. 
> **Metrics** that indicate a **possible problem** are **highlighted** in **red**.

![quickstart-host-overview](/Users/zhongmingmao/data/typora/quickstart-host-overview.png)

### Get value out of your data

1. After using the **dashboards** to **examine** your **data**
   - and **confirm** you’ve **ingested** all the host **logs** and **metrics** you want to monitor
   - you can use **Elastic Observability** to gain **deeper insight** into your data.
2. For **host monitoring**, the following **capabilities** and **features** are recommended:
   - In the **Infrastructure UI**, analyze and compare data collected from your hosts. You can also:
     - **Detect anomalies** for **memory usage** and **network traffic** on hosts.
     - **Create alerts** that notify you when **an anomaly is detected** or **a metric exceeds a given value**.
   - In the **Logs Explorer**
     - **search** and **filter** your log data, get information about the **structure** of log fields
     - and **display** your **findings** in a **visualization**.
     - **Monitor log data set quality** to find **degraded documents**.
     - **Run a pattern analysis** to find **patterns** in **unstructured log messages**.
     - **Create alerts** that notify you when an **Observability data** type **reaches** or **exceeds** a **given value**.
   - Use **machine learning** to apply **predictive analytics** to your data:
     - **Detect anomalies** by comparing **real-time** and **historical** data from different sources
       - to look for **unusual**, **problematic patterns**.
     - Analyze **log spikes and drops**.
     - **Detect change points** in your **time series data**.

![image-20250303200030028](/Users/zhongmingmao/data/typora/image-20250303200030028.png)

## Kubernetes + Elastic Agent

1. you’ll learn how to create the **Kubernetes resources** that are required to **monitor** your **cluster infrastructure**.
2. This new approach requires **minimal configuration** and provides you with an **easy setup** to **monitor** your **infrastructure**.
3. You no longer need to **download**, **install**, or **configure** the **Elastic Agent**
   - everything **happens automatically** when you run the **kubectl** command.
4. The **kubectl** command installs the **standalone Elastic Agent** in your **Kubernetes cluster**
   - downloads all the **Kubernetes resources** needed to collect **metrics** from the **cluster**, and sends it to Elastic.

### Prerequisites

1. A running **Kubernetes cluster**
2. **Kubectl**

### Collect your data

1. In Kibana, go to the **Observability UI** and click **Add Data**.
2. Under **What do you want to monitor**? select **Kubernetes**, and then select **Elastic Agent: Logs & Metrics**.
3. To install the Elastic Agent on your host, copy and run the install command.
   - You will use the **kubectl** command to **download** a **manifest file**
   - inject **user’s API key** generated by **Kibana**, and **create** the **Kubernetes resources**.
4. Go back to the **Add Observability Data** page.
   - There might be a **slight delay** before data is ingested.
   - When ready, you will see the message We are monitoring your cluster.
5. Click **Explore Kubernetes cluster** to navigate to **dashboards** and explore your data.

![quickstart-k8s-entry-point](/Users/zhongmingmao/data/typora/quickstart-k8s-entry-point.png)

![image-20250303201654286](/Users/zhongmingmao/data/typora/image-20250303201654286.png)

![image-20250303202149041](/Users/zhongmingmao/data/typora/image-20250303202149041.png)

### Visualize your data

1. After installation is complete and all **relevant data** is flowing into Elastic
2. the Visualize your data section allows you to access the **Kubernetes Cluster Overview dashboard** that can be used to monitor the **health** of the **cluster**.
3. Furthermore, you can access other useful **prebuilt dashboards** for **monitoring** Kubernetes **resources**
   - for example running pods per namespace, as well as the resources they consume, like CPU and memory.

![quickstart-k8s-overview](/Users/zhongmingmao/data/typora/quickstart-k8s-overview.png)

## Hosts + OpenTelemetry

1. This functionality is in **technical preview** and may be **changed** or **removed** in a **future release**.
2. Elastic will work to **fix any issues**, but features in technical preview are not subject to the **support SLA** of **official GA features**.
3. In this quickstart guide, you’ll learn how to monitor your hosts using the **Elastic Distribution** of **OpenTelemetry** (EDOT) **Collector**.
4. You’ll also learn how to use **Observability features** to gain **deeper insight** into your observability data after collecting it.

### Prerequisites

1. This quickstart is only available for **Linux** and **MacOS** systems.
2. A user with the **Admin** role or higher—required to **onboard system logs and metrics**.
3. **Root privileges** on the host—required to run the **OpenTelemetry collector** because of these components:
   - **hostmetrics** - receiver to read **all system metrics** (all processes, memory, etc.).
   - **filelog** - to allow the collector to **read any user or application log files**.

### Limitations

1. **Host network panels** do not display data in some **Elastic Observability UIs**
   - Due to an **upstream limitation**, `host.network.*` metrics are **not available** from **OpenTelemetry**
2. **Process state** is **unavailable** in **OpenTelemetry host metrics**
   - The `process.state` metric is **not present** and is assigned a **dummy value** of **Unknown** in the **State column** of the **host processes** table.
3. **Host OS version** and **operating system** may show as "**N/A**"
   - Although the **Elasticsearch exporter** processes **resource attributes**, it may **not populate these values**.
4. **Normalized Load data** is **missing** unless the **CPU scraper** is **enabled**
   - The `systm.load.cores` metric is **required** for the **Normalized Load** column in the Hosts table and the Normalized Load visualization in the host detailed view.
5. **MacOS** collectors do not support **CPU** and **disk** metrics
   - The hostmetrics receiver does not collect these metrics on MacOS, leaving related fields **empty**.
6. **Permission issues** may cause **error logs** for **process** metrics
   - The hostmetrics receiver **logs errors** if it cannot **access certain process information** due to **insufficient permissions**.
7. **Mapping errors** appear **temporarily** in the console
   - **Initial mapping errors** occur until the system **completes** the **mapping process**.

### Collect your data

> Follow these steps to collect **logs** and **metrics** using the **EDOT** Collector:

1. In **Kibana**, go to the **Observability UI** and click **Add Data**.
2. Under **What do you want to monitor**? select **Host**, and then select **OpenTelemetry: Logs & Metrics**.
3. Select the appropriate platform.
4. Copy the command under step 1, open a terminal on your host, and run the command.
   - This command downloads the **Elastic Agent package**, extracts it in a **EDOT** directory. 
     - For example, elastic-distro-8.17.2-darwin-aarch64
   - It also adds a sample **otel.yml** configuration file to the directory and updates the **storage directory**, **Elastic endpoint**, and **API key** in the file.
   - The **default log path** is `/var/log/*.log`. To update the path, modify the **otel.yml** in the EDOT directory.
   - Find additional sample **otel.yml** configuration files in the **EDOT** directory in the **otel_samples** folder.
5. Copy the command under Step 2 and run it in your terminal to start the **EDOT Collector**.
6. Logs are collected from setup onward, so you won’t see logs that occurred before starting the EDOT Collector.
7. Under Visualize your data, you’ll see links to **Logs Explorer** to **view your logs** and **Hosts** to **view your host metrics**.

![quickstart-monitor-hosts-otel-entry-point](/Users/zhongmingmao/data/typora/quickstart-monitor-hosts-otel-entry-point.png)

## Kubernetes + OpenTelemetry

1. This functionality is in **technical preview** and may be **changed** or **removed** in a future release.
2. Elastic will work to **fix any issues**, but features in technical preview are **not subject** to the **support SLA** of official **GA** features.
3. In this quickstart guide, you’ll learn how to send Kubernetes **logs**, **metrics**, and **application traces** to **Elasticsearch**
   - using the **OpenTelemetry Operator** to orchestrate Elastic Distributions of OpenTelemetry (**EDOT**) Collectors and SDK instances.
   - All the components will be deployed through the **opentelemetry-kube-stack** helm chart.
     - OpenTelemetry **Operator**
     - **DaemonSet** - EDOT **Collector** configured for **node level metrics**
     - **Deployment** - EDOT **Collector** configured for **cluster level metrics**.
     - **Instrumentation** object for **applications auto-instrumentation**.

### Prerequisites

1. A running **Kubernetes cluster** (**v1.23** or newer).
2. Kubectl
3. Helm
4. (optional) Cert-manager, if you opt for automatic **generation** and **renewal** of **TLS certificates**.

### Collect your data

1. In Kibana, go to the **Observability UI** and click **Add Data**.
2. Under **What do you want to monitor**? select **Kubernetes**, and then select **OpenTelemetry: Full Observability**.

![quickstart-k8s-otel-entry-point](/Users/zhongmingmao/data/typora/quickstart-k8s-otel-entry-point.png)

> Add the OpenTelemetry repository to Helm

```
helm repo add open-telemetry 'https://open-telemetry.github.io/opentelemetry-helm-charts' --force-update
```

> Install the **OpenTelemetry Operator**

1. Install the OpenTelemetry Operator using the **kube-stack** Helm chart and the provided values file.
2. For **automatic certificate renewal**, we recommend installing the **cert-manager**
3. Follow the on-screen instructions to install all needed components.
   - The **default installation** deploys the **OpenTelemetry Operator** with a **self-signed TLS** certificate valid for **365** days.
   - This certificate won’t be **renewed** unless the **Helm Chart release** is **manually updated**.
   - Refer to the **cert-manager** integrated installation guide
     - to enable **automatic certificate generation and renewal** using cert-manager.
4. Deploy the **OpenTelemetry Operator** and **EDOT Collectors** using the **kube-stack** Helm chart with the provided values.yaml file.
   - Add the **helm chart repository** needed for the installation.
   - Create a **namespace**.
   - Create a **secret** with an **API Key** and the **Elasticsearch endpoint** to be used by the collectors.
   - Install the **opentelemetry-kube-stack** helm chart with the provided **values.yaml**.
   - Optionally, for **instrumenting applications**, apply the corresponding **annotations** as shown in Kibana.

```
kubectl create namespace opentelemetry-operator-system
kubectl create secret generic elastic-secret-otel \
  --namespace opentelemetry-operator-system \
  --from-literal=elastic_endpoint='https://xxxx.us-central1.gcp.cloud.es.io:443' \
  --from-literal=elastic_api_key='xxx'
helm install opentelemetry-kube-stack open-telemetry/opentelemetry-kube-stack \
  --namespace opentelemetry-operator-system \
  --values 'https://raw.githubusercontent.com/elastic/opentelemetry/refs/heads/8.16/resources/kubernetes/operator/helm/values.yaml' \
  --version '0.3.3'
```

![image-20250304113251992](/Users/zhongmingmao/data/typora/image-20250304113251992.png)

![image-20250304113800311](/Users/zhongmingmao/data/typora/image-20250304113800311.png)

> **Instrument** your **application** (optional)

1. Enable **automatic instrumentation** for your **applications** by **annotating the pods template**
2. (spec.template.metadata.annotations) in your **Deployment** or relevant workload object (**StatefulSet**, **Job**, **CronJob**, etc.)

> Node.js

```yaml
# To annotate specific deployment Pods modify its manifest
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  ...
  template:
    metadata:
      annotations:
        instrumentation.opentelemetry.io/inject-nodejs: "opentelemetry-operator-system/elastic-instrumentation"
      ...
    spec:
      containers:
      - image: myapplication-image
        name: app
      ...

# To annotate all resources in a namespace
kubectl annotate namespace my-namespace instrumentation.opentelemetry.io/inject-nodejs="opentelemetry-operator-system/elastic-instrumentation"

# Restart your deployment
kubectl rollout restart deployment myapp -n my-namespace

# Check annotations have been applied correctly and auto-instrumentation library is injected
kubectl describe pod <myapp-pod-name> -n my-namespace
```

> Java

```yaml
# To annotate specific deployment Pods modify its manifest
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  ...
  template:
    metadata:
      annotations:
        instrumentation.opentelemetry.io/inject-java: "opentelemetry-operator-system/elastic-instrumentation"
      ...
    spec:
      containers:
      - image: myapplication-image
        name: app
      ...

# To annotate all resources in a namespace
kubectl annotate namespace my-namespace instrumentation.opentelemetry.io/inject-java="opentelemetry-operator-system/elastic-instrumentation"

# Restart your deployment
kubectl rollout restart deployment myapp -n my-namespace

# Check annotations have been applied correctly and auto-instrumentation library is injected
kubectl describe pod <myapp-pod-name> -n my-namespace
```

> Python

```yaml
# To annotate specific deployment Pods modify its manifest
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  ...
  template:
    metadata:
      annotations:
        instrumentation.opentelemetry.io/inject-python: "opentelemetry-operator-system/elastic-instrumentation"
      ...
    spec:
      containers:
      - image: myapplication-image
        name: app
      ...

# To annotate all resources in a namespace
kubectl annotate namespace my-namespace instrumentation.opentelemetry.io/inject-python="opentelemetry-operator-system/elastic-instrumentation"

# Restart your deployment
kubectl rollout restart deployment myapp -n my-namespace

# Check annotations have been applied correctly and auto-instrumentation library is injected
kubectl describe pod <myapp-pod-name> -n my-namespace
```

> .NET

```yaml
# To annotate specific deployment Pods modify its manifest
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  ...
  template:
    metadata:
      annotations:
        instrumentation.opentelemetry.io/inject-dotnet: "opentelemetry-operator-system/elastic-instrumentation"
      ...
    spec:
      containers:
      - image: myapplication-image
        name: app
      ...

# To annotate all resources in a namespace
kubectl annotate namespace my-namespace instrumentation.opentelemetry.io/inject-dotnet="opentelemetry-operator-system/elastic-instrumentation"

# Restart your deployment
kubectl rollout restart deployment myapp -n my-namespace

# Check annotations have been applied correctly and auto-instrumentation library is injected
kubectl describe pod <myapp-pod-name> -n my-namespace
```

> Go

```yaml
# To annotate specific deployment Pods modify its manifest
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  ...
  template:
    metadata:
      annotations:
        instrumentation.opentelemetry.io/inject-go: "opentelemetry-operator-system/elastic-instrumentation"
      ...
    spec:
      containers:
      - image: myapplication-image
        name: app
      ...

# To annotate all resources in a namespace
kubectl annotate namespace my-namespace instrumentation.opentelemetry.io/inject-go="opentelemetry-operator-system/elastic-instrumentation"

# Restart your deployment
kubectl rollout restart deployment myapp -n my-namespace

# Check annotations have been applied correctly and auto-instrumentation library is injected
kubectl describe pod <myapp-pod-name> -n my-namespace
```

### Visualize your data

1. After installation is complete and all **relevant data** is flowing into Elastic
2. the Visualize your data section provides a link to the `[OTEL][Metrics Kubernetes]Cluster Overview` dashboard used to monitor the **health** of the **cluster**.

![quickstart-k8s-otel-dashboard](/Users/zhongmingmao/data/typora/quickstart-k8s-otel-dashboard.png)

### Troubleshooting and more

1. To troubleshoot **deployment** and **installation**, refer to installation verification.
2. For **application instrumentation** details, refer to Instrumenting applications with **EDOT SDKs** on **Kubernetes**.

# Application and service monitoring

> learn how to observe and monitor **software applications** and **services** running in your environment.

1. Application performance monitoring (**APM**)
   - Monitor software services and applications in **real time**
   - by collecting **detailed performance information**
     - on response time for incoming requests, database queries, calls to caches, external HTTP requests, and more.
2. **Synthetic monitoring**
   - Monitor the **availability** of **network endpoints** and **services**.
3. Real user monitoring (**RUM**)
   - **Quantify** and **analyze** the **perceived performance** of your **web application** using **real-world user experiences**.
4. **Uptime** monitoring (deprecated)
   - Periodically check the **status** of your **services** and **applications**.
5. Tutorial: **Monitor a Java application**
   - Monitor a Java application using Elastic Observability: **Logs**, **Infrastructure metrics**, **APM**, and **Uptime**.

## APM

1. Elastic APM is an **application performance monitoring system** built on the **Elastic Stack**.
2. It allows you to monitor software services and applications in **real time**
   - by collecting **detailed performance information**
     - on response time for incoming requests, database queries, calls to caches, external HTTP requests, and more.
   - This makes it easy to **pinpoint and fix performance problems quickly**.

![apm-app-landing](/Users/zhongmingmao/data/typora/apm-app-landing.png)

1. Elastic APM also **automatically** collects **unhandled errors and exceptions**.
2. **Errors** are **grouped** based primarily on the **stack trace**
   - so you can **identify new errors as they appear** and keep an eye on **how many times specific errors happen**.
3. **Metrics** are another vital source of information when **debugging production systems**.
   - Elastic APM agents **automatically** pick up basic **host-level metrics** and **agent-specific metrics**, like **JVM metrics** in the Java Agent, and **Go runtime metrics** in the Go Agent.

### Get started with APM

1. Starting in version **8.15.0**
   - the Elasticsearch **apm-data plugin** manages **APM index templates, lifecycle policies, and ingest pipelines**.
2. The **APM Server** receives **performance data** from your **APM agents**
   - **validates** and **processes** it, and then **transforms** the data into **Elasticsearch documents**.
3. If you’re on this page, then you’ve chosen to **self-manage** the **Elastic Stack**
   - and you now must decide how to **run** and **configure** the **APM Server**.
4. There are two options, and the **components** required are **different** for each:
   - **Fleet-managed APM Server**
   - **APM Server binary**

> Fleet-managed APM Server

![fm-ov](/Users/zhongmingmao/data/typora/fm-ov.png)

1. Fleet is a **web-based UI** in **Kibana** that is used to **centrally manage Elastic Agents**.
2. In this deployment model
   - use **Elastic Agent** to spin up **APM Server instances** that can be **centrally-managed** in a **custom-curated user interface**.

| Key                  | Value                                                        |
| -------------------- | ------------------------------------------------------------ |
| Pros                 | Conveniently manage one, some, or many different integrations from one **central Fleet UI**.<br />**Centrally** manage **multiple APM Servers** running on edge machines. |
| Supported outputs    | **Elasticsearch** + **Elasticsearch Service**<br />**not** support **all** the outputs that are supported by the APM Server **binary** method of running Elastic APM. |
| Required components  | **APM agents**<br />**Elastic Agent** (which runs multiple subprocesses including <u>APM Server</u>, <u>Fleet Server</u>, and <u>Elastic Stack</u>) |
| Configuration method | **Kibana UI**                                                |

> APM Server binary - Install, configure, and run the APM Server binary **wherever** you need it.

![bin-ov](/Users/zhongmingmao/data/typora/bin-ov.png)

| Key                  | Value                                                        |
| -------------------- | ------------------------------------------------------------ |
| Pros                 | **Simplest** self-managed option<br />**No addition component** knowledge required<br />**YAML** configuration simplifies **automation** |
| Supported outputs    | Elasticsearch<br />Elasticsearch Service<br />Logstash<br />Kafka<br />Redis<br />File<br />Console |
| Required components  | APM agents<br />APM Server<br />Elastic Stack                |
| Configuration method | **YAML**                                                     |

> Help me decide - **APM Server binary**

1. This decision **tree highlights key factors** to help you make an informed decision about implementing Elastic APM.
2. It provides **practical guidance** and is not intended to serve as a **comprehensive reference** of all possible implementations and capabilities.

![image-20250304122415182](/Users/zhongmingmao/data/typora/image-20250304122415182.png)

#### Fleet-managed APM Server

##### Prerequisites

1. You need **Elasticsearch** for **storing** and **searching** your data, and **Kibana** for **visualizing** and **managing** it.
2. **Elasticsearch cluster** and **Kibana** (version **8.17**) with a **basic license** or higher.
3. **Secure, encrypted connection** between **Kibana** and **Elasticsearch**.
4. **Internet connection** for **Kibana** to **download integration packages** from the **Elastic Package Registry**. 
   - Make sure the **Kibana server** can connect to https://epr.elastic.co on port 443.
5. **Kibana user** with **All privileges** on **Fleet** and **Integrations**.
   - Since many **Integrations assets** are **shared across spaces**, users need the **Kibana privileges** in **all spaces**.
6. In the **Elasticsearch** configuration, the **built-in API key service** must be enabled. (**xpack.security.authc.api_key.enabled: true**)
7. In the **Kibana** configuration, the **saved objects encryption key** must be set
   - **Fleet** requires this setting in order to **save API keys** and **encrypt** them in **Kibana**. 
   - You can either set **xpack.encryptedSavedObjects.encryptionKey** to an **alphanumeric** value of **at least 32 characters**
     - or run the **kibana-encryption-keys** command to **generate the key.**

> Example security settings

1. For **testing purposes**, you can use the following settings to get started quickly
2. but make sure you properly **secure** the **Elastic Stack** before sending real data.

> **elasticsearch.yml** example:

```yaml
xpack.security.enabled: true
xpack.security.authc.api_key.enabled: true
```

> **kibana.yml** example:
> The **password** should be **stored** in the **Kibana keystore** as described in the **Elasticsearch security documentation**.

```yaml
elasticsearch.username: "kibana_system" 
xpack.encryptedSavedObjects.encryptionKey: "something_at_least_32_characters"
```

##### Step 1: Set up Fleet

1. Use **Fleet** in **Kibana** to get **APM data** into the **Elastic Stack**.
2. The first time you use Fleet, you’ll need to set it up and add a **Fleet Server** using the steps outlined below.
3. To deploy a **self-managed Fleet Server**
   - you install an **Elastic Agent** and **enroll** it in an **agent policy** containing the **Fleet Server integration**.
4. You can install only a **single Elastic Agent** per **host**
   - which means you **cannot** run **Fleet Server** and **another Elastic Agent** on the **same host**
     - unless you deploy a **containerized Fleet Server**.
5. In Fleet, open the **Settings** tab. For more information about these settings, see Fleet settings.
6. Under **Fleet Server hosts**
   - click **Edit hosts** and specify one or more **host URLs** your **Elastic Agents** will use to connect to **Fleet Server**.
   - For example, https://192.0.2.1:8220, where 192.0.2.1 is the host IP where you will install **Fleet Server**.
7. In the **Elasticsearch hosts** field, specify the **Elasticsearch URLs** where **Elastic Agents** will **send data**
   - For example, https://192.0.2.0:9200.
   - Skip this step if you’ve started the Elastic Stack with **security enabled**
     - you **cannot change** this setting because it’s **managed outside of Fleet**
8. Click the **Agents** tab and follow the in-product instructions to add a Fleet server:

![image-20250304140325476](/Users/zhongmingmao/data/typora/image-20250304140325476.png)

1. Choose **Quick Start** if you want **Fleet** to **generate a Fleet Server policy** and **enrollment token** for you.
   - The **Fleet Server policy** will include a **Fleet Server integration** plus a **system integration** for **monitoring Elastic Agent**.
   - This option **generates self-signed certificates** and is **not recommended** for **production use cases**.
2. Choose **Advanced** if you want to either
   - Use your own **Fleet Server policy**.
     - You can **create** a new Fleet Server policy or **select** an **existing** one.
   - Use your own **TLS certificates** to **encrypt traffic** between **Elastic Agents** and **Fleet Server**.
3. It’s recommended you **generate** a **unique service token** for **each Fleet Server**.
4. If you are providing your **own certificates**:
   - Before running the **install** command, make sure you **replace** the values in **angle brackets**.
   - Note that the **URL** specified by **--url** must match the **DNS name** used to **generate** the **certificate** specified by **--fleet-server-cert**.
5. The **install** command installs the **Elastic Agent** as a **managed service** and **enrolls** it in a **Fleet Server policy**.
6. If installation is successful, you’ll see **confirmation** that **Fleet Server connected**.
   - Click Continue **enrolling Elastic Agent** to begin **enrolling** your **agents** in **Fleet Server**.
7. If you’re unable to add a **Fleet-managed agent**, click the **Agents** tab and confirm that the agent running **Fleet Server** is **healthy**.

![image-20250304141223421](/Users/zhongmingmao/data/typora/image-20250304141223421.png)

```
curl -L -O https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.17.2-darwin-aarch64.tar.gz
tar xzvf elastic-agent-8.17.2-darwin-aarch64.tar.gz
cd elastic-agent-8.17.2-darwin-aarch64
sudo ./elastic-agent install \
  --fleet-server-es=https://xxx.us-central1.gcp.cloud.es.io:443 \
  --fleet-server-service-token=xxx \
  --fleet-server-policy=fleet-server-policy \
  --fleet-server-port=8220
```

![image-20250304142848146](/Users/zhongmingmao/data/typora/image-20250304142848146.png)

![image-20250304142929833](/Users/zhongmingmao/data/typora/image-20250304142929833.png)

![image-20250304143051116](/Users/zhongmingmao/data/typora/image-20250304143051116.png)

![image-20250304143213945](/Users/zhongmingmao/data/typora/image-20250304143213945.png)

![image-20250304143241798](/Users/zhongmingmao/data/typora/image-20250304143241798.png)

![image-20250304143438503](/Users/zhongmingmao/data/typora/image-20250304143438503.png)

##### Step 2: Add and configure the APM integration

1. If you don’t have a Fleet setup already in place
   - the easiest way to get started is to run the **APM integration** in the **same Elastic Agent** that acts as the **Fleet Server**.
2. In **Kibana**, find **Integrations** in the main menu or use the global search field.
3. Select **Elastic APM**.
4. Click **Add Elastic APM**.

![image-20250304143612187](/Users/zhongmingmao/data/typora/image-20250304143612187.png)

![image-20250304143858777](/Users/zhongmingmao/data/typora/image-20250304143858777.png)

![image-20250304144016234](/Users/zhongmingmao/data/typora/image-20250304144016234.png)

1. On the **Add Elastic APM integration** page
   - define the **host** and **port** where **APM Server** will **listen**. Make a note of this value—you’ll need it later.
   - Using **Docker** or **Kubernetes**? Set the host to **0.0.0.0** to bind to **all interfaces**.
2. Under **Agent authorization**, set a **Secret token**.
   - This will be used to **authorize requests** from **APM agents** to the **APM Server**. Make a note of this value—you’ll need it later.
3. Click **Save and continue**. 
   - This step takes a minute or two to complete.
   - When it’s done, you’ll have an **agent policy** that contains an **APM integration policy** for the configuration you just specified.
4. To view the new policy, click **Agent policy 1**.

![image-20250304145158272](/Users/zhongmingmao/data/typora/image-20250304145158272.png)

1. Any **Elastic Agents** assigned to this **policy** will collect **APM data** from your **instrumented services**.
2. An **internet connection** is required to **install the APM integration** via the **Fleet UI** in **Kibana**.

##### Step 3: Install APM agents

1. **APM agents** are written in the **same language** as your **service**.
2. To **monitor** a new service, you must **install the agent** and configure it with a **service name**, **APM Server host**, and **Secret token**.
3. **Service name**
   - The APM integration maps an **instrumented service’s name**–defined in each **APM agent’s configuration**
     - to the **index** that its **data** is stored in **Elasticsearch**. 
   - **Service names** are **case-insensitive** and must be **unique**.
     - For example, you cannot have a service named **Foo** and another named **foo**.
   - **Special characters** will be **removed** from service names and replaced with **underscores** (_).
4. **APM Server URL**
   - The **host** and **port** that **APM Server** listens for **events** on. 
   - This should match the host and port defined when setting up the **APM integration**.
5. **Secret token**
   - Authentication method for **APM agent** and **APM Server** communication.
   - This should match the secret token defined when setting up the **APM integration**.
6. Edit your APM integration settings if you need to change the **APM Server URL** or **secret token** to match your APM agents.

![image-20250304151651299](/Users/zhongmingmao/data/typora/image-20250304151651299.png)

![image-20250304151746186](/Users/zhongmingmao/data/typora/image-20250304151746186.png)

![image-20250304160612694](/Users/zhongmingmao/data/typora/image-20250304160612694.png)

![image-20250304160727621](/Users/zhongmingmao/data/typora/image-20250304160727621.png)

> Java

1. Manually set up and configure the agent with the **-javaagent** JVM option.
2. **No application code change** is required, but this requires an application **restart**.
3. Download the APM agent
4. The first step in getting started with the **Elastic APM Java agent** is to retrieve a copy of the **agent JAR**.
5. Java agent releases are published to **Maven central**.
6. Add -javaagent flag
   - When starting your application, add the **JVM** flag `-javaagent:/path/to/elastic-apm-agent-<version>.jar`
7. Different application servers have different ways of setting the **-javaagent** flag and **system properties**.
   - Start your application (for example a Spring Boot application or other embedded servers) and add the **-javaagent** JVM flag.
   - Use the **-D** prefix to **configure the agent** using **system properties**

```
java -javaagent:elastic-apm-agent-1.52.2.jar \
-Delastic.apm.service_name=my-cool-service \
-Delastic.apm.application_packages=org.example,org.another.example \
-Delastic.apm.server_url=https://xxx.apm.us-central1.gcp.cloud.es.io:443 \
-Delastic.apm.secret_token=xxx \
-jar math-game.jar
```

1. Automatic setup with **apm-agent-attach-cli.jar**
   - Automatically set up the agent without needing to **alter the configuration** of your **JVM** or application server.
   - This method requires **no changes** to **application code** or **JVM options**, and allows attaching to a running JVM.
2. **Programmatic API** setup to **self-attach**
   - Set up the agent with a **one-line code change** and an **extra apm-agent-attach dependency**.
   - This method requires **no changes** to **JVM** options
     - and the **agent artifact** is **embedded** within the **packaged application binary**.

##### Step 4: View your data

1. Back in **Kibana**, under **Observability**, select **APM**.
2. You should see **application performance** monitoring data flowing into the Elastic Stack!

![kibana-apm-sample-data](/Users/zhongmingmao/data/typora/kibana-apm-sample-data.png)

#### APM Server binary

##### Prerequisites

1. First, see the **Elastic Support Matrix** for information about **supported operating systems** and **product compatibility**.
   - **Elasticsearch** for **storing** and **indexing** data.
   - **Kibana** for **visualizing** with the Applications UI.
2. We recommend you use the **same version** of **Elasticsearch**, **Kibana**, and **APM Server**. 

![apm-architecture-diy](/Users/zhongmingmao/data/typora/apm-architecture-diy.png)

##### Step 1: Install

```
curl -L -O https://artifacts.elastic.co/downloads/apm-server/apm-server-8.17.2-darwin-x86_64.tar.gz
tar xzvf apm-server-8.17.2-darwin-x86_64.tar.gz
```

##### Step 2: Set up and configure

1. Configure APM by editing the **apm-server.yml** configuration file.
2. The **location** of this file varies by **platform**

> A minimal configuration file might look like this:

```yaml
apm-server:
  host: "localhost:8200" 
output.elasticsearch:
  hosts: ["localhost:9200"] 
  username: "elastic" 
  password: "changeme"
```

1. The **host:port** APM Server listens on.
2. The Elasticsearch **host:port** to connect to.
3. This example uses **basic authentication**.
   - The user provided here needs the **privileges required** to **publish events** to **Elasticsearch**.

##### Step 3: Start

1. In a **production** environment, you would put **APM Server** on its **own machines**, similar to how you run **Elasticsearch**.
2. You can run it on the **same machines** as **Elasticsearch**
   - but this is **not recommended**, as the **processes** will be **competing** for **resources**.

> To start APM Server, run:

```
./apm-server -e
```

1. The **-e** global flag enables **logging to stderr** and **disables syslog/file output**.
2. Remove this flag if you’ve **enabled logging** in the configuration file.
3. You should see APM Server start up.
   - It will try to **connect to Elasticsearch** on localhost port 9200 and **expose an API** to **agents** on port **8200**.

##### Step 4: Install APM agents

> OpenTelemetry

1. **Elastic** integrates with **OpenTelemetry**
2. allowing you to **reuse** your **existing instrumentation** to easily send **observability data** to the Elastic Stack.

```
java -javaagent:elastic-apm-agent-1.52.2.jar \
-Delastic.apm.service_name=my-cool-service \
-Delastic.apm.application_packages=org.example,org.another.example \
-Delastic.apm.server_url=http://127.0.0.1:8200 \
-jar math-game.jar
```

##### Step 5: View your data

![bin-ov](/Users/zhongmingmao/data/typora/bin-ov.png)

1. Once you have at least one **APM agent** sending data to **APM Server**
2. you can start **visualizing** your data in the **Kibana Applications UI**.

![image-20250304184150506](/Users/zhongmingmao/data/typora/image-20250304184150506.png)

##### Run APM Server on Docker

1. Docker images for APM Server are available from the **Elastic Docker registry**. The base image is **ubuntu:22.04**.
2. These images are **free to use** under the **Elastic license**.
   - They contain **open source and free commercial features** and access to **paid commercial features**.
   - Start a **30-day trial** to try out **all** of the **paid commercial features**.

> https://www.elastic.co/subscriptions

![image-20250304184922431](/Users/zhongmingmao/data/typora/image-20250304184922431.png)

![image-20250304185209263](/Users/zhongmingmao/data/typora/image-20250304185209263.png)

![image-20250304185352118](/Users/zhongmingmao/data/typora/image-20250304185352118.png)

![image-20250304185542190](/Users/zhongmingmao/data/typora/image-20250304185542190.png)

![image-20250304185629038](/Users/zhongmingmao/data/typora/image-20250304185629038.png)

![image-20250304185804112](/Users/zhongmingmao/data/typora/image-20250304185804112.png)

![image-20250304185829237](/Users/zhongmingmao/data/typora/image-20250304185829237.png)

> Pull the Docker image:

```
docker pull docker.elastic.co/apm/apm-server:8.17.2
```

> Verify the Docker image:

```
wget https://artifacts.elastic.co/cosign.pub
cosign verify --key cosign.pub docker.elastic.co/apm/apm-server:8.17.2
```

![image-20250304190448641](/Users/zhongmingmao/data/typora/image-20250304190448641.png)

1. The Docker image provides several methods for **configuring** APM Server. 
2. The conventional approach is to provide a **configuration file** via a **volume mount**
   - but it’s also possible to create a custom image with your configuration included.

> Download this example configuration file as a starting point:

```
curl -L -O https://raw.githubusercontent.com/elastic/apm-server/8.17/apm-server.docker.yml
```

1. One way to configure APM Server on Docker is to provide **apm-server.docker.yml** via a **volume** mount.
2. With docker run, the volume mount can be specified like this.

```
docker run -d \
  -p 8200:8200 \
  --name=apm-server \
  --user=apm-server \
  --volume="$(pwd)/apm-server.docker.yml:/usr/share/apm-server/apm-server.yml:ro" \
  docker.elastic.co/apm/apm-server:8.17.2 \
  --strict.perms=false -e \
  -E output.elasticsearch.hosts=["elasticsearch:9200"]  
```

1. Substitute your **Elasticsearch hosts and ports**.
2. If you are using the **hosted Elasticsearch Service** in **Elastic Cloud**
   - replace the -E **output.elasticsearch.hosts** line with the **Cloud ID** and **elastic password** using the syntax shown earlier.

> It’s possible to **embed** your **APM Server configuration** in a **custom image**. Here is an example Dockerfile to achieve this:

```dockerfile
FROM docker.elastic.co/apm/apm-server:8.17.2
COPY --chmod=0644 --chown=1000:1000 apm-server.yml /usr/share/apm-server/apm-server.yml
```

### Application data types

1. **Elastic APM agents** capture **different types** of **information** from within their **instrumented applications**.

2. These are known as **events**, and can be **spans**, **transactions**, **traces**, **errors**, or **metrics**.

3. Elastic APM helps you see what happens **from start to finish** when a **request** is made to an **application**:

   - **Spans**
     - A span contain **information** about the **execution** of a **specific code path**.
     - They are the **building blocks** of **transactions** and **traces**.
   - **Transactions**
     - A transaction describes an **event** captured by an **Elastic APM agent** instrumenting a service.
     - A transaction is technically a type of **span** that has **additional attributes** associated with it
       - and often contains **multiple child spans**.
     - You can think of transactions as the **highest level** of **work** you’re measuring within a service.
   - **Traces**
     - A trace is **a group of transactions and spans** with a **common root**.
     - Each trace **tracks** the **entirety** of a **single request**. 
     - When a trace travels through **multiple services**, it is known as a **distributed trace**.

   ![spans-transactions-and-traces](/Users/zhongmingmao/data/typora/spans-transactions-and-traces.png)

   > In addition to the building blocks of traces, Elastic APM agents also capture:

4. **Errors**

   - An error is created when **something goes wrong** with a **request** to an application.

   - This event contains information to help you **determine where and why** an error occurred
     - often including in **which transaction** the error occurred.

5. **Metrics**

   - Metrics measure the **state of a system** by **gathering information** on a **regular interval**.

6. **Events** can contain **additional metadata** which further **enriches** your data.

#### Spans

1. Spans contain **information** about the **execution** of a **specific code path**.
2. They measure **from the start to the end** of an **activity**, and they can have a **parent/child relationship** with **other spans**.
3. **Agents automatically instrument** a variety of **libraries** to capture these spans from within your application
   - but you can also use the **Agent API** for **custom instrumentation** of **specific code paths**.
4. Among other things, spans can contain
   - A **transaction.id** attribute that refers to its **parent transaction**.
   - A **parent.id** attribute that refers to its **parent span or transaction**.
   - Its **start time** and **duration**.
   - A **name**, **type**, **subtype**, and **action**
   - An optional **stack trace**.
     - Stack traces consist of **stack frames**, which represent a **function call** on the **call stack**.
     - They include attributes like **function name**, **file name and path**, **line number**, etc.
5. Most agents **limit keyword fields**
   - like **span.id**, to **1024** characters, and non-keyword fields, like **span.start.us**, to **10,000** characters.

##### Dropped spans

1. For **performance** reasons, APM agents can choose to **sample** or **omit** spans purposefully.
2. This can be useful in preventing **edge cases**
   - like **long-running transactions** with **over 100 spans**, that would otherwise **overload** both the **Agent** and the **APM Server**.
3. When this occurs, the **Applications UI** will **display** the number of **spans dropped**.

> To configure the **number of spans** recorded **per transaction**, see the relevant Agent documentation:

| Agent   | Config                            |
| ------- | --------------------------------- |
| Android | Not yet supported                 |
| iOS     | Not yet supported                 |
| Go      | ELASTIC_APM_TRANSACTION_MAX_SPANS |
| Java    | transaction_max_spans             |
| .NET    | TransactionMaxSpans               |
| Node.js | transactionMaxSpans               |
| PHP     | transaction_max_spans             |
| Python  | transaction_max_spans             |
| Ruby    | transaction_max_spans             |

##### Missing spans

1. Agents stream **spans** to the APM Server **separately** from their **transactions**.
2. Because of this, **unforeseen errors** may cause **spans** to **go missing**.
3. **Agents** know **how many spans** a **transaction** should have
   - if the number of **expected spans** does not equal the number of **spans received** by the APM Server
   - the **Applications UI** will **calculate the difference** and **display a message**.

##### Data streams

1. **Spans** are **stored** with **transactions** in the following **data streams**:
2. **Application traces** - `traces-apm-<namespace>`
3. **RUM** and **iOS** agent application traces - `traces-apm.rum-<namespace>`

##### Example span document

> This example shows what **span documents** can look like when **indexed** in **Elasticsearch**.

```json
[
    {
        "@timestamp": "2017-05-30T18:53:27.154Z",
        "agent": {
            "name": "elastic-node",
            "version": "3.14.0"
        },
        "ecs": {
            "version": "1.12.0"
        },
        "event": {
            "outcome": "unknown"
        },
        "http": {
            "request": {
                "method": "GET"
            },
            "response": {
                "status_code": 200
            }
        },
        "labels": {
            "span_tag": "something"
        },
        "observer": {
            "hostname": "ix.lan",
            "type": "apm-server",
            "version": "8.0.0"
        },
        "parent": {
            "id": "945254c567a5417e"
        },
        "processor": {
            "event": "span",
            "name": "transaction"
        },
        "service": {
            "environment": "staging",
            "name": "1234_service-12a3"
        },
        "span": {
            "action": "query",
            "db": {
                "instance": "customers",
                "statement": "SELECT * FROM product_types WHERE user_id=?",
                "type": "sql",
                "user": {
                    "name": "readonly_user"
                }
            },
            "duration": {
                "us": 3781
            },
            "http": {
                "method": "GET",
                "response": {
                    "status_code": 200
                }
            },
            "http.url.original": "http://localhost:8000",
            "id": "0aaaaaaaaaaaaaaa",
            "name": "SELECT FROM product_types",
            "stacktrace": [
                {
                    "abs_path": "net.js",
                    "context": {
                        "post": [
                            "    ins.currentTransaction = prev",
                            "    return result",
                            "}"
                        ],
                        "pre": [
                            "  var trans = this.currentTransaction",
                            ""
                        ]
                    },
                    "exclude_from_grouping": false,
                    "filename": "net.js",
                    "function": "onread",
                    "library_frame": true,
                    "line": {
                        "column": 4,
                        "context": "line3",
                        "number": 547
                    },
                    "module": "some module",
                    "vars": {
                        "key": "value"
                    }
                },
                {
                    "exclude_from_grouping": false,
                    "filename": "my2file.js",
                    "line": {
                        "number": 10
                    }
                }
            ],
            "start": {
                "us": 2830
            },
            "subtype": "postgresql",
            "sync": false,
            "type": "db"
        },
        "timestamp": {
            "us": 1496170407154000
        },
        "trace": {
            "id": "945254c567a5417eaaaaaaaaaaaaaaaa"
        },
        "transaction": {
            "id": "945254c567a5417e"
        },
        "url": {
            "original": "http://localhost:8000"
        }
    }
]
```

##### Span compression

1. In some cases, **APM agents** may collect **large amounts** of **very similar or identical spans** in **a transaction**.
2. For example, this can happen if spans are captured **inside of a loop**
   - or in **unoptimized SQL queries** that use **multiple queries** instead of **joins** to fetch related data.
3. In such cases, the **upper limit** of **spans** per **transaction** (by default, **500 spans**) can be reached quickly
   - causing the **agent** to **stop capturing** potentially **more relevant spans** for a given **transaction**.
4. Such **repeated similar spans** often aren’t very relevant for themselves, especially if they are of very **short duration**.
   - They also can **clutter the UI**, and cause **processing and storage overhead**.
5. To address this problem, the **APM agents** can **compress** such spans into a **single span**.
   - The **compressed span** retains **most** of the **original span information**
   - such as **overall duration** and the **number of spans** it represents.
6. Regardless of the **compression strategy**, a span is **eligible** for **compression** if:
   - It has **not propagated** its **trace context**.
   - Is an **exit** span (such as **database query spans**).
   - Its **outcome** is **not "failure"**.

###### Compression strategies

1. The **APM agent** can select between **two strategies** to decide if **two adjacent spans** can be **compressed**.
2. Both strategies have the **benefit** that **only one previous span** needs to be kept in **memory**.
3. This is important to ensure that the agent **doesn’t require large amounts of memory** to enable **span compression**.

> **Same-Kind** strategy - The agent selects this strategy if two adjacent spans have the same:

1. span **type**
2. span **subtype**
3. **destination**.service.resource - e.g. **database** name

> **Exact-Match** strategy - The agent selects this strategy if two adjacent spans have the same:

1. span **name**
2. span **type**
3. span **subtype**
4. **destination**.service.resource - e.g. **database** name

###### Settings

> **max span duration -- not compressed**

1. The agent has configuration settings to define **upper thresholds** in terms of **span duration** for both strategies.
2. For the "**Same-Kind**" strategy, the default limit is **0 milliseconds**
   - which means that the "Same-Kind" strategy is **disabled by default**.
3. For the "**Exact-Match**" strategy, the default limit is **50 milliseconds**
   - Spans with **longer duration** are **not compressed**.

#### Transactions

1. Transactions are a **special kind of span** that have **additional attributes** associated with them.
   - They describe an **event** captured by an **Elastic APM agent** instrumenting a service. 
   - You can think of transactions as the **highest level of work** you’re measuring within a service.
2. As an example, a transaction might be a:
   - **Request** to your server
   - **Batch job**
   - **Background job**
   - Custom transaction type
3. **Agents** decide whether to **sample** transactions or not, and provide settings to control **sampling behavior**.
   - If **sampled**, the **spans of a transaction** are **sent** and **stored** as **separate documents**.
   - Within **one transaction** there can be **0, 1, or many spans** captured.
4. A transaction contains:
   - The **timestamp** of the **event**
   - A **unique id, type, and name**
   - Data about the **environment** in which the event is recorded:
     - **Service** - environment, framework, language, etc.
     - **Host** - architecture, hostname, IP, etc.
     - **Process** - args, PID, PPID, etc.
     - **URL** - full, domain, port, query, etc.
     - **User** - (if supplied) email, ID, username, etc.
   - Other **relevant information** depending on the agent.
     - Example: The **JavaScript RUM agent** captures **transaction marks**
     - which are points in **time relative to the start of the transaction** with some label.
5. In addition, agents provide options for users to capture **custom metadata**.
   - **Metadata** can be **indexed**. - **labels**
   - or **not-indexed** - **custom**.
6. Transactions are **grouped** by their **type** and **name** in the Applications UI’s **Transaction overview**.
   - If you’re using a **supported framework**, APM agents will **automatically** handle the **naming** for you.
   - If you’re not, or if you wish to **override** the **default**, all agents have **API methods** to **manually** set the type and name.
7. **type**
   - should be a **keyword** of **specific relevance** in the **service’s domain**, e.g. **request**, **backgroundjob**, etc.
8. **name**
   - should be a **generic designation** of a **transaction** in the scope of a **single service**
   - e.g. **GET /users/:id**, **UsersController#show**, etc.
9. Most agents limit **keyword fields** (e.g. labels) to **1024** characters
   - **non-keyword fields** (e.g. span.db.statement) to **10,000** characters.

##### Data streams

> **Transactions** are **stored with spans** in the following data streams:

1. Application traces - `traces-apm-<namespace>`
2. **RUM** and **iOS** agent application traces - `traces-apm.rum-<namespace>`

##### Example transaction document

> This example shows what **transaction documents** can look like when **indexed** in Elasticsearch

```json
[
    {
        "@timestamp": "2017-05-30T18:53:42.281Z",
        "agent": {
            "name": "elastic-node",
            "version": "3.14.0"
        },
        "container": {
            "id": "container-id"
        },
        "ecs": {
            "version": "1.12.0"
        },
        "event": {
            "ingested": "2020-08-11T09:55:04.391451Z",
            "outcome": "unknown"
        },
        "host": {
            "architecture": "x64",
            "ip": ["127.0.0.1"],
            "os": {
                "platform": "darwin"
            }
        },
        "kubernetes": {
            "namespace": "namespace1",
            "pod": {
                "name": "pod-name",
                "uid": "pod-uid"
            }
        },
        "observer": {
            "hostname": "ix.lan",
            "type": "apm-server",
            "version": "8.0.0"
        },
        "process": {
            "args": [
                "node",
                "server.js"
            ],
            "pid": 1234,
            "parent": {
                "pid": 6789
            },
            "title": "node"
        },
        "processor": {
            "event": "transaction",
            "name": "transaction"
        },
        "service": {
            "environment": "staging",
            "framework": {
                "name": "Express",
                "version": "1.2.3"
            },
            "language": {
                "name": "ecmascript",
                "version": "8"
            },
            "name": "1234_service-12a3",
            "node": {
                "name": "container-id"
            },
            "runtime": {
                "name": "node",
                "version": "8.0.0"
            },
            "version": "5.1.3"
        },
        "timestamp": {
            "us": 1496170422281000
        },
        "trace": {
            "id": "85925e55b43f4340aaaaaaaaaaaaaaaa"
        },
        "transaction": {
            "duration": {
                "us": 13980
            },
            "id": "85925e55b43f4340",
            "name": "GET /api/types",
            "result": "failure",
            "sampled": true,
            "span_count": {
                "started": 0
            },
            "type": "request"
        },
        "user": {
            "email": "foo@bar.com",
            "id": "123user",
            "name": "foo"
        }
    }
]
```

#### Transaction sampling

1. **Distributed tracing** can generate a **substantial amount of data**.
   - More data can mean **higher costs** and **more noise**.
   - **Sampling** aims to **lower the amount of data ingested** and the **effort** required to **analyze** that data
   - all while still making it **easy** to find **anomalous patterns** in your applications
     - **detect outages**, **track errors**, and **lower** mean time to recovery (**MTTR**).
2. Elastic APM supports two types of sampling
   - **Head**-based sampling
   - **Tail**-based sampling

##### Head-based sampling

1. In head-based sampling, the **sampling decision** for each **trace** is made when the trace is **initiated**.
2. Each trace has a **defined** and **equal probability** of being sampled.
3. For example, a **sampling value** of **.2** indicates a **transaction sample rate** of **20%**.
   - This means that only **20%** of **traces** will **send** and **retain** all of their **associated information**.
   - The remaining traces will **drop contextual information** to **reduce** the **transfer** and **storage** size of the **trace**.
4. Head-based sampling is **quick** and **easy** to set up.
   - Its **downside** is that it’s **entirely random** — interesting data might be **discarded** purely due to **chance**.

###### Distributed tracing

1. In a **distributed trace**, the **sampling decision** is still made when the trace is **initiated**.
2. Each **subsequent** service **respects** the **initial service’s sampling decision**, regardless of its **configured sample rate**
3. the result is a **sampling percentage** that matches the **initiating service**.

![dt-sampling-example-1](/Users/zhongmingmao/data/typora/dt-sampling-example-1.png)

1. In the example in Figure 1, Service A initiates four transactions and has sample rate of **.5** (**50%**).
2. The **upstream sampling decision** is **respected**
   - so even if the **sample rate** is defined and is a **different value** in Service B and Service C
   - the sample rate will be **.5** (**50%**) for **all services**.

![dt-sampling-example-2](/Users/zhongmingmao/data/typora/dt-sampling-example-2.png)

1. In the example in Figure 2, Service A initiates four transactions and has a sample rate of **1** (**100%**).
2. Again, the **upstream sampling decision** is **respected**, so the **sample rate** for **all services** will be **1** (**100%**).

> Trace continuation **strategies** with **distributed tracing**

1. In addition to setting the **sample rate**, you can also specify which **trace continuation strategy** to use.
2. There are three trace continuation strategies: **continue**, **restart**, and **restart_external**.
3. **continue**
   - The continue trace continuation strategy is the **default**
   - and will behave similar to the examples in the **Distributed tracing** section.
4. **restart_external**
   - Use the restart_external trace continuation strategy on an **Elastic-monitored service**
   - to **start a new trace** if the **previous service** did not have a **traceparent** header with **es vendor data**.
   - This can be helpful if a transaction includes an **Elastic-monitored service**
     - that is **receiving requests** from an **unmonitored service**.

![dt-sampling-continuation-strategy-restart_external](/Users/zhongmingmao/data/typora/dt-sampling-continuation-strategy-restart_external.png)

1. In the example in Figure 3, Service A is an Elastic-monitored service that initiates four transactions with a sample rate of **.25** (25%).
2. Because Service B is **unmonitored**, the traces started in Service A will **end** there.
3. Service C is an Elastic-monitored service that initiates four transactions that **start new traces** with a new sample rate of **.5** (50%).
4. Because Service D is also Elastic-monitored service, the **upstream sampling decision** defined in Service C is **respected**. 
5. The end result will be three sampled traces.

> Use the **restart** trace continuation strategy on an **Elastic-monitored service** to **start a new trace**
> **regardless** of whether the **previous service** had a **traceparent header**.

1. This can be helpful if an Elastic-monitored service is **publicly exposed**
2. and you do not want tracing data to possibly be **spoofed** by **user requests**.

![dt-sampling-continuation-strategy-restart](/Users/zhongmingmao/data/typora/dt-sampling-continuation-strategy-restart.png)

1. In the example in Figure 4, Service A and Service B are Elastic-monitored services that use the **default** trace continuation strategy.
2. Service A has a **sample rate** of **.25** (25%), and that **sampling decision** is **respected** in Service B.
3. Service C is an Elastic-monitored service that uses the **restart** trace continuation strategy and has a **sample rate** of **1** (100%).
   - Because it uses restart, the **upstream sample rate** is **not respected** in Service C
   - and all four traces will be **sampled as new traces** in Service C.
4. The end result will be five sampled traces.

###### OpenTelemetry

1. Head-based sampling is **implemented directly** in the **APM agents** and **SDKs**.
2. The **sample rate** must be **propagated** between **services** and the **managed intake service** in order to produce **accurate metrics**.
3. OpenTelemetry offers multiple samplers.
   - However, most samplers **do not propagate** the **sample rate**.
   - This results in **inaccurate span-based metrics**, like **APM throughput**, **latency**, and **error metrics**.
4. For **accurate span-based metrics** when using **head-based sampling** with **OpenTelemetry**
   - you must use a **consistent probability sampler**.
   - These samplers **propagate** the **sample rate** between **services** and the **managed intake service**
   - resulting in **accurate metrics**.
5. OpenTelemetry does not offer **consistent probability samplers** in **all languages**.
   - OpenTelemetry users should consider using **tail-based sampling** instead.

##### Tail-based sampling

1. Support for tail-based sampling
   - Tail-based sampling is **only supported** when writing to **Elasticsearch**.
   - If you are using a **different output**, tail-based sampling is **not supported**.
2. Tail-based sampling is **not compatible** with **Elastic Cloud Serverless**.
3. In tail-based sampling, the **sampling decision** for each trace is made **after** the **trace** has **completed**.
   - This means all traces will be **analyzed** against a set of **rules**, or **policies**
   - which will determine the **rate** at which they are sampled.
4. Unlike head-based sampling, each trace does **not** have an **equal probability** of being sampled.
   - Because **slower traces** are **more interesting** than **faster ones**, tail-based sampling uses **weighted random sampling** 
   - so traces with a **longer root transaction duration** are **more likely** to be **sampled**
     - than traces with a **fast root transaction duration**.
5. A **downside** of tail-based sampling is that it results in **more data** being **sent** from **APM agents** to the **APM Server**.
   - The **APM Server** will therefore use more **CPU**, **memory**, and **disk** than with head-based sampling.
6. However, because the **tail-based sampling decision** happens in **APM Server**
   - there is **less data** to transfer from **APM Server** to **Elasticsearch**.
7. So running **APM Server** close to your **instrumented services** can **reduce** any **increase in transfer costs** that tail-based sampling brings.

###### Distributed tracing

> With tail-based sampling, **all traces** are **observed** and a **sampling decision** is only made once a **trace completes**.

![dt-sampling-example-3](/Users/zhongmingmao/data/typora/dt-sampling-example-3.png)

1. In this example, Service A initiates four transactions.
2. If our **sample rate** is **.5** (50%) for traces with a **success outcome**, and **1** (100%) for traces with a **failure outcome**

###### OpenTelemetry

1. Tail-based sampling is **implemented entirely** in **APM Server**
   - and will work with traces sent by either **Elastic APM agents** or **OpenTelemetry SDKs**.
2. Due to **OpenTelemetry tail-based sampling limitations** when using **tailsamplingprocessor**
   - we recommend using **APM Server tail-based sampling** instead.

### Collect application data

#### Use OpenTelemetry with APM

1. OpenTelemetry is a set of **APIs**, **SDKs**, **tooling**, and **integrations**
   - that enable the **capture** and **management** of **telemetry data** from your **services** and **applications**.
2. **Elastic** integrates with **OpenTelemetry**
   - allowing you to **reuse** your **existing instrumentation** to easily send **observability data** to the **Elastic Stack**.

##### ~~Elastic Distributions of OpenTelemetry language SDKs~~

1. Some **Elastic Distributions** of **OpenTelemetry** are **not yet recommended** for **production use**.
   - **Functionality** may be **changed** or **removed** in **future releases**.
   - **Alpha releases** are **not subject to** the **support SLA** of **official GA features**.
2. **Elastic** offers **several distributions** of **OpenTelemetry language SDKs**.
   - A **distribution** is a **customized version** of an **upstream OpenTelemetry repository**.
   - Each Elastic Distribution of OpenTelemetry is a customized version of an **OpenTelemetry language SDK**.

> Java / Python / Node.js / .NET

![apm-otel-distro](/Users/zhongmingmao/data/typora/apm-otel-distro.png)

1. With an **Elastic Distribution** of **OpenTelemetry language SDK** you have access to **all the features** of the **OpenTelemetry SDK** that it customizes, plus:
2. You may get access to **SDK improvements** and **bug fixes** contributed by the **Elastic team**
   - **before** the changes are available **upstream** in the OpenTelemetry repositories.
3. The distro **preconfigures** the **collection** of **tracing** and **metrics** signals, applying some **opinionated defaults**, such as which sources are collected by default.

##### ~~Upstream OpenTelemetry API/SDK + Elastic APM agent~~

>  Use the **OpenTelemetry API/SDKs** with **Elastic APM agents** to translate **OpenTelemetry API calls** to **Elastic APM API calls**.

![apm-otel-api-sdk-elastic-agent](/Users/zhongmingmao/data/typora/apm-otel-api-sdk-elastic-agent.png)

1. This allows you to **reuse** your **existing OpenTelemetry instrumentation** to create **Elastic APM transactions and spans**
   - avoiding **vendor lock-in** and having to redo manual instrumentation.
2. However, **not all features** of the **OpenTelemetry API** are **supported** when using this approach
   - and **not all Elastic APM agents** support this approach.

##### Upstream OpenTelemetry Collector and language SDKs

1. The Elastic Stack **natively** supports the OpenTelemetry protocol (**OTLP**).
   - This means **trace data** and **metrics** collected from your **applications** and **infrastructure** by an **OpenTelemetry Collector** or **OpenTelemetry language SDK** can be sent to the **Elastic Stack**.
2. You can set up an **OpenTelemetry Collector**, instrument your application with an **OpenTelemetry language SDK** that sends data to the **collector**, and use the collector to **process** and **export** the data to **APM Server**.

![apm-otel-api-sdk-collector](/Users/zhongmingmao/data/typora/apm-otel-api-sdk-collector.png)

1. It’s also possible to send data **directly** to **APM Server** from an **upstream OpenTelemetry SDK**.
   - You might do this during **development** or if you’re monitoring a **small-scale application**.
2. This approach works well when you need to instrument a technology that Elastic doesn’t provide a solution for.
   - For example, if you want to instrument **C** or **C++** you could use the **OpenTelemetry C++ client**.
3. However, there are some **limitations** when using **collectors** and **language SDKs** built and maintained by **OpenTelemetry**
   - Elastic can’t provide **implementation support** on how to use **upstream OpenTelemetry tools**.
   - You won’t have access to **Elastic enterprise APM features**.
   - You may experience problems with **performance efficiency**.

##### Upstream OpenTelemetry Collectors and language SDKs

