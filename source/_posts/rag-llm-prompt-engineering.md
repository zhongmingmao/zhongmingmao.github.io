---
title: RAG - LLM + Prompt Engineering
mathjax: true
date: 2024-08-14 00:06:25
cover: https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/llm-prompting.webp
categories:
  - AI
  - RAG
tags:
  - AI
  - LLM
  - RAG
  - Prompting
---

# RAG 生成流程

![image-20241022212827467](https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20241022212827467.png)

<!-- more -->

1. 经过 RAG **索引**流程（外部知识的**解析**和**向量化**）和 RAG **检索**流程（**语义相似性**的匹配及混合检索），进入到 RAG **生成**流程
2. 在 RAG 生成流程中，需要**组合指令**，即携带**查询问题**及检索到的相关信息输入的 LLM，由 LLM **理解并生成**最终的回复
3. RAG 的本质是通过 LLM 提供**外部知识**来**增强**其理解和回答领域问题的能力
4. LLM 在 RAG 系统中起到了**大脑**的作用
   - 在面对**复杂**且**多样化**的 RAG 任务时，**LLM 的性能**直接决定了系统的**整体效果**
5. **提示词工程**是生成流程中的另一个关键环节
   - 通过**有效的指令的设计和组合**，可以帮助 LLM **更好地理解**输入内容，从而生成**更加精确和相关**的回答
   - **精心设计**的问题提示词，往往能**提升生成效果**

# LLM

## 发展

![image-20241022214256459](https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20241022214256459.png)

> RAG 目前更关注**通用大模型**

![image-20241022214741014](https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20241022214741014.png)

## 原理

1. Google 于 2017 年发布论文 **Attention Is All You Need**，引入了 **Transformer** 模型
2. **Transformer** 模型是**深度学习领域**的一个**突破**性架构，**LLM** 的成功得益于对 **Transformer** 模型的应用
3. 与传统的 **RNN**（循环神经网络） 相比，**Transformer** 模型**不依赖于序列顺序**
   - 通过自注意力（**Self-Attention**）机制来捕捉序列中**各元素之间的关系**
4. **Transformer** 由多个堆叠的编码层（**Encoder**）和解码层（**Decoder**）组成
   - 每一层包括**自注意力层**、**前馈层**和**归一化层**
   - 这些层**协同**工作，逐步**捕捉**输入数据信息**特征**，从而**预测**输出，实现强大的语言**理解**和**生成**能力
5. Transformer 模型的**核心**创新 - **位置编码** + **自注意力机制**
   - **位置编码**
     - 帮助模型理解输入数据的**顺序**信息
   - **自注意力机制**
     - 允许模型根据输入的**全局上下文**，为每个 **Token** 分配不同的**注意力权重**
     - 从而更准确地理解词与词之间的**关联性**
6. Transformer 特别适用于**语言模型**
   - 语言模型需要精确捕捉**上下文中的细微差别**，生成符合**语义逻辑**的文本

> **编码器**负责**理解**输入信息的**顺序**和**语义**，而**解码器**则输出**概率最高**的 **Token**

![image-20241022220451857](https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20241022220451857.png)

1. LLM 的突破始于 OpenAI 于 2022 年底发布的 **ChatGPT**
2. 核心优势
   - 庞大的**参数规模** + 基于 PB 级别数据的训练所带来的卓越**语言理解和生成能力** + 显著的**涌现能力**
3. LLM 不仅在传统的 **NLP** 处理任务中展现了卓越表现，还具备**解决复杂问题**和进行**逻辑推理**等**高级认知能力**
4. 基于 **Transformer** 模型**预测下一个 Token** 的原理
   - LLM 在分析**海量**的语料库后，能够在逻辑上**精准补全**不完整的句子，甚至生成新的句子
   - 赋予了 LLM 生成**连贯且上下文相关**的文本的能力，适用于**文本生成**、**翻译**、**问答系统**等多个领域

## 选型

### 测评

> SuperCLUE：**中文通用**大模型综合性测评基准

![image-20241022222230276](https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20241022222230276.png)

1. 在 RAG 场景中，LLM 的**检索能力**表现是核心
2. SuperCLUE 针对 RAG 应用场景进行了独立测试，具体评估了**检索**和**生成**过程中的表现

### 维度

> 开源 vs 闭源

1. **开源模型**适用于**数据敏感性高**或者有**严格合规要求**的场景，通过**自托管**实现对数据的完全掌控，确保**隐私**与**安全**
2. **闭源模型**适用于**数据敏感度较低**的应用场景，其维护和服务相对完善，降低**运维复杂度**

> 模型参数规模

1. **大参数模型**在**复杂任务**中的**推理**和**生成**能力较强，但并非所有应用场景都需要**高精度模型**
2. **小参数模型**（7B）在满足**简单逻辑**任务时，具备更优的**响应速度**、**成本控制**和**资源利用效率**

> 国内部署 vs 国外部署

1. 稳定性、网络延迟、充值付费等
2. 数据合规

### 推荐

> 闭源

1. 通义千问、文心一言、腾讯混元、字节豆包、Kimi Chat
2. **参数量较高**，在 RAG 场景的**实际表现差异较少**，主要取决于**成本**

> 开源

| 系列         | 特点                                                         |
| ------------ | ------------------------------------------------------------ |
| **Qwen**     | 在**长上下文**处理上表现出色，非常适合需要**深度语义理解**的 RAG 任务 |
| **Baichuan** | 在**数学**和**编码**任务中表现卓越，在**安全性**方面经过深入评估 |
| **ChatGLM**  | 适用于**长文本**检索和生成                                   |

# Prompt Engineering

## 概念

1. Prompt Engineering 是为生成式 AI 模型**设计输入**以获得**最佳输出**的实践
2. 输入即 Prompt，而编写 Prompt 的过程即 Prompt Engineering
3. 核心理念 - 通过提供更优质的输入，让**生成式 AI 模型**（如 LLM）生成更符合需求的结果
4. Prompt Engineering 通过**开发**和**优化** Prompt 来有效利用 LLM 的**潜力**
5. Prompt 工程师的任务不仅仅是**设计提示**
   - 而是通**深入理解**模型的**功能**和**局限性**，创造能够与模型输入产生**最佳互动**的 Prompt

## 元素

> Prompt 组成元素

| 元素                 | 描述                                                         |
| -------------------- | ------------------------------------------------------------ |
| **Instruction**      | 指示模型要执行的特定**任务**或者**操作**                     |
| **Context**          | 为模型提供额外**信息**或**背景**，帮助引导模型生成更准确的响应 |
| **Input Data**       | 希望模型回答的问题或者感兴趣的输入内容                       |
| **Output Indicator** | 指示模型的**输出类型**或**格式**                             |

![image-20241022225548891](https://rag-1253868755.cos.ap-guangzhou.myqcloud.com/image-20241022225548891.png)

## 技巧

> RAG 中的 Prompt Engineering 技巧 - **高效低成本**地**提升输出质量**

### 具体指令

1. 向 LLM 提供**具体清晰**的指令，能够提高输出的**准确性**
2. **模糊**的指令往往导致模型生成**不理想**的结果

```
请根据上传的银行业报告，简洁总结当前的市场趋势，重点分析政策变化对行业的影响，输出为以下Markdown格式：
- **市场趋势**
- **政策影响**
- **竞争风险**
```

### 示例学习

1. 通过给模型提供多个**参考示例**，模型可以进行**模式识别**，进而**模仿**、**思考**并**生成**类似的答案
2. **无需**对模型进行**进一步训练**，有效提升模型的输出质量

```
以下是两个关于银行业的分析示例，请按照这种格式对新的报告进行分析：
- 示例 1：**市场趋势**：由于政策放宽，银行贷款增长迅速。
- 示例 2：**政策影响**：新的利率政策可能会对中小企业贷款产生负面影响。


请对下面报告进行同样的分析。
```

### 默认回复

1. 当模型无法从文档中获取足够信息时，通过设定**默认回复策略**，避免模型产生**幻觉**（虚假答案）
2. 确保模型仅基于**文档中的事实**进行回答

```
如果文档中没有足够的事实回答问题，请返回{无法从文档中获得相关内容}，而不是进行推测。
```

### 角色设定

1. 为模型设定特定的角色身份，可以帮助模型**更好地理解**任务要求和角色责任，输出更加一致的内容

```
你的角色: 知识库专家
- 背景：分析银行业市场数据
- 目标：生成一份详细的行业趋势分析
- 限制：仅根据报告中的数据生成分析
```

### 解释理由

1. 在编写 Prompt 时，向模型**解释**为什么某些任务需要**特定的处理方式**
2. 可以帮助模型更好地理解任务背景，从而提高输出的**质量**和**相关性**

```
请生成一份简明扼要的银行业报告摘要，不要逐字重复段落内容。原因：读者可以访问完整文档，如果需要可以详细阅读全文。
```

### 基础说明

1. 为模型提供文档的**背景信息**和**文本来源**可以奠定**任务基础**，让模型更好地进行任务**推理**和**回答**

```
以下是关于银行业政策变化的相关规则，它们将用于回答有关政策对银行业影响的问题。
```

